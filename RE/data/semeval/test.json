{
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_48": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_48",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_48",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_48",
		"text": "The synthetic motherset was generated by producing 10,000 candidate normals and 10,000 candidate anomalies from two different multivariate distributions with the intention of being able to manipulate all problem dimensions with ease . The candidate normals are drawn from a multivariate gaussian with a covariance matrix of $I$ ; that is , each feature is drawn from the standard normal distribution independently of the others . The anomalies are drawn uniformly from the hyper-cube defined by the range $(-4,4)$ in each dimension . Both distributions have ten dimensions ; that is , each point exists in $R^{10}$ ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_49": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_49",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_49",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_49",
		"text": "Our heuristic procedure begins by training a Random Forest as in \\cite{Breiman} to solve the multi-class classification problem . Then we calculate the amount of confusion between each pair of classes . For each data point $x_i$ , the Random Forest computes an estimate of $P(\\hat{y_i}=k|x_i)$ , the predicted probability that $x_i$ belongs to class $k$ . We construct a confusion matrix $C$ in which cell $C_{j,k}$ contains the sum of $P(\\hat{y_i}=k|x_i)$ for all $x_i$ whose true class $y_i = j$ . We then define a graph in which each node is a class and each edge ( between two classes $j$ and $k$ ) has a weight equal to $C[j,k]+C[k,j]$ . This is the ( un-normalized ) probability that a data point in class $j$ will be confused with a data point in class $k$ or vice versa . We then compute the maximum weight spanning tree of this ( complete ) graph to identify a graph of `` most - confusable ' ' relationships between pairs of classes . We then two - color this tree so that no adjacent nodes have the same color . The two colors define the two classes of points ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_39": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_39",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_39",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_39",
		"text": "These models yield $\\hat{R^2}$ measures of 0.7299 ( for logit ( AUC ) ) and 0.8009 ( for log ( LIFT ) ) , a strong indication that the variables we are considering are adequate to explain micro-experiment outcomes . The mixed effects models also provide coefficients measuring the effect of each problem dimension on each algorithm . Similar to \\cref{fig:ar,fig:pd,fig:cl,fig:ir} , \\cref{fig:arco,fig:pdco,fig:clco,fig:irco} show these coefficients across each problem dimension ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_11": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_11",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_11",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_11",
		"text": "The well - known Local Outlier Factor algorithm ( Breunig , et al. \\cite{Breunig:2000} ) computes the outlier score of a point $x_i$ by computing its average distance to its $k$ nearest neighbors . It normalizes this distance by computing the average distance of each of those neighbors to {\\ it their } $k$ nearest neighbors . So , roughly speaking , a point is believed to be more anomalous if it is significantly farther from its neighbors than they are from each other ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_10": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_10",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_10",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_10",
		"text": "As proposed by Tax and Duin \\cite{Tax:2004} and similar in concept to One - Class SVM , Support Vector Data Description finds the smallest hypersphere in kernel space that encloses $1-\\delta$ of the data . As above , the outlier scores produced by this algorithm are determined by the residual after each point is projected onto the decision surface ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_38": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_38",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_38",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_38",
		"text": "So far the $\\hat{R^2}$ of our best models are 0.5019 and 0.6382 which are respectable measures but leave a lot of variance unexplained . We constructed several mixed effect models to see if we could better explain our results with the same data . Our best models kept our problem dimensions as fixed effects and treated choice of algorithm and motherset as random effect groups . Each member of each random effect group models its interaction with the fixed effects . Additionally , choice of motherset also models its own interaction with choice of algorithm . $$metric \\sim (rf + pd + cl + ir | algo) + (rf + pd + cl + ir + algo | mset)$$"
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_12": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_12",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_12",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_12",
		"text": "Angle - Based Outlier Detection as proposed by Kriegel , et al in \\cite{abod} in its full form is an algorithm of cubic complexity as follows . For each point $x_i$ , consider all pairs of other points $(x_j,x_k)\\in X,i\\ne j\\ne k$ and compute the angle between them relative to to point $x_i$ . The sample variance of these angles determines the outlier score , with \\emph{lower} variances indicating anomalous points . Because of the run - time complexity , two simple approximations were suggested by the authors . The first is to sub sample the data and use this as the reference set for computing angles . The other is to only consider the angles among the $k$ nearest neighbors to $x_i$ . In initial experiments we found the latter to outperform the former and so that is the strategy employed in this study ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_8": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_8",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_8",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_8",
		"text": "Another approach to density estimation is to fit a Gaussian mixture model ( GMM ) using the EM algorithm . A single GMM is not very robust , and like $k$ - means clustering it requires that we select a value of $k$ Gaussian mixture components . To improve robustness , we computed an ensemble of GMMs for many values of $k$ , discarded models that did not fit the data well , and then combined the predicted densities of the remaining models . As above , the outlier scores produced are based on the negative log - likelihood of each point according to the final models ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_9": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_9",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_9",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_9",
		"text": "The One - Class SVM algorithm ( Scholkopf et al. \\cite{Scholkopf:99} ) uses a Support - Vector Machine to search for a kernel - space decision boundary that separates fraction $1-\\delta$ of the data from the kernel - space origin . The outlier scores produced by this algorithm are determined by the residual after each point is projected onto the decision surface . Points outside the decision boundary will have positive residuals , where interior points will have negative residuals ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_13": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_13",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_13",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_13",
		"text": "Precision - at - $k$ or Recall - at - $k$ metrics are also common but run the risk of being application specific ( the appropriate selection of $k$ is determined by the context of the application ) and we feel not appropriate for a broad meta-analysis such as this , but we note that such metrics might be the more useful in a real - world setting ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_17": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_17",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_17",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_17",
		"text": "\\cref{tbl:hypo} summarizes the global benchmark failure rates for AUC and AP . The `` Either ' ' column indicates benchmarks for which all algorithms failed under at least one of the two metrics . \\begin{table}  \\resizebox{\\textwidth} {! } { \\begin{minipage} { 0.5\\text width } \\tbl{Benchmark Failure Rate by Metric and Significance Level\\label{tbl:hypo} } { \\begin{tabular} { | r | | c | c | c | } \\hline & \\textbf{AUC} & \\textbf{AP} & \\textbf{Either} \\\\ \\hline \\hline $\\alpha=0.05$ & 0.2418 & 0.2815 & 0.3337 \\\\ $\\alpha=0.01$ & 0.3282 & 0.4162 & 0.4609 \\\\ $\\alpha=0.001$ & 0.4108 & 0.5087 & 0.5430 \\\\ \\hline \\end{tabular} } \\end{minipage} } \\end{table}"
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_16": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_16",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_16",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_16",
		"text": "We performed such hypothesis tests for both AUC and AP and for $\\alpha\\in(0.05,0.01,0.001)$ for each micro-experiment result . Failure in this context refers to failing to reject the null hypothesis . To summarize our tests , we first define the notion of \\textbf{benchmark failure} as a benchmark instance for which \\emph{all} algorithms failed . While benchmark failure is dependent on the algorithms used in this study , we still believe it is a good indication that we should not use the benchmark as evidence for later conclusions ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_14": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_14",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_14",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_14",
		"text": "Specifically , one can treat the AUC and AP of a random ranking of points as random variables each with parameters $n_{\\text{anom}}$ ( the number of anomalies in the benchmark ) and $n_{\\text{norm}}$ ( the number of normals ) and then compute the quantiles of interest for each of these distributions . Conducting a test with significance $\\alpha$ is a matter of computing the $(1-\\alpha)$ - quantile of the appropriate random variable . Refer to \\cref{appendix:random} for an overview of how AUC and AP can be treated as random variables ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_28": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_28",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_28",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_28",
		"text": "To demonstrate the impact of our benchmark construction methodology on micro-experiment results we first want to examine results in a way that is agnostic to choice of algorithm . Because we are only examining results from benchmarks where at least one algorithm produced statistically significant output , we know that if we only consider the best result from each benchmark we are always choosing a result that is better than random with high confidence . As each benchmark construction factor has a well defined control group , we compute the mean difference in performance - of - best - algorithm between each level and the control group , and then place a $0.999$ confidence interval around this difference . The results are displayed in \\cref{fig:mset,fig:ar,fig:pd,fig:cl,fig:ir} . Observe that the metrics logit ( AUC ) and log ( LIFT ) are not meant to be compared to each other , but are shown side by side for a more compact presentation ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_29": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_29",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_29",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_29",
		"text": "\\begin{table}  \\resizebox{\\textwidth} {! } { \\begin{minipage} { 0.5\\text width } \\tbl{Mean Performance by Algorithm and Metric\\label{tbl:meanalgo} } { \\begin{tabular} { | r | | c | c | } \\hline & \\textbf{Mean logit [unused10] } & \\textbf{Mean [unused10] } \\\\ \\hline \\hline abod & 0.9517 & 0.9009 \\\\ egmm & 0.9678 & 0.9081\\\\ iforest & \\textbf{1.0893} & [unused10] \\\\ loda & 0.8604 & 0.9156 \\\\ lof & 0.9632 & 0.9329\\\\ ocsvm & 0.5650 & 0.8608 \\\\ rkde & 0.9554 & 0.9132\\\\ svdd & 0.1538 & 0.2806 \\\\ \\hline \\end{tabular} } \\end{minipage} } \\end{table}"
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_15": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_15",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_15",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_15",
		"text": "A more intuitive view of this process : if algorithm $a$ achieves an AUC 0 f 0.75 on benchmark $b$ and we reject the null hypothesis with $\\alpha=0.001$ , that would mean that with probability at least 0.999 a random ranking would achieve an AUC worse than 0.75 \\emph{on benchmark [unused10] } ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_18": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_18",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_18",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_18",
		"text": "The appropriate significance level for this study is debatable . Smaller $\\alpha$ trades away potential evidence ( by eliminating benchmarks ) for greater confidence that the results from the benchmarks under consideration are relevant . We choose to apply the more stringent threshold of $\\alpha=0.001$ ; even though the failure rate at this level is rather high , it still leaves many benchmarks across all factors of interest ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_30": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_30",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_30",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_30",
		"text": "We have already described measures of \\textbf{clusteredness} and \\textbf{feature irrelevance} in \\cref{sec:method} that are continuous ; as with clusteredness we will apply a log transform to the feature irrelevance ratio . \\textbf{relative frequency} and \\textbf{point difficulty} are both in the range $[0,1]$ and so as with AUC we will apply the logit transform to them . This gives us real valued representations of each problem dimension suitable for a linear model ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_24": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_24",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_24",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_24",
		"text": "\\begin{table}  \\resizebox{\\textwidth} {! } { \\begin{minipage} { 0.5\\text width } \\tbl{Benchmark Failure Rate by Metric and Feature Irrelevance Level ( [unused10] )\\label{tbl:irfail} } { \\begin{tabular} { | r | | c | c | c | } \\hline & \\textbf{AUC} & \\textbf{AP} & \\textbf{Either} \\\\ \\hline \\hline ir - 0 & 0.3065 & 0.4008 & 0.4327 \\\\ ir - 1 & 0.3785 & 0.4760 & 0.5098 \\\\ ir - 2 & \\textbf{0.4356} & \\textbf{0.5362} & \\textbf{0.5743} \\\\ ir - 3 & \\textbf{0.5224} & \\textbf{0.6215} & \\textbf{0.6549} \\\\ \\hline \\end{tabular} } \\end{minipage} } \\end{table}"
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_2": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_2",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_2",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_2",
		"text": "{ \\it Relative frequency} is the fraction of the incoming data points that are anomalies of interest. This value is the problem dimension that is most reliably reported in the literature already and has also been called ``plurality'' and ``contamination rate''. Little is done to examine the impact is has on results, however. The behavior of anomaly detection algorithms often changes with the relative frequency. If anomalies are very rare, then methods that pretend that all training points are ``normal'' and fit a model to them may do well. If anomalies are more common, then methods that attempt to fit a model of the anomalies may do well. In most experiments in the literature, the anomalies have a relative frequency between 0.01 and 0.1, but some go as high as 0.3 \\cite{kim:08,Liu:08} . Many security applications are estimated to have relative frequencies in the range of $10^{-5}$ or $10^{-6}$ ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_3": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_3",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_3",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_3",
		"text": "We propose to define point difficulty ( pd ) based on an oracle that knows the true generating processes underlying the `` normal ' ' and `` anomalous ' ' points . Using this knowledge , the oracle can estimate the probability $P(y=\\mbox{normal}|x)$ that a data point $x$ was generated by the `` normal ' ' distribution or $P(y=\\mbox{anomaly}|x)$ that a data point $x$ was generated by the `` anomalous ' ' distribution . We consider the point difficulty of any point to be the estimated probability that it belongs to the other class . The point difficulty level of an entire benchmark is summarized as the mean of the point difficulty of all the points in the benchmark ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_25": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_25",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_25",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_25",
		"text": "\\begin{table}  \\resizebox{\\textwidth} {! } { \\begin{minipage} { 0.5\\text width } \\tbl{Algorithm Failure Rate by Metric ( [unused10] )\\label{tbl:algofail} } { \\begin{tabular} { | r | | c | c | c | } \\hline & \\textbf{AUC} & \\textbf{AP} & \\textbf{Either} \\\\ \\hline \\hline abod & 0.5898 & 0.6784 & 0.7000 \\\\ iforest & \\textbf{0.5520} & \\textbf{0.6514} & [unused10] \\\\ loda & 0.6187 & 0.6955 & 0.7194 \\\\ lof & 0.6016 & 0.7071 & 0.7331 \\\\ rkde & 0.6122 & 0.7030 & 0.7194 \\\\ ocsvm & 0.7218 & 0.7342 & 0.7960 \\\\ svdd & 0.8482 & 0.8868 & 0.9080 \\\\ egmm & 0.6188 & 0.7146 & 0.7303 \\\\ \\hline \\end{tabular} } \\end{minipage} } \\end{table}"
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_31": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_31",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_31",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_31",
		"text": "The simplest fixed effect linear model to build would be to predict a metric given our four problem dimensions ( abbreviated $rf,pd,cl,ir$ ) , choice of motherset ( $mset$ ) and choice of algorithm ( $algo$ ) . $$metric \\sim rf + pd + cl + ir + mset + algo$$"
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_19": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_19",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_19",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_19",
		"text": "\\begin{table}  \\resizebox{\\textwidth} { ! } { \\begin{minipage} { 0.5\\text width } \\tbl{Benchmark Failure Rate by Metric and Motherset ( [unused10] )\\label{tbl:msetfail} } { \\begin{tabular} { | r | | c | c | c | } \\hline & \\textbf{AUC} & \\textbf{AP} & \\textbf{Either} \\\\ \\hline \\hline synthetic & 0.2417 & 0.2553 & 0.2765 \\\\ abalone & 0.3838 & 0.4533 & 0.4841 \\\\ comm. and .crime & \\textbf{0.4924} & 0.5053 & [unused10] \\\\ concrete & \\textbf{0.5121} & \\textbf{0.5908} & [unused10] \\\\ fault & \\textbf{0.4178} & \\textbf{0.6105} & [unused10] \\\\ gas & 0.2767 & \\textbf{0.5178} & 0.5189 \\\\ imgseg & 0.2792 & 0.2569 & 0.3667 \\\\ landsat & \\textbf{0.5286} & \\textbf{0.5617} & [unused10] \\\\ letter .rec & \\textbf{0.6276} & \\textbf{0.7273} & [unused10] \\\\ magic .gamma & 0.3300 & 0.3322 & 0.3917 \\\\ opt .digits & \\textbf{0.5567} & \\textbf{0.7115} & [unused10] \\\\ pageb & 0.0468 & 0.1894 & 0.1915\\\\ particle & 0.2533 & 0.3678 & 0.4306 \\\\ shuttle & 0.0944 & 0.2711 & 0.2722 \\\\ skin & 0.0853 & 0.3673 & 0.3693 \\\\ spambase & 0.3622 & 0.4844 & 0.5178 \\\\ wave & \\textbf{0.4954} & \\textbf{0.6000} & \\textbf{0.6278} \\\\ wine & \\textbf{0.4860} & \\textbf{0.6355} & \\textbf{0.6554} \\\\ yearp & \\textbf{0.6822} & \\textbf{0.7239} & \\textbf{0.7572} \\\\ yeast & \\textbf{0.9733} & \\textbf{0.9789} & \\textbf{0.9900} \\\\ \\ hline \\end{tabular} } \\end{minipage} } \\end{table}"
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_27": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_27",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_27",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_27",
		"text": "\\begin{itemize}  \\item \\textbf{AUC} -- We use the logit transform : $$\\text{logit}(AUC)=\\log\\left(\\frac{AUC}{1-AUC}\\right)$$ \\item \\textbf{AP} -- Because AP does not have a constant expectation , one way to normalize AP is to compute the \\textbf{lift} which is the ratio of AP to its expectation . It is commonly assumed that this expectation is equivalent to the anomaly rate , but \\cite{exactAP} shows that while this can be a good approximation it is not exactly correct . More important it can be a bad approximation when relative frequency is low , which is the case for most of our benchmarks . We compute lift using the exact expectation . To map this ratio to all real numbers a sensible further transformation is to take the log of this lift : $$\\log(LIFT)=\\log\\left(\\frac{AP}{E[AP]}\\right)$$ \\end{itemize}"
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_33": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_33",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_33",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_33",
		"text": "An ANOVA test on each of these models provides a $t$ - test for each variable in the model and an $F$ - test on the model itself . To save space we do not report these individual values ; the results are easily summarized as \\emph{every} test has a $p$ - value well below $0.001$ ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_1": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_1",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_1",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_1",
		"text": "An anomaly detection algorithm takes as input the $N$ data points and produces as output a real - valued anomaly score for each point such that points with higher scores are believed to be more anomalous . Natural metrics of quality for anomaly predictions are the area under the ROC curve ( AUC ) and the Average Precision ( AP ; also known as the area under the precision - recall curve ) . In some applications , we are only interested in the top $K$ highest - ranked points , in which case , natural metrics are the precision and recall at $K$ . In other applications , we might choose a threshold and classify all points whose anomaly score exceeds the threshold as anomalies and all other points as nominal . In such settings , common metrics are precision , recall , and F1 ( the harmonic mean of precision and recall ) . Accuracy or error rate are typically not very useful , because in most applications the anomalies constitute a very small fraction of the data ( e.g. , from 0.01\\% to 1\\% ) . In this paper , we consider only the AUC and AP metrics ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_0": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_0",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_0",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_0",
		"text": "We study the following unsupervised anomaly detection setting . We are given a collection of $N$ data points $x_1, \\ldots, x_N$ , each a $d$ - dimensional real - valued vector . These data points are a mixture of `` nominal ' ' points and `` anomalous ' ' points . However , none of the points are labeled . The goal is to identify the anomalous points ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_32": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_32",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_32",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_32",
		"text": "First we build this model for each metric , using our discrete construction factors and our real valued transformations and compare the models . Our metric for comparison is the $\\hat{R^2}$ goodness - of - fit measure , which is inversely related to the mean squared error of the model , which is the figure of merit each of these models is trying to optimize ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_26": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_26",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_26",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_26",
		"text": "Later in this section we will to analyze our micro-experiment results with various linear models , and summarizing the means of metrics like AUC and AP which are constrained to range $[0,1]$ can be problematic , especially in the case of AP which does not have a constant expectation . For the remainder of this paper we transform both of these metrics so that they extend to the range of all real numbers in the following ways :"
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_22": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_22",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_22",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_22",
		"text": "\\begin{table}  \\resizebox{\\textwidth} {! } { \\begin{minipage} { 0.5\\ text width } \\tbl{Benchmark Failure Rate by Metric and Point Difficulty Level ( [unused10] )\\label{tbl:pdfail} } { \\begin{tabular} { | r | | c | c | c | } \\hline & \\textbf{AUC} & \\textbf{AP} & \\textbf{Either} \\\\ \\hline \\hline pd - 0 & 0.2887 & 0.3951 & 0.4328 \\\\ pd - 1 & 0.2803 & 0.3988 & 0.4268 \\\\ pd - 2 & \\textbf{0.4252} & \\textbf{0.5257} & \\textbf{0.5576} \\\\ pd - 3 & \\textbf{0.5662} & \\textbf{0.6481} & \\textbf{0.6858} \\\\ pd - 4 & \\textbf{0.7540} & \\textbf{0.8041} & \\textbf{0.8437} \\\\ \\hline \\end{tabular} } \\end{minipage} } \\end{table}"
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_36": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_36",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_36",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_36",
		"text": "To better evaluate the importance of each variable on predicting our metrics we construct simpler models that exclude one of the variables from the model and then measure the difference in $\\hat{R^2}$ measures relative to our base model . We also construct a model without all four problem dimension variables to measure the impact of all problem dimensions in aggregate . \\cref{tbl:rsq} shows these results . Boldfaced items are those with greater $\\hat{R^2}$ loss than the algorithm variable which suggests that the variable is \\emph{more important to your final outcome than your choice of algorithm is} ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_4": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_4",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_4",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_4",
		"text": "We binned this measure into five discrete levels : \\begin{itemize}  \\item \\emph{pd-0} : control group ; ( difficulty score $\\in(0,1))$ \\item \\emph{pd-1} : difficulty score $\\in(0,0.1\\overline{6})$ \\item \\emph{pd-2} : difficulty score $\\in[0.1\\overline{6},0.\\overline{3})$ \\item \\emph{pd-3} : difficulty score $\\in[0.\\overline{3},0.5)$ \\item \\emph{pd-4} : difficulty score $\\in[0.5,1)$ \\end{itemize}"
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_5": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_5",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_5",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_5",
		"text": "We propose to define semantic variation among anomalies with the following measure . The { \\ it normalized clusteredness } ( nc ) of this set of points is defined as \\[\\log\\left(\\frac{\\hat{\\sigma} ^ 2_n } { \\hat{\\sigma} ^ 2_a }\\ right ) \\ ] where $\\hat{\\sigma}^2_n$ is the sample variance of the selected normal points and $\\hat{\\sigma}^2_a$ is the sample variance of the selected anomaly points . When normalized clusteredness is less than 0 , the anomaly points exhibit greater semantic variation than the normal points . When normalized clusteredness is greater than 0 , the anomaly points are more tightly packed than the normal points ( on average ) ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_37": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_37",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_37",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_37",
		"text": "\\begin{table} \\resizebox{\\textwidth} { ! } { \\begin{minipage} { 1.15 \\ text width } \\tbl{Changes in [unused10] When Different Variables Are Missing\\label{tbl:rsq} } { \\begin{tabular} { | r | | c | c | c | c | } \\hline & \\textbf{ [unused10] } & \\textbf{ [unused10] } & \\textbf{ [unused10] } & \\textbf{ [unused10] } \\\\ \\hline \\hline All Variables & 0.5019 & -- & 0.6382 & --\\\\ w/o Algorithm & 0.4512 & 0.0507 & 0.6013 & 0.0369 \\\\ w/o Motherset & \\textbf{0.2617} & \\textbf{0.2403} & \\textbf{0.5190} & [unused10] \\\\ w/o All Problem Dimensions & \\textbf{0.3221} & \\textbf{0.1799} & \\textbf{0.2359} & \\textbf{0.4022} \\\\ -- w/o Relative Frequency & \\textbf{0.4311} & \\textbf{0.0709} & \\textbf{0.4108} & \\textbf{0.2274} \\\\ -- w/o Point Difficulty & 0.4742 & 0.0277 & 0.6264 & 0.0117 \\\\ -- w/o Clusteredness & 0.4909 & 0.0111 & \\textbf{0.6004} & \\textbf{0.0378} \\\\ -- w /o Feature Irrelevance & 0.4831 & 0.0189 & 0.6279 & 0.0103 \\\\ \\hline \\end{tabular} } \\end{minipage} } \\end{table}"
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_23": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_23",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_23",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_23",
		"text": "\\begin{table}  \\resizebox{\\textwidth} {! } { \\begin{minipage} { 0.5\\text width } \\tbl{Benchmark Failure Rate by Metric and Clustering Strategy ( [unused10] )\\label{tbl:clfail} } { \\begin{tabular} { | r | | c | c | c | } \\hline & \\textbf{AUC} & \\textbf{AP} & \\textbf{Either} \\\\ \\hline \\hline none & \\textbf{0.4189} & \\textbf{0.5201} & \\textbf{0.5479} \\\\ cluster & \\textbf{0.4431} & \\textbf{0.5891} & \\textbf{0.6036} \\\\ scatter & 0.3695 & 0.4146 & 0.4759 \\\\ \\hline \\end{tabular} } \\end{minipage} } \\end{table}"
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_35": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_35",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_35",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_35",
		"text": "\\begin{table}  \\resizebox{\\textwidth} {! } { \\begin{minipage} { 0.55\\ text width } \\tbl{Problem Dimension Coefficients by Metric\\label{tbl:basecoef} } { \\begin{tabular} { | r | | c | c | } \\hline & \\textbf{ [unused10] } & \\textbf{ [unused10] } \\\\ \\hline \\hline $\\text{logit}(\\text{relative frequency})$ & - 0.1994 & - 0.3527 \\\\ $\\text{logit}(\\text{point difficulty})$ & - 0.3209 & - 0.2014 \\\\ $\\text{clusteredness}$ & - 0.1255 & - 0.2141 \\\\ $\\log(\\text{feature irrelevance})$ & - 0.2962 & - 0.1998 \\\\ \\hline \\end{tabular} } \\end{minipage} } \\end{table}"
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_21": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_21",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_21",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_21",
		"text": "\\begin{table}  \\resizebox{\\textwidth} {! } { \\begin{minipage} { 0.5\\text width } \\tbl{Benchmark Failure Rate by Metric and Relative Frequency Level ( [unused10] )\\label{tbl:arfail} } { \\begin{tabular} { | r | | c | c | c | } \\hline & \\textbf{AUC} & \\textbf{AP} & \\textbf{Either} \\\\ \\hline \\hline rf - 0 & 0.3432 & 0.4212 & 0.4324 \\\\ rf - 1 & \\textbf{0.7286} & \\textbf{0.8464} & \\textbf{0.9081} \\\\ rf - 2 & \\textbf{0.5432} & \\textbf{0.6889} & [unused10] \\\\ rf - 3 & \\textbf{0.4395} & \\textbf{0.5786} & \\textbf{0.6395} \\\\ rf - 4 & 0.2350 & 0.3076 & 0.3234 \\\\ rf - 5 & 0.2533 & 0.3031 & 0.3139 \\\\ \\hline \\end{tabular} } \\end{minipage} } \\end{table}"
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_7": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_7",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_7",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_7",
		"text": "To simplify the process of determining how many irrelevant features are needed , we compute an estimate of how many extra features will achieve a desired average distance ratio . Note that the expected distance between two vectors ( $\\alpha$ ) whose coordinates are drawn at random ( e.g. , from the unit interval or from a standard normal Gaussian ) grows in proportion to $\\sqrt{d}$ , where $d$ is the dimensionality of the data . Hence , if a dataset already has $d$ dimensions and we want to estimate $d'$ , the number of dimensions needed to increase the average pairwise distance by a factor of $\\alpha$ , then we need $$\\hat{d'} = (\\alpha \\sqrt{d})^2$$ dimensions , where $\\alpha\\in\\{1.0,1.2,1.5,2.0\\}$ for this study ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_6": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_6",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_6",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_6",
		"text": "\\begin{itemize} \\item \\emph{nc-0} : control group ; ( clusteredness not considered ) . \\item \\emph{nc-1} : nc $< 0$ ; ( scattered anomalies ) . \\item \\emph{nc-2} : nc $> 0$ ; ( clustered anomalies ) . \\end{itemize}"
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_20": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_20",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_20",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_20",
		"text": "\\begin{table}  \\resizebox{\\textwidth} {! } { \\begin{minipage} { 0.5\\ text width } \\tbl{Benchmark Failure Rate by Metric and Motherset Origin ( [unused10] )\\label{tbl:origfail} } { \\begin{tabular} { | r | | c | c | c | } \\hline & \\textbf{AUC} & \\textbf{AP} & \\textbf{Either} \\\\ \\hline \\hline binary & 0.2490 & 0.3530 & 0.3914 \\\\ multiclass & \\textbf{0.4488} & \\textbf{0.5627} & \\textbf{0.5913} \\\\ regression & \\textbf{0.5159} & \\textbf{0.5830} & \\textbf{0.6219} \\\\ \\hline \\end{tabular} } \\end{minipage} } \\end{table}"
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_34": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_34",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_34",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_34",
		"text": "\\begin{table}  \\resizebox{\\textwidth} {! } { \\begin{minipage} { 0.5\\ text width } \\tbl{ [unused10] of Linear Regression by Metric and Variable Type\\label{tbl:facvval} } { \\begin{tabular} { | r | | c | c | } \\hline & \\textbf{ [unused10] } & \\textbf{ [unused10] } \\\\ \\hline \\hline Discrete Variables & 0.4910 & 0.6251 \\\\ Real Variables & 0.5019 & 0.6382 \\\\ \\hline \\end{tabular} } \\end{minipage} } \\end{table}"
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_53": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_53",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_53",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_53",
		"text": "As described in the main body of the paper we used a KNN approximation of the original algorithm . The only parameter in such an implementation is the choice of $k$ , which we set at 0.005 of the data ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_47": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_47",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_47",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_47",
		"text": "\\cref{fig:ar,fig:pd,fig:cl,fig:ir} and \\cref{tbl:basecoef} suggest that our defined problems dimensions all have an impact on experimental results . The reported $\\hat{R^2}$ of our mixed models in \\cref{sec:basic} suggest that choice of motherset , choice of algorithm and our proposed problem dimensions are capable of predicting experimental results with good accuracy . Based on this we are able to recommend using our methodology ( or something appropriately similar ) for controlling and measuring these problem dimensions . We encourage further work that focuses on specific contexts that can be defined by these problem dimensions , especially if it maps these contexts to real - world applications ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_46": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_46",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_46",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_46",
		"text": "\\begin{table} \\resizebox{\\textwidth} {! } { \\begin{minipage} { 0.63\\text width } \\tbl{Mean Performance by Algorithm and Metric (Normalized by a Trivial Solution)\\label{tbl:triv} } { \\begin{tabular} { | r | | c | c | } \\hline & \\textbf{Mean [unused10] } & \\textbf{Mean [unused10] } \\\\ \\hline \\hline abod & 0.0654 & 0.1193 \\\\ egmm & 0.0774 & 0.1265 \\\\ iforest & \\textbf{0.1006} & [unused10] \\\\ loda & 0.0578 & 0.1340 \\\\ lof & 0.0723 & 0.1513 \\\\ ocsvm & - 0.1004 & 0.0792 \\\\ rkde & 0.0707 & 0.1316 \\\\ svdd & - 0.1817 & - 0.5010 \\\\ \\hline \\end{tabular} } \\end{minipage} } \\end{table}"
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_52": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_52",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_52",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_52",
		"text": "We employed the \\texttt{R} package \\texttt{Rlof} available at \\url{http://cran.open-source-solution.org/web/packages/Rlof/} . We chose $k$ to be 3 \\ % of the dataset . This was the smallest value for which LOF would reliably run on all datasets ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_44": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_44",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_44",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_44",
		"text": "By eliminating benchmarks based on hypothesis testing we attempted to account for benchmarks that are too difficult or otherwise unrealistic in composition , but an additional concern of ours is that some benchmarks might be trivially easy . It is often the case in anomaly detection literature that reported results are highly accurate , such as in \\cite{loda,inne,Kriegel:2009,rajasegarar2010centered,Amer:2013} whereas the mean accuracy on our corpus of benchmarks is much lower . In particular , consider the work presented in \\cite{inne} ; the authors share the parameterization of each algorithm on each benchmark and praise the algorithm \\textbf{iNNe} for sometimes performing well with parameter $\\psi=2$ . However , an understanding of the iNNe algorithm and the implication of that parameter choice will reveal that the algorithm is doing little more than approximating the distance of each point from the mean of the data . While we acknowledge that this particular work is a smaller workshop publication , it should serve as a warning that benchmarks for which all algorithms perform well might be benchmarks that can be trivially solved and their inclusion in reported results might not be helpful ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_50": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_50",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_50",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_50",
		"text": "To reduce the computational cost of fitting , and to improve the numerical stability of the process , we first transformed each benchmark dataset via principle component analysis . We selected principle components ( in descending eigenvalue order ) to retain 95 \\ % of the variance . To generate the members of the ensemble , we varied the number of clusters $k$ by trying all values in $\\{1,2,3,4, 5, 6\\}$ . For each value of $k$ , we generated 15 GMMs by training on 15 bootstrap replicates of the data and by randomly initializing each replicate . We then computed the average out - of - bag log likelihood for each value of $k$ and discarded $k$ values whose average log likelihood was less than 0.85 times the average log likelihood of the best value of $k$ . The purpose of this was to discard GMMs that do not fit the data very well . Finally , an anomaly score is computed for each point $x$ by computing the average `` surprise ' ' , which is the average negative log probability density $\\frac{1}{L} \\sum_{\\ell=1}^L -\\log P_{\\ell}(x)$ , where $L$ is the number of fitted GMMs and $P_{\\ell}(x)$ is the density assigned by GMM $\\ell$ to data point $x$ . We found in preliminary experiments that this worked better than using the mean probability density $\\frac{1}{L} \\sum_{\\ell=1}^L P_{\\ell}(x)$ ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_51": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_51",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_51",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_51",
		"text": "We employed the \\texttt{libsvm} implementation of Chang and Lin \\cite{chang:2011} available at \\url{http://www.csie.ntu.edu.tw/~cjlin/libsvm/} . For each benchmark , we employed a Gaussian radial basis function kernel . Selection of kernel bandwidth was done using the DFN method proposed in \\cite{xiao2014} , while the parameter $\\nu$ was set to 0.03 ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_45": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_45",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_45",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_45",
		"text": "To investigate this phenomenon further , we ran a trivial algorithm against our corpus of benchmarks . The algorithm simply computes the arithmetic mean of the data and assigns an outlier score to each point based on its euclidean distance from that mean . We use the performance of this algorithm to normalize the performance of the other non-trivial algorithms . For both AUC and AP we compute the ratio of a given algorithm 's performance over the performance of the trivial algorithm . As with logit $(AUC)$ and $\\log(LIFT)$ we then take the natural log of these ratios . $$\\log\\left(\\frac{AUC_{\\text{non-trivial}}}{AUC_{\\text{trivial}}}\\right), \\log\\left(\\frac{AP_{\\text{non-trivial}}}{AP_{\\text{trivial}}}\\right) $$ In the case of AP , this is very similar to our previous transformed metric , except instead of normalizing against random expectation , we are normalizing against the performance of a trivial solution . Under this metric , achieving a perfect score on a benchmark that is also perfectly or almost - perfectly solved by a trivial solution is not given much merit , while a lower score that is a significant improvement on trivial performance is given much more credit . \\cref{tbl:triv} shows the mean performance of each algorithm under these new metrics ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_41": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_41",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_41",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_41",
		"text": "\\begin{table} \\resizebox{\\textwidth} {! } { \\begin{minipage} { 0.5\\text width } \\tbl{Mean Performance by Algorithm and Metric with Many Irrelevant Features\\label{tbl:hiir} } { \\begin{tabular} { | r | | c | c | } \\hline & \\textbf{Mean [unused10] } & \\textbf{Mean [unused10] } \\\\ \\hline \\hline abod & 0.4424 & 0.4612 \\\\ eg mm & 0.4561 & 0.5069 \\\\ iforest & \\textbf{0.8117} & [unused10] \\\\ loda & 0.5803 & 0.7722 \\\\ lof & 0.6199 & 0.7187 \\\\ ocsvm & 0.5752 & 0.8527 \\\\ rkde & 0.5477 & 0.6716 \\\\ svdd & 0.3366 & 0.3580 \\\\ \\hline \\end{tabular} } \\end{minipage} } \\end{table}"
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_55": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_55",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_55",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_55",
		"text": "The AUC or AP of a random ranking can be seen as a discrete parametric distribution with parameters $n_{\\text{norm}}$ ( number of normals ) and $n_{\\text{anom}}$ ( number of anomalies ) . The distribution is parametric because there are `` only ' ' $(n_{\\text{norm}}+n_{\\text{anom}})!$ possible rankings , meaning there are a finite number of possible AUC or AP scores for a given set of parameters ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_54": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_54",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_54",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_54",
		"text": "We implemented the algorithm as suggest by the authors of \\cite{loda} . Each projection used approximately $\\sqrt{d}$ features and a total of $3d$ projections were used , where $d$ is the number of features in the benchmark ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_40": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_40",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_40",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_40",
		"text": "\\begin{table}  \\resizebox{\\textwidth} {! } { \\begin{minipage} { 0.5\\text width } \\tbl{Mean Performance by Algorithm and Metric with No Irrelevant Features\\label{tbl:noir} } { \\begin{tabular} { | r | | c | c | } \\hline & \\textbf{Mean [unused10] } & \\textbf{Mean [unused10] } \\\\ \\hline \\hline abod & 1.3706 & [unused10] \\\\ egmm & 1.3522 & 1.2120 \\\\ iforest & 1.3145 & 1.1690 \\\\ loda & 1.1020 & 1.0235 \\\\ lof & 1.1800 & 1.0958 \\\\ ocsvm & 0.5654 & 0.9077 \\\\ rkde & \\textbf{1.4256} & 1.1747 \\\\ svdd & - 0.0118 & 0.2290 \\\\ \\hline \\end{tabular} } \\end{minipage} } \\end{table}"
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_56": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_56",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_56",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_56",
		"text": "In both cases it is possible to enumerate these scores and compute how much probability mass each score carries , and thus quantiles of these distributions can be computed . However for larger values of $n$ this becomes computationally inefficient ."
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_42": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_42",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_42",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_42",
		"text": "\\begin{table}  \\resizebox{\\textwidth} {! } { \\begin{minipage} { 0.5\\text width } \\tbl{Mean Performance by Algorithm and Metric When Clusteredness is Greater Than 0.25\\label{tbl:hicl} } { \\begin{tabular} { | r | | c | c | } \\hline & \\textbf{Mean [unused10] } & \\textbf{Mean [unused10] } \\\\ \\hline \\hline abod & \\textbf{1.0305} & [unused10] \\\\ egmm & 0.7199 & 0.4834 \\\\ iforest & 0.7405 & 0.5075 \\\\ loda & 0.5689 & 0.4225 \\\\ lof & 0.7623 & 0.5336 \\\\ ocsvm & 0.0385 & 0.2316 \\\\ rkde & 0.7179 & 0.5387 \\\\ svdd & 0.0327 & 0.0639 \\\\ \\hline \\end{tabular} } \\end{minipage} } \\end{table}"
	},
	"1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_43": {
		"id": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_43",
		"phase": "test",
		"topic": "cs.ai",
		"document": "1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem",
		"paragraph": "paragraph_43",
		"prefix": "selected/test/cs.ai-ann3/1503.01158v2.A_Meta_Analysis_of_the_Anomaly_Detection_Problem/paragraph_43",
		"text": "\\begin{table} \\resizebox{\\textwidth} {! } { \\begin{minipage} { 0.5\\text width } \\tbl{Mean Performance by Algorithm and Metric with Mothersets Selected for Dubious Reasons\\label{tbl:nefarious} } { \\begin{tabular} { | r | | c | c | } \\hline & \\textbf{Mean [unused10] } & \\textbf{Mean [unused10] } \\\\ \\hline \\hline abod & 0.6094 & 0.6071 \\\\ eg mm & 0.5826 & 0.6285 \\\\ iforest & 0.7675 & 0.8903\\\\ loda & 0.7981 & [unused10] \\\\ lof & 0.5999 & 0.7340\\\\ ocsvm & 0.5121 & 0.8080 \\\\ rkde & \\textbf{0.8554} & 0.9222\\\\ svdd & 0.1764 & 0.3164 \\\\ \\hline \\end{tabular} } \\end{minipage} } \\end{table}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_72": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_72",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_72",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_72",
		"text": "Loosening monetary policy raises inflation . Observing higher prices , customers underinfer the underlying increase in nominal marginal costs and thus perceive higher price markups . Firms respond to such perceptions by cutting their actual markups . The price markup falls by $1.4\\%$ , which raises output and employment by $0.7\\%$ . ( Output and employment respond identically because the production function is calibrated to be linear . )"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_66": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_66",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_66",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_66",
		"text": "We then simulate the dynamics of a firm 's price in response to an unexpected and permanent increase in its marginal cost ( see Appendix ~ B. 5 ) . We find that the fairness parameter $\\t$ primarily affects the level of the cost passthrough , while the inference parameter $\\g$ primarily affects its persistence . Based on the simulations , we set $\\e=2.23$ , $\\t=9$ , and $\\g=0.8$ . This calibration allows us to achieve a steady - state price markup of ~ $1.5$ , an instantaneous cost passthrough of ~ $0.4$ , and a two - year cost passthrough of ~ $0.7$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_99": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_99",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_99",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_99",
		"text": "Next , the properties indicate that $F(0)>0$ and $F'(0)$ is finite , so $\\lim_{M^p\\to 0} \\f(M^p) = 0$ . And they indicate that $F(M^h)=0$ while $M^h>0$ and $F'(M^h)<0$ , so $\\lim_{M^p\\to M^h} \\f(M^p) = +\\infty$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_159": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_159",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_159",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_159",
		"text": "\\paragraph{Proof of Lemma~\\ref{l:monetary} } The law of motion \\eqref{e:mphat} for the perceived price markup comes from \\eqref{e:mphata} . The expression of the perceived price markup as a discounted sum of past inflation rates is obtained by iterating \\eqref{e:mphata} backward ; and by noting that $\\lim_{T\\to \\infty}\\g^T \\cdot \\wh{m^p}(t-T)=0$ as $\\g\\in(0,1)$ and $\\wh{m^p}$ is bounded ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_165": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_165",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_165",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_165",
		"text": "\\paragraph{First-Order Condition with Respect to Price} The first - order condition with respect to $P(t)$ is $\\pdx{\\Lc}{P(t)}=0$ , which gives \\begin{equation*} 0=Y(t)+\\Hc(t)\\pd{Y^{d}}{P}+(1-\\g)\\Kc(t)\\frac{C^{p}(t)}{P(t)}. \\end{equation*} This equation is the same as \\eqref{e:focpj} ; therefore , it can be re-expressed as \\eqref{e:ejmj} ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_171": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_171",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_171",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_171",
		"text": "Our calibration procedure starts by initializing $\\t$ and $\\g$ to some values . Using these values and the target $\\ol{M}=1.5$ , we compute $\\e$ from \\eqref{e:mssa} . In \\eqref{e:mssa} we use \\eqref{e:phia} , which holds because the fairness function is \\eqref{e:f} , and because there is no inflation in steady state so customers are acclimated . Using the values of $\\t$ , $\\g$ , and $\\e$ , we simulate the dynamics of the cost passthrough ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_170": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_170",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_170",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_170",
		"text": "\\paragraph{Calibration Procedure} We set the shape of the fairness function to \\eqref{e:f} and the discount factor to $\\d=0.99$ . Then , using the simulations , we calibrate the three main parameters of the model : the concern for fairness , $\\t$ , the degree of underinference , $\\g$ , and the elasticity of substitution between goods , $\\e$ . Our goal is to produce an instantaneous cost passthrough of $\\b = 0.4$ , a two - year cost passthrough of $\\b =0.7$ , together with a steady - state price markup of $\\ol{M}=1.5$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_164": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_164",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_164",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_164",
		"text": "\\paragraph{First-Order Condition with Respect to Output} The first - order condition with respect to $Y(t)$ is $\\pdx{\\Lc}{Y(t)}=0$ . It yields \\begin{equation*} \\Hc(t)=P(t) \\bs{1-\\frac{C(t)}{P(t)}}, \\end{equation*} which is the same equation as \\eqref{e:hj2} and thus can be rewritten as \\eqref{e:hj} ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_158": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_158",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_158",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_158",
		"text": "We now bring these results together . Equation \\eqref{e:ema} can be written $LHS= \\E[t]{RHS}$ . This equation also holds in steady state so $\\ol{LHS} =\\ol{RHS}$ . Combining these two equations , we infer \\begin{equation*} \\exp{\\ln(LHS)-\\ln(\\ol{LHS})} = \\E[t]{\\exp{\\ln(RHS)-\\ln(\\ol{RHS})}}. \\end{equation*} Around $x=0$ , we have $\\exp(x) = 1 + x$ . Applying this approximation to both sides of the previous equation , we find \\begin{equation*} 1+\\ln(LHS)-\\ln(\\ol{LHS}) = 1+ \\E[t]{\\ln(RHS)-\\ln(\\ol{RHS})}. \\end{equation*} We then use the results in \\eqref{e:lhs} and \\eqref{e:rhs} : \\begin{equation*} \\O_{1} \\wh{m}(t) + \\O_{0} \\wh{m^p}(t) = \\O_{3} \\cdot \\bs{\\O_{1} \\E[t]{\\wh{m}(t+1)} + \\O_{2} \\E[t]{\\wh{m^p}(t+1)}}. \\end{equation*} We divide this equation by $\\O_{0}$ ; insert the values of $\\wh{m}(t)$ and $\\wh{m}(t+1)$ given by \\eqref{e:mhat} ; and insert the value of $\\wh{m^p}(t+1)$ given by \\eqref{e:mphata} . We obtain \\begin{equation} -\\frac{(1+\\eta)\\O_{1}}{\\O_{0}} \\wh{n}(t) + \\wh{m^p}(t) = -\\frac{(1+\\eta)\\O_{3}\\O_{1}}{\\O_{0}} \\E[t]{\\wh{n}(t+1)} + \\frac{\\g\\O_{3}\\O_{2}}{\\O_{0}} \\E[t]{\\wh{\\pi}(t+1)+\\wh{m^p}(t)}. \\label{e:phillips0}\\end{equation} Using \\eqref{e:omega0} , \\eqref{e:omega1} , \\eqref{e:omega2} , and \\eqref{e:omega3} , we find that \\begin{align*} \\frac{(1+\\eta)\\O_{1} } { \\O_{0} } &= ( 1 + \\eta) \\frac{\\e+(\\e-1) \\g \\ol{\\f} } { \\g \\ol{\\f}  \\ol{\\s} } \\bs{1+\\frac{(1-\\d)\\g} { 1 - \\d\\g} \\ol{\\f} } \\ equiv \\l_1 \\\\ \\frac{(1+\\eta)\\O_{3}  \\O_{1} } { \\O_{0} } & = ( 1 + \\eta) \\d \\frac{\\e+(\\e-1)\\ol{\\f} } { \\ol{\\f}  \\ol{\\s} } \\bs{1+\\frac{(1-\\d)\\g} { 1 - \\d\\g} \\ol{\\f} } \\ equiv \\l_2 \\\\ \\frac{\\g\\O_{3}  \\O_{2} } { \\O_{0} } &= \\d\\g^2 \\frac{\\e +(\\e-1)\\ol{\\f} } { \\e+(\\e-1) \\g \\ol{\\f} } \\cdot \\frac{(\\e-1) \\ol{\\f}  \\ol{\\s} } { \\e+(\\e-1) \\ol{\\f} } \\cdot \\frac{\\e+(\\e-1) \\g \\ol{\\f} } { ( \\e-1)\\g\\ol{\\f}  \\ol{\\s} } = \\ d\\g . \\end{align*} Bringing these results into \\eqref{e:phillips0} , we obtain the short - run Phillip s curve : \\begin{equation} (1-\\d\\g) \\wh{m^p}(t) - \\l_1 \\wh{n}(t) = \\d \\g \\E[t]{\\wh{\\pi}(t+1)} - \\l_2 \\E[t]{\\wh{n}(t+1)}. \\label{e:phillipsa}\\end{equation}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_98": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_98",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_98",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_98",
		"text": "The properties also indicate that $F>0$ is decreasing in $M^p$ , and that $F'<0$ is decreasing in $M^p$ ( as $F$ is concave in $M^p$ ) . Thus , both $1/F>0$ and $-F'>0$ are increasing in $M^p$ , which implies that $\\f$ is strictly increasing in $M^p$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_67": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_67",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_67",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_67",
		"text": "\\paragraph{Other Parameters} We set the labor - supply parameter to $\\eta=1.1$ , which gives a Frisch elasticity of labor supply of $1/1.1=0.9$ . This value is the median microestimate of the Frisch elasticity for aggregate hours \\cp[Table~2]{CGM13} . We then set the quarterly discount factor to $\\d=0.99$ , giving an annual rate of return on bonds of ~ $4\\%$ . We set the production - function parameter to $\\a=1$ . This calibration guarantees that the labor share , which equals $\\a/\\ol{M}$ in steady state , takes its conventional value of ~ $2/3$ . Last , we calibrate the monetary - policy parameter to $\\p=1.5$ , which is consistent with observed variations in the federal funds rate \\cp[p.~52]{G08} ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_73": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_73",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_73",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_73",
		"text": "\\begin{table} [ t ] \\caption{Opinions about price movements in Japan, 2001--2017}  \\footnotesize\\begin{tabular*} { \\textwidth}{@{\\extracolsep{\\fill} } lcc cc }\\ toprule & & \\multicolumn{3} { c } { Opinion about perceived price change } \\\\ \\cmidrule{3-5} Perceived price change & Respondents & Favorable & Neutral & Unfavorable \\\\ \\ midrule Prices have gone up & 68,491 & $2.5\\%$ & $13.0\\%$ & $83.7\\%$ \\\\ Prices have gone down & 18,257 & $43.0\\%$ & $34.2\\%$ & $21.9\\%$ \\\\ \\bottomrule\\end{tabular*} [unused10] . } \\label{t:japan}  \\end{table}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_59": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_59",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_59",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_59",
		"text": "As in the monopoly model , fairness affects pricing through the price elasticity of demand $E$ , which satisfies ~ \\eqref{e:e2} . Unlike in the monopoly model , however , the profit - maximizing markup is not $E/(E-1)$ because $E$ does not capture the effect of the current price on future beliefs and thus future demands . Instead , in equilibrium , firms set their price markup $M$ such that \\begin{equation} \\frac{M(t)-1}{M(t)} E(t) = 1-\\d\\g+\\d\\E[t]{\\frac{M(t+1)-1}{M(t+1)} \\bs{E(t+1)-(1-\\g)\\e}}. \\label{e:em}\\end{equation} The gap between $M(t)$ and $E(t)/[E(t)-1]$ reflects how much today 's price affects future perceived marginal costs , demands , and profits . Conversely , if firms do not care about the future ( $\\d=0$ ) , the equation reduces to $M(t) = E(t)/[E(t)-1]$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_65": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_65",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_65",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_65",
		"text": "Third , \\ct[Table~7.4]{BG14} provide estimates of the long - run exchange - rate passthrough for the United States and seven other countries . The exchange - rate passthrough measures the response of import prices to exchange - rate shocks . Its level may not reflect that of the cost passthrough , because marginal costs may not vary one - for - one with exchange rates , but there is no reason for the two passthroughs to have different dynamics \\cp{AIK14} . The immediate exchange - rate passthrough is estimated at $0.4$ , and the two - year exchange - rate passthrough at ~ $0.7$ . Based on these dynamics , and the fact that the immediate cost passthrough is also ~ $0.4$ , we target a two - year cost passthrough of ~ $0.7$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_71": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_71",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_71",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_71",
		"text": "Figure ~ \\ref{f:monetary} depicts the dynamical response to the expansionary monetary shock . The exogenous component of monetary policy and inflation rate are expressed as deviations from steady - state values , measured in percentage points and annualized ( by multiplying by four the variables $\\wh{i_0}(t)$ and $\\wh{\\pi}(t)$ ) ; all other variables are expressed as percentage deviations from steady - state values ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_172": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_172",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_172",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_172",
		"text": "We repeat the simulation for different values of $\\t$ and $\\g$ until we obtain a cost passthrough of $0.4$ on impact and $0.7$ after two years . We reach these targets with $\\t=9$ and $\\g=0.8$ . The corresponding value of $\\e$ is $2.23$ . The corresponding passthrough dynamics are shown in Figure ~ \\ref{f:calibration} ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_166": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_166",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_166",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_166",
		"text": "\\paragraph{First-Order Condition with Respect to Perceived Marginal Cost} Finally , the first - order condition with respect to $C^{p}(t)$ is $\\pdx{\\Lc}{C^p(t)}=0$ , which yields \\begin{equation*} 0 =\\d \\E[t]{\\Hc(t+1) \\pd{Y^{d}}{C^{p}} +\\g \\Kc(t+1) \\frac{C^{p}(t+1)}{C^{p}(t)}} -\\Kc(t). \\end{equation*} Using the elasticity given by \\eqref{e:ydc} , we get \\begin{equation*} \\Kc(t) = \\d \\E[t]{\\Hc(t+1) \\frac{Y(t+1)}{C^{p}(t)} \\bs{E(M^{p}(t+1))-\\e} +\\g \\Kc(t+1) \\frac{C^{p}(t+1)}{C^{p}(t)}}. \\end{equation*} Next we multiply the equation by $C^p(t)/[Y(t)P(t)]$ , and we insert the perceived price markups $M^p(t) = P(t)/C^{p}(t)$ and $M^p(t+1) = P(t+1)/C^{p}(t+1)$ . We get \\begin{equation*} \\frac{\\Kc(t)}{Y(t) M^{p}(t)}=\\d \\E[t]{\\frac{Y(t+1) P(t+1)}{Y(t) P(t)}\\bc{\\frac{\\Hc(t+1)}{P(t+1)} \\bs{E(M^{p}(t+1))-\\e} +\\g\\frac{\\Kc(t+1)}{Y(t+1)M^{p}(t+1)}}}. \\end{equation*} To conclude , we multiply the equation by $(1-\\g)$ , eliminate $\\Hc(t+1)$ using \\eqref{e:hj} , and eliminate $\\Kc(t)$ and $\\Kc(t+1)$ using \\eqref{e:ejmj} . This gives the following pricing equation : \\begin{equation}\\medmuskip=1mu\\thickmuskip=2mu \\frac{M(t)-1}{M(t)} E(M^{p}(t))=1+\\d \\E[t]{\\frac{Y(t+1) P(t+1)}{Y(t)P(t)}\\bc{\\frac{M(t+1)-1}{M(t+1)}\\bs{E(M^{p}(t+1))-(1-\\g)\\e}-\\g}}. \\label{e:emjc}\\end{equation} In steady state , this equation becomes \\eqref{e:emss1} and can therefore be written as \\eqref{e:mssa} ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_167": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_167",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_167",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_167",
		"text": "\\paragraph{Firm Pricing} The firm 's pricing is described by four variables : the price $P(t)$ , markup $M(t)$ , output $Y(t)$ , and perceived markup $M^p(t)$ . These four variables are determined by four equations : the pricing equation ~ \\eqref{e:emjc} , the definition of the markup $M(t) = P(t)/C(t)$ , the demand curve ~ \\eqref{e:ydjc} , and the perceived markup 's law of motion ~ \\eqref{e:mpt} ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_173": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_173",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_173",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_173",
		"text": "The short - run Phillips curve is given by \\begin{equation*} \\wh{\\pi}(t)=\\d \\E[t]{\\wh{\\pi}(t+1)} + \\k \\wh{n}(t), \\end{equation*} where \\begin{equation*} \\k \\equiv (1+\\eta) \\cdot \\frac{(1-\\x)(1-\\d\\x)}{\\x} \\cdot \\frac{\\a}{\\a+\\bp{1-\\a} \\e}, \\end{equation*} and $\\x$ is the fraction of firms keeping their prices unchanged each period . This Phillips curve is obtained from ( 21 ) in \\ct[Chapter~3]{G08} , by using logarithmic consumption utility , and by replacing the output gap by $\\a \\wh{n}(t)$ . \\footnote{The output gap is the logarithmic difference between the actual and the natural level of output. The natural levels of output and employment are reached when prices are flexible, so when the price markup is [unused10] . Since [unused10] is also the steady-state price markup, we infer from \\eqref{e:na} that the natural and steady - state levels of employment are equal . Hence , \\eqref{e:y} implies that the natural level of output is $Y^n(t)= A(t) \\ol{N}^{\\a}$ . Consequently the output gap is $\\ln(Y(t))- \\ln(Y^n(t))= \\a [\\ln(N(t))-\\ln(\\ol{N})] = \\a\\wh{n}(t)$ . }"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_70": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_70",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_70",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_70",
		"text": "We assume that the exogenous component $i_0(t)$ of the monetary - policy rule \\eqref{e:taylor} follows an AR ( 1 ) process such that \\begin{equation*} \\wh{i_0}(t)=\\m^i \\cdot \\wh{i_0}(t-1) - \\z^i(t), \\end{equation*} where the disturbance $\\z^i(t)$ follows a white - noise process with mean zero , and $\\m^i\\in(0,1)$ governs the persistence of shocks . We set $\\m^i = 0.75$ , which corresponds to moderate persistence ( \\inp[p.~52]{G08} ; \\inp[p.~26]{G10} ) . We simulate the response to an initial disturbance of $\\z^i(0) = 0.25\\%$ , which is an expansionary monetary shock . Without any inflation response , this shock would reduce the annualized interest rate by 1 percentage point ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_64": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_64",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_64",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_64",
		"text": "Second , in the United States , Sweden , India , and Mexico , the short - run cost passthrough is estimated between $0.2$ and $0.7$ , with an average value of ~ $0.4$ ( Section ~ \\ref{s:subproportional} ) . Hence , we target a short - run cost passthrough of ~ $0.4$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_58": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_58",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_58",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_58",
		"text": "The demand for good ~ $j$ from all households is \\begin{equation*} Y^{d}\\of{t,P_{j}(t),C_{j}^{p}(t-1)} = Z(t) \\bs{\\frac{P_{j}(t)}{X(t)}}^{-\\e} F\\of{\\bp{\\frac{\\e}{\\e-1}}^{1-\\g}\\bs{\\frac{P_{j}(t)}{C_{j}^{p}(t-1)}}^{\\g}}^{\\e-1}, \\end{equation*} where $Z(t) = \\int_0^1 Z_{k}(t)\\,dk$ describes the level of aggregate demand . The price of good ~ $j$ appears twice in the demand curve : as part of the relative price $P_j/X$ ; and as part of the fairness factor $F$ . This second element leads to unconventional pricing ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_60": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_60",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_60",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_60",
		"text": "\\paragraph{Fairness Function} We set the shape of the fairness function $F$ to \\eqref{e:f} . This simple functional form has two advantages . First , it introduces only one new parameter , $\\t>0$ , which governs the concern for fairness . Second , it produces a fairness factor equal to one at the zero - inflation steady state . Indeed , in such steady state , the perceived price markup is $\\ol{M^p}=\\ol{P}/\\ol{C^p}=\\e/(\\e-1)$ , as shown by \\eqref{e:cpj} , and so the fairness factor is $\\ol{F}=1$ . Thus , with no trend inflation , customers acclimate and are neither happy nor unhappy about markups ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_74": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_74",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_74",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_74",
		"text": "In fact the response of output to a monetary shock is broadly the same in the model as in US data . First , the shape of the response is similar , as output is estimated to respond to monetary shocks in a hump - shaped fashion \\cp[Figures~1--4]{R15} . Second , the amplitude of the response is comparable . After a one - percentage - point decrease of the nominal interest rate , the literature estimates that output increases between $0.6\\%$ and $5\\%$ , with a median value of $1.6\\%$ \\cp[Table~1]{R15} ; and using a range of methods and samples , \\ct[Table~2]{R15} estimates that output increases between $0.2\\%$ and $2.2\\%$ , with a median value of $0.8\\%$ . In our simulation , output rises by $0.7\\%$ when the exogenous component of monetary policy decreases by ~ 1 percentage point --- close to Ramey 's median estimate ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_48": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_48",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_48",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_48",
		"text": "An amount $Y_{jk}(t)$ of good ~ $j$ bought by household ~ $k$ at a unit price $P_{j}(t)$ yields a fairness - adjusted consumption \\begin{equation*} Z_{jk}(t)= F_{j}(M^{p}_{j}(P_{j}(t))) \\cdot Y_{jk}(t). \\end{equation*} Household ~ $k$ 's fairness - adjusted consumption of the various goods aggregates into a consumption index \\begin{equation*} Z_{k}(t) = \\bs{\\int_{0}^{1} Z_{jk}(t)^{(\\e-1)/\\e}\\,dj}^{\\e/(\\e-1)}, \\end{equation*} where $\\e>1$ is the elasticity of substitution between different goods . The price of one unit of the consumption index at time ~ $t$ is given by the price index \\begin{equation*} X(t)=\\bc{\\int_0^1\\bs{\\frac{P_{j}(t)}{F_{j}(M^{p}_{j}(P_{j}(t)))}}^{1-\\e}\\,dj}^{1/(1-\\e)}. \\end{equation*}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_163": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_163",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_163",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_163",
		"text": "To solve the firm 's problem , we set up the Lagrangian : \\begin{align*}  \\Lc& =\\E[0]\\sum_{t=0} ^ { \\infty}\\d^t \\bigg\\{ \\bs{P(t) - C(t)} Y ( t ) \\\\ & + \\Hc(t) \\bs{Y^{d} ( P ( t ) , C ^ { p } ( t - 1 ) ) - Y ( t ) } \\\\ &+ \\Kc(t) \\bs{\\bs{C^{p} ( t - 1 ) }^{ [unused10] { \\e} P(t)}^{1-\\g} - C ^{ p } ( t ) }\\ bigg \\ } , \\end{align*} where $\\Hc(t)$ is the Lagrange multiplier on the demand constraint in period ~ $t$ , and $\\Kc(t)$ is the Lagrange multiplier on the perceived marginal cost 's law of motion in period ~ $t$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_162": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_162",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_162",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_162",
		"text": "\\paragraph{Firm Problem} This is a simplified version of the New Keynesian firm problem , which abstracts from hiring decisions . The firm chooses price $P(t)$ and output $Y(t)$ to maximize the expected present - discounted value of profits \\begin{equation*} \\E[0] \\sum_{t=0}^{\\infty}\\d^t \\bs{P(t) - C(t)} Y(t), \\end{equation*} subject to the demand \\begin{equation} Y^{d}(P(t),C^{p}(t-1)) = P(t)^{-\\e} F\\of{\\bp{\\frac{\\e}{\\e-1}}^{1-\\g}\\bs{\\frac{P(t)}{C^{p}(t-1)}}^{\\g}}^{\\e-1} \\label{e:ydjc}\\end{equation} and to the law of motion \\eqref{e:cpj} for the perceived marginal cost $C^{p}(t)$ . The nominal marginal cost $C(t)$ is exogenous and stochastic ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_49": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_49",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_49",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_49",
		"text": "\\paragraph{Households} Household ~ $k$ derives utility from consuming goods and disutility from working . Its expected lifetime utility is \\begin{equation*} \\E[0] \\sum_{t=0}^{\\infty}\\d^{t} \\bs{\\ln(Z_{k}(t))-\\frac{N_{k}(t)^{1+\\eta}}{1+\\eta}}, \\end{equation*} where $\\E[t]$ is the mathematical expectation conditional on time - $t$ information , $\\d\\in(0,1)$ is the discount factor , $N_{k}(t)$ is its labor supply , and $\\eta > 0$ is the inverse of the Frisch elasticity of labor supply ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_75": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_75",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_75",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_75",
		"text": "Third , the textbook model cannot produce the hump - shaped response of output observed in US data and predicted by the fairness model , since it does not include any backward - looking element . The fairness model , by contrast , includes a backward - looking element in the form of the perceived price markup $\\wh{m^p}(t)$ , which enters the Phillips curve \\eqref{e:phillips} and depends on the past via \\eqref{e:mphat} . It is well understood that hump - shaped impulse responses can be obtained by inserting backward - looking elements --- for instance , by assuming that consumers form habits \\cp{F00,CEE05} . Under that assumption , consumers ' behavior depends on their past consumption , which then enters the IS curve and generates hump - shaped responses ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_61": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_61",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_61",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_61",
		"text": "\\begin{table} [ t ] \\caption{Parameter values in simulations}  \\footnotesize\\begin{tabular*} { \\textwidth}{@{\\extracolsep{\\fill} } lll }\\ toprule Value & Description & Source or target \\\\ \\ midrule [unused10] {c } { A . Common parameters }\\\\ $\\d=0.99$ & Quarterly discount factor & Annual rate of return $=4\\%$ \\\\ $\\a = 1$ & Shape of production function & Labor share [unused10] \\\\ $\\eta=1.1$ & Inverse of Frisch elasticity of labor supply & [unused10] \\\\ $\\p=1.5$ & Response of nominal interest rate to inflation & \\ct[p.~52]{G08} \\\\ $\\m^i=0.75$ & Persistence of monetary shock & \\ct[p.~52]{G08} , \\ct[p.~26]{G10} \\\\ $\\m^a=0.9$ & Persistence of technology shock & [unused10] \\\\ \\ midrule \\multicolumn{3} {c } { B . Parameters of the New Keynesian model with fairness }\\\\ $\\e=2.23$ & Elasticity of substitution across goods & Steady - state price markup [unused10] \\\\ $\\t=9$ & Fairness concern & Instantaneous cost passthrough [unused10] \\\\ $\\g=0.8$ & Degree of underinference & Two - year cost passthrough [unused10]  \\\\ \\ midrule \\multicolumn{3} {c } { C . Parameters of the textbook New Keynesian model }\\\\ $\\e=3$ & Elasticity of substitution across goods & Steady - state price markup [unused10] \\\\ $\\x=0.67$ & Share of firms keeping price unchanged & Average price duration $=3$ quarters \\\\ \\bottomrule\\end{tabular*} [unused10] .} \\label{t:calibration}  \\end{table}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_77": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_77",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_77",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_77",
		"text": "\\paragraph{Simulation Results} We simulate the dynamical response of our calibrated model to an unexpected and transitory technology shock , once again around the zero - inflation steady state . We assume that the logarithm of technology $A(t)$ in the production function \\eqref{e:yj} follows an AR ( 1 ) process such that \\begin{equation*} \\wh{a}(t)=\\m^a \\cdot \\wh{a}(t-1)+ \\z^a(t), \\end{equation*} where the disturbance $\\z^a(t)$ follows a white - noise process with mean zero , and $\\m^a\\in(0,1)$ governs the persistence of shocks . We set $\\m^a = 0.9$ , which is typical \\cp[p.~55]{G08} . We simulate the response to an initial disturbance of $\\z^a(0) = 1\\%$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_63": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_63",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_63",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_63",
		"text": "First , using firm - level data , \\ct[p.~575]{DEG20} estimate price markups in the United States . They find that the average markup across the US economy hovers between $1.2$ and $1.3$ in the 1955 -- 1980 period , rises from $1.2$ in 1980 to $1.5$ in 2000 , remains around $1.5$ until 2014 , before spiking to $1.6$ in 2016 . As the markup averages $1.5$ between 2000 and 2016 , we adopt this value as a target . \\footnote{The aggregate markup computed by \\ct{DEG20} is commensurate to markups measured in specific industries and goods in the United States . In the automobile industry , \\ct[p.~882]{BLP95} estimate that on average $(P-C)/P = 0.239$ , which translates into a markup of $M=P/C = 1/(1-0.239) = 1.3$ . In the ready - to - eat cereal industry , \\ct[Table~8]{N01} finds that a median estimate of $(P-C)/P$ is $0.372$ , which translates into a markup of $M=P/C = 1/(1-0.372) = 1.6$ . In the coffee industry , \\ct[Table~6]{NZ10} also estimate a markup of $1.6$ . For most national - brand items retailed in supermarkets , \\ct[p.~166]{BBD03} discover that markups range between $1.4$ and $2.1$ . Finally , earlier work surveyed by \\ct[pp.~260--267]{RW95} finds similar markups : between $1.2$ and $1.7$ in the industrial - organization literature , and around $2$ in the marketing literature . }"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_88": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_88",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_88",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_88",
		"text": "\\begin{figure} [ p ] \\includegraphics[scale=0.3,page=13]{\\pdf}  \\includegraphics[scale=0.3,page=14]{\\pdf}  \\caption{Long-run Phillips curves for various degrees of acclimation}  \\note{The top panel gives the relationship between steady-state inflation rate and steady-state price markup. The bottom panel gives the relationship between steady-state inflation rate and steady-state employment. In both panels, inflation is measured as an annual rate. In the bottom panel, employment is measured as a percentage deviation from employment in the zero-inflation steady state. These long-run Phillips curve are constructed using the expressions in Proposition~\\ref{p:longrun} under the calibration in Table ~ \\ref{t:calibration} , for various degrees of acclimation : $\\c=0$ ( no acclimation ) , $\\c = 0.3$ , $\\c = 0.7$ , and $\\c=1$ ( full acclimation ) . } \\label{f:longrun}  \\end{figure}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_160": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_160",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_160",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_160",
		"text": "We first combine \\eqref{e:mphata} , \\eqref{e:is} , and \\eqref{e:phillipsa} into a linear dynamical system : \\begin{equation*} \\bs{\\begin{array}{ccc} \\g & \\g & 0\\\\ 0 & \\p & \\a \\\\ 0 & 0 & \\l_1 \\\\ \\end{array}} \\bs{\\begin{array}{c} \\wh{m^p}(t-1)\\\\ \\wh{\\pi}(t)\\\\ \\wh{n}(t)\\\\ \\end{array}} = \\bs{\\begin{array}{ccc} 1 & 0 & 0\\\\ 0 & 1 & \\a \\\\ 1-\\d\\g & -\\d\\g & \\l_2\\\\ \\end{array}} \\bs{\\begin{array}{c} \\wh{m^p}(t)\\\\ \\E[t]{\\wh{\\pi}(t+1)}\\\\ \\E[t]{\\wh{n}(t+1)}\\\\ \\end{array}}- \\bs{\\begin{array}{c} 0\\\\ 1\\\\ 0\\\\ \\end{array}} \\o(t), \\end{equation*} where \\begin{equation*} \\o(t) = \\wh{i_0}(t)+\\wh{a}(t) - \\E[t]{\\wh{a}(t+1)} \\end{equation*} is an exogenous shock realized at time ~ $t$ . The inverse of the matrix on the right - hand side is \\begin{equation*} \\bs{\\begin{array}{ccc} 1 & 0 & 0\\\\ 0 & 1 & \\a \\\\ 1-\\d\\g & -\\d\\g & \\l_2\\\\ \\end{array}}^{-1} = \\bs{\\begin{array}{ccc} 1 & 0 & 0\\\\ \\frac{(1-\\d\\g)\\a}{\\l_2 + \\a \\d \\g} & \\frac{\\l_2}{\\l_2 + \\a \\d \\g} & \\frac{-\\a}{\\l_2 + \\a \\d \\g}\\\\ \\frac{\\d\\g-1}{\\l_2 + \\a \\d \\g} & \\frac{\\d \\g}{\\l_2 + \\a \\d \\g} & \\frac{1}{\\l_2 + \\a \\d \\g}\\\\ \\end{array}}. \\end{equation*} Premultiplying the dynamical system by the inverse matrix , we obtain the Blanchard - Kahn form of the system : \\begin{equation*} \\bs{\\begin{array}{c} \\wh{m^p}(t)\\\\ \\E[t]{\\wh{\\pi}(t+1)}\\\\ \\E[t]{\\wh{n}(t+1)}\\\\ \\end{array}} = \\bs{\\begin{array}{ccc} \\g & \\g & 0\\\\ \\frac{ (1 - \\d \\g )\\a \\g}{\\l_2 + \\a \\d \\g} & \\frac{\\l_2 \\p + \\a \\g (1- \\d \\g)}{\\l_2 + \\a \\d \\g} & \\frac{(\\l_2-\\l_1) \\a}{\\l_2 + \\a \\d \\g}\\\\ \\frac{-(1-\\d \\g)\\g }{\\l_2 + \\a \\d \\g} & \\frac{\\bs{\\d\\p+\\d\\g- 1} \\g}{\\l_2 + \\a \\d \\g} & \\frac{\\l_1 + \\a \\d \\g}{\\l_2 + \\a \\d \\g}\\\\ \\end{array}} \\bs{\\begin{array}{c} \\wh{m^p}(t-1)\\\\ \\wh{\\pi}(t)\\\\ \\wh{n}(t)\\\\ \\end{array}} + \\bs{\\begin{array}{c} 0\\\\ \\frac{\\l_2}{\\l_2 + \\a \\d \\g}\\\\ \\frac{\\d \\g}{\\l_2 + \\a \\d \\g}\\\\ \\end{array}} \\o(t). \\end{equation*} This dynamical system determines perceived price markup $\\wh{m^p}(t)$ , inflation $\\wh{\\pi}(t)$ , and employment $\\wh{n}(t)$ . All the other variables directly follow ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_174": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_174",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_174",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_174",
		"text": "The IS equation and short - run Phillips curve jointly determine employment $\\wh{n}(t)$ and inflation $\\wh{\\pi}(t)$ . The other variables directly follow from $\\wh{n}(t)$ and $\\wh{\\pi}(t)$ . The nominal interest rate $\\wh{i}(t)$ is given by ~ \\eqref{e:ihat} . Output $\\wh{y}(t)$ is given by ~ \\eqref{e:yhat} . The price markup $\\wh{m}(t)$ is given by ~ \\eqref{e:mhat} . Since households observe both prices and costs , perceived and actual price markups are equal : $\\wh{m^p}(t) = \\wh{m}(t)$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_148": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_148",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_148",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_148",
		"text": "Third , from the expression of steady - state employment $\\ol{N}$ in Proposition ~ \\ref{p:longrun} , we learn that \\begin{equation*} \\od{\\ln(\\ol{N})}{\\ol{\\pi}} = \\frac{-1}{1+\\eta}\\cdot\\odl{\\ol{M}}{\\ol{\\f}}\\cdot\\od{\\ln(\\ol{\\f})}{\\ol{\\pi}}. \\end{equation*} Using \\eqref{e:dphi} and \\eqref{e:dm2} , we therefore find \\begin{equation*} \\od{\\ln(\\ol{N})}{\\ol{\\pi}} = \\frac{1-\\d}{1+\\eta}\\cdot\\frac{\\t}{1+\\frac{(1-\\d)\\g}{1-\\d\\g}\\t}\\cdot \\frac{1}{\\bs{1+\\frac{(1-\\d)\\g}{1-\\d\\g}\\t}\\e-1}\\cdot \\frac{\\g^2}{(1-\\g)(1-\\d\\g)} \\cdot\\frac{\\bs{1+(1-\\c)\\t}\\e-1}{\\e-1}. \\end{equation*} Inverting this equation , we obtain the slope of the long - run Phillips curve : \\begin{equation} \\od{\\ol{\\pi}}{\\ln(\\ol{N})} = \\frac{1+\\eta}{1-\\d}\\cdot \\frac{(1-\\g)(1-\\d\\g)}{\\g^2}\\cdot \\frac{\\e-1}{\\t} \\cdot \\frac{\\bs{1+\\frac{(1-\\d)\\g}{1-\\d\\g}\\t}\\bs{\\bp{1+\\frac{(1-\\d)\\g}{1-\\d\\g}\\t}\\e-1}}{\\bs{1+(1-\\c)\\t}\\e-1}. \\label{e:dpi}\\end{equation}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_149": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_149",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_149",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_149",
		"text": "We now derive comparative statics on the slope of the long - run Phillips curve . We repeatedly use the assumptions that $\\d\\in(0,1)$ , $\\eta>0$ , $\\g\\in(0,1)$ , $\\t>0$ , $\\e>1$ , and $\\c\\in[0,1]$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_161": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_161",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_161",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_161",
		"text": "Under the calibration in Table ~ \\ref{t:calibration} , the Blanchard - Kahn conditions are satisfied , so the equilibrium exists and is determinate . Indeed , under such calibration , the eigenvalues of the matrix in the Blanchard - Kahn system are $0.30$ , $1.02+0.03i$ , and $1.02-0.03i$ : one eigenvalue is within the unit circle , and two are outside the unit circle . Further , the dynamical system has one predetermined variable at time ~ $t$ ( $\\wh{m^p}(t-1)$ ) and two nonpredetermined variables ( $\\wh{n}(t)$ and $\\wh{\\pi}(t)$ ) . As the number of eigenvalues outside the unit circle matches the number of nonpredetermined variables , the solution to the dynamical system exists and is unique \\cp[Proposition~1]{BK80} ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_89": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_89",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_89",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_89",
		"text": "With full acclimation ( $\\c=1$ ) , the Phillips curve is almost vertical , so in the long run inflation barely affects price markup and employment . For instance , increasing the inflation rate from 0\\% to 1\\% only raises employment by $0.06\\%$ . With partial acclimation , the Phillips curve becomes flatter . With an acclimation of $\\c=0.7$ , the same increase in inflation raises employment by $0.4\\%$ ; and with a lower acclimation of $\\c=0.3$ , it raises employment by $0.8\\%$ . Finally , with no acclimation ( $\\c=0$ ) , the Phillips curve is even flatter , and inflation has a larger effect on price markup and employment . Then , increasing inflation from 0\\% to 1\\% raises employment by $1.2\\%$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_62": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_62",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_62",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_62",
		"text": "\\paragraph{Fairness-Related Parameters} We then calibrate the three parameters central to our theory : the fairness parameter $\\t$ , the inference parameter $\\g$ , and the elasticity of substitution across goods $\\e$ . These parameters jointly determine the average value of the price markup and its response to shocks --- which determines the cost passthrough . Hence , for the calibration , we match evidence on price markups and cost passthroughs . We target three empirical moments : average price markup , short - run cost passthrough , and long - run cost passthrough ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_76": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_76",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_76",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_76",
		"text": "\\begin{figure} [ p ] [unused10] \\ h fill [unused10] \\\\ [unused10] \\ h fill [unused10] \\\\ [unused10] \\h fill [unused10] \\\\ \\caption{Effects of a positive technology shock} [unused10] .} \\label{f:technology}  \\end{figure}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_39": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_39",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_39",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_39",
		"text": "\\begin{proposition} \\label{p:subproportional} When customers care about fairness and update subproportionally , the monopoly 's markup $M$ is implicitly defined by \\begin{equation} M=1+\\frac{1}{\\e-1}\\cdot \\frac{1}{1+\\g \\f(M^p(M \\cdot C))}, \\label{e:m}\\end{equation} which implies that $M \\in (1,\\e/(\\e-1))$ . Furthermore , the cost passthrough is given by \\begin{equation*} \\b=1\\bigg/\\bc{1+\\frac{\\g^{2}\\f \\s}{\\bp{1+\\g \\f} \\bs{\\e+(\\e-1) \\g\\f}}}, \\end{equation*} which implies that $\\b\\in(0,1)$ . Hence , the markup is lower than without fairness concerns or with rational inference ; and unlike without fairness concerns or with rational inference , the cost passthrough is incomplete . \\end{proposition}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_11": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_11",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_11",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_11",
		"text": "We begin by determining customers ' demand for the monopoly good . The customer chooses purchases $Y$ to maximize utility \\begin{equation*} \\frac{\\e}{\\e-1} \\bp{F \\cdot Y}^{(\\e-1)/\\e} + W - P \\cdot Y. \\end{equation*} The maximum of the customer 's utility function is given by the following first - order condition : \\begin{equation*} F^{(\\e-1)/\\e} \\cdot Y^{-1/\\e} = P. \\end{equation*} This first - order condition yields the demand curve \\begin{equation} Y^{d}(P)= P^{-\\e} \\cdot F(M^{p}(P))^{\\e-1}. \\label{e:yd}\\end{equation} The price affects demand through two channels : the typical substitution effect , captured by $P^{-\\e}$ ; and the fairness channel , captured by $F(M^{p}(P))^{\\e-1}$ . The fairness channel appears because the price influences the perceived markup and thus the fairness of the transaction ; this in turn affects the marginal utility of consumption and demand ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_106": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_106",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_106",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_106",
		"text": "We apply the results of Proposition ~ \\ref{p:subproportional} to a specific fairness function : \\begin{equation} F(M^p) = 1- \\t \\cdot \\bp{M^p - \\frac{\\e}{\\e-1}}. \\label{e:fa}\\end{equation} We also assume that customers are acclimated , so $M^p = \\e/(\\e-1)$ and $F=1$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_112": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_112",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_112",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_112",
		"text": "Next , we divide numerator and denominator of $\\D$ in \\eqref{e:delta} by $\\t \\bp{\\e\\t+\\e-1}$ : \\begin{equation*} \\D(\\g,\\t,\\e) = \\frac{\\g^{2}}{(\\e-1)\\bp{\\g+1/\\t}\\frac{\\g\\e\\t+\\e-1}{\\e\\t+\\e-1}}. \\end{equation*} First , $\\g+1/\\t$ is decreasing in $\\t$ . Second , as $\\e>1$ and $\\g\\leq 1$ , $(\\g\\e\\t+\\e-1)/(\\e\\t+\\e-1)$ is decreasing in $\\t$ . Hence , $\\D$ is increasing in $\\t$ , and as $\\b = 1/(1+\\D)$ , $\\b$ is decreasing in $\\t$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_113": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_113",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_113",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_113",
		"text": "Last , dividing numerator and denominator of $\\D$ in \\eqref{e:delta} by $\\g^2$ , we get \\begin{equation*} \\D(\\g,\\t,\\e) = \\frac{\\t \\bs{(1+\\t)\\e-1}}{(\\e-1)\\bs{\\t\\e+(\\e-1)/\\g} \\bp{\\t+1/\\g}}. \\end{equation*} The denominator is decreasing in $\\g$ , so $\\D$ is increasing in $\\g$ . Since $\\b = 1/(1+\\D)$ , we conclude that $\\b$ is decreasing in $\\g$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_107": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_107",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_107",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_107",
		"text": "\\paragraph{Preliminary Results} The elasticity of the fairness function \\eqref{e:fa} is \\begin{equation*} \\f = - \\frac{M^p}{F}\\cdot \\od{F}{M^p} = \\frac{M^p}{F}\\cdot \\t. \\end{equation*} Accordingly , the superelasticity of the fairness function \\eqref{e:fa} satisfies \\begin{equation*} \\s = \\odl{\\f}{M^p} = 1 - \\odl{F}{M^p} = 1+\\f. \\end{equation*} When $M^p = \\e/(\\e-1)$ and $F=1$ , the elasticity and superelasticity simplify to \\begin{align}  \\f &= \\frac{\\e\\t } { \\e-1}\\label{e:phia} \\\\ \\s &= 1+\\frac{\\e\\t } { \\e-1}.\\label{e:sigmaa}  \\end{align}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_10": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_10",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_10",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_10",
		"text": "Finally , the monopoly has constant marginal cost $C>0$ . It chooses price $P$ and output $Y$ to maximize profits $(P - C) \\cdot Y$ subject to customers ' demand for its good ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_38": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_38",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_38",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_38",
		"text": "Combining \\eqref{e:e} and \\eqref{e:cp} , we then find that the price elasticity of demand satisfies \\begin{equation} E=\\e+(\\e-1) \\cdot \\g \\cdot \\f(M^p). \\label{e:e2}\\end{equation} We have seen that without fairness concerns ( $\\f=0$ ) , or with rational inference ( $\\g=0$ ) , the price elasticity of demand is constant , equal to $\\e$ . That result changes here . Since $\\g>0$ , the price elasticity of demand is always greater than $\\e$ . Moreover , since $\\f(M^{p})$ is increasing in $M^{p}$ and $M^{p}(P)$ in $P$ , the price elasticity of demand is increasing in $P$ . These properties have implications for the markup charged by the monopoly , $M=E/(1-E)$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_12": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_12",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_12",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_12",
		"text": "We turn to the monopoly 's pricing . The monopoly chooses price $P$ to maximize profits $(P-C) \\cdot Y^{d}(P)$ . The first - order condition is \\begin{equation*} Y^d(P)+\\bp{P-C} \\od{Y^{d}}{P}=0. \\end{equation*} We introduce the price elasticity of demand , normalized to be positive : \\begin{equation*} E = -\\odl{Y^{d}}{P} = - \\frac{P}{Y^d} \\cdot \\od{Y^{d}}{P}. \\end{equation*} The first - order condition then yields the classical result that \\begin{equation*} P= \\frac{E}{E-1} \\cdot C; \\end{equation*} that is , the monopoly optimally sets its price at a markup $M=E/(E-1)$ over marginal cost . \\footnote{In Appendix~A, we use the assumptions on the belief and fairness functions introduced in the next sections to verify that the first-order condition always gives the maximum of the monopoly's profit function.}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_139": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_139",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_139",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_139",
		"text": "We describe the steady - state equilibrium by six variables : output $\\ol{Y}$ , employment $\\ol{N}$ , inflation $\\ol{\\pi}$ , nominal interest rate $\\ol{i}$ , price markup $\\ol{M}$ , and perceived price markup $\\ol{M^p}$ . These six variables are governed by six equations ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_111": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_111",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_111",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_111",
		"text": "First , we divide numerator and denominator of $\\D$ by $(\\e-1)$ : \\begin{equation*} \\D(\\g,\\t,\\e) = \\frac{\\g^{2}\\t\\bs{1+\\t\\e/(\\e-1)}}{\\bs{(1+\\g\\t)\\e-1} \\bp{1+\\g\\t}}. \\end{equation*} Since $\\e/(\\e-1)$ is decreasing in $\\e$ and $(1+\\g\\t)\\e-1$ is increasing in $\\e$ , $\\D$ is decreasing in $\\e$ . As $\\b = 1/(1+\\D)$ , we conclude that $\\b$ is increasing in $\\e$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_105": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_105",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_105",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_105",
		"text": "Finally , combining \\eqref{e:beta0} with \\eqref{e:dmdmp} yields the cost passthrough \\begin{equation} \\b=\\frac{1}{1+\\frac{\\g^{2}\\f \\s}{\\bp{1+\\g \\f} \\bs{\\e+(\\e-1) \\g\\f}}}. \\label{e:betaa}\\end{equation} Since $\\g>0$ ( Definition ~ \\ref{d:subproportional} ) , $\\f>0$ ( Lemma ~ \\ref{l:phi} ) , and $\\s>0$ ( also Lemma ~ \\ref{l:phi} ) , we infer that $\\b\\in(0,1)$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_8": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_8",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_8",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_8",
		"text": "A monopoly sells a good to a representative customer . The monopoly cannot price - discriminate , so each unit of good sells at the same price $P$ . The customer cares about fairness and appraises transactional fairness by assessing the markup charged by the monopoly . Since the customer does not observe the marginal cost of production , she needs to infer it from the price . We assume that the marginal cost perceived at price $P$ is given by a belief function $C^{p}(P)$ . For simplicity , we restrict $C^p(P)$ to be deterministic . Having inferred the marginal cost , the customer deduces that the markup charged by the monopoly is \\begin{equation*} M^{p}(P)=\\frac{P}{C^{p}(P)}. \\end{equation*} The perceived markup determines the fairness of the transaction through a fairness function $F(M^p)>0$ . Both functions $C^{p}(P)$ and $F(M^p)$ are assumed to be twice differentiable ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_9": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_9",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_9",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_9",
		"text": "A customer who buys the quantity $Y$ of the good at price $P$ experiences the fairness - adjusted consumption \\begin{equation*} Z= F(M^{p}(P)) \\cdot Y. \\end{equation*} The customer also faces a budget constraint : \\begin{equation*} P \\cdot Y + B = W, \\end{equation*} where $W>0$ designates initial wealth , and $B$ designates remaining money balances . Fairness - adjusted consumption and money balances enter a quasilinear utility function \\begin{equation*} \\frac{\\e}{\\e-1} \\cdot Z^{(\\e-1)/\\e} + B, \\end{equation*} where the parameter $\\e>1$ governs the concavity of the utility function . Given fairness factor $F$ and price $P$ , the customer chooses purchases $Y$ and money balances $B$ to maximize utility subject to the budget constraint ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_104": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_104",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_104",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_104",
		"text": "Our next step is to compute the elasticity of $M(M^p)$ with respect to $M^p$ from \\eqref{e:ma} : \\begin{equation*} -\\odl{M}{M^p} = -\\frac{1}{M}\\cdot \\od{M}{\\ln(M^p)} = \\frac{1}{M}\\cdot \\frac{1}{\\e-1}\\cdot \\frac{1}{1+\\g \\f}\\cdot \\frac{1}{1+\\g \\f} \\cdot \\g \\cdot \\od{\\f}{\\ln(M^p)}. \\end{equation*} Using \\eqref{e:ma} , we find that \\begin{equation*} (\\e-1)(1+\\g \\f) M = \\e + (\\e-1)\\g \\f. \\end{equation*} Moreover , by definition , the superelasticity $\\s$ of the fairness function satisfies $\\f\\s = \\odx{\\f}{\\ln(M^p)}$ . Combining these three results , we obtain \\begin{equation} -\\odl{M}{M^p} = \\frac{\\g \\f \\s}{[\\e+(\\e-1)\\g \\f](1+\\g \\f)}. \\label{e:dmdmp}\\end{equation}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_110": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_110",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_110",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_110",
		"text": "Next we introduce the auxiliary function \\begin{equation} \\D(\\g,\\t,\\e) = \\frac{\\g^{2}\\t \\bs{(1+\\t)\\e-1}}{(\\e-1)\\bs{(1+\\g\\t)\\e-1} \\bp{1+\\g\\t}}, \\label{e:delta}\\end{equation} where $\\g\\in (0,1]$ , $\\t>0$ , and $\\e>1$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_138": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_138",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_138",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_138",
		"text": "We now apply the equilibrium conditions to a steady - state environment , in which all real variables are constant and all nominal variables grow at the inflation rate , $\\ol{\\pi}$ . We use these steady - state conditions to prove Lemma ~ \\ref{l:longrun} , Proposition ~ \\ref{p:longrun} , and Corollary ~ \\ref{c:longrun} . We also use these conditions to compute the long - run Phillips curves that are displayed in Figure \\ref{f:longrun} ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_13": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_13",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_13",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_13",
		"text": "To learn more about the monopoly 's markup , we compute the elasticity $E$ . Using \\eqref{e:yd} , we find \\begin{equation} E= \\e + (\\e-1) \\cdot \\f \\cdot \\bs{1-\\odl{C^{p}}{P}}, \\label{e:e}\\end{equation} where $\\f = -\\odlx{F}{M^p}$ is the elasticity of the fairness function with respect to the perceived markup , normalized to be positive . The first term , $\\e$ , describes the standard substitution effect . The second term , $(\\e-1) \\cdot\\f\\cdot \\bs{1-\\odlx{C^{p}}{P}}$ , represents the fairness channel and splits into two subterms . The first subterm , $(\\e-1)\\cdot \\f $ , appears because a higher price mechanically raises the perceived markup and thus reduces fairness . The second subterm , $- (\\e-1)\\cdot \\f\\cdot \\bs{\\odlx{C^{p}}{P}}$ , appears because a higher price conveys information about the marginal cost and thus influences perceived markup and fairness . We now use \\eqref{e:e} to compute the markup in various situations ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_17": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_17",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_17",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_17",
		"text": "\\begin{definition} \\label{d:fairness} Customers who care about fairness have a fairness function $F(M^p)$ that is positive , strictly decreasing , and weakly concave on $[0,M^h]$ , where $F(M^h)=0$ and $M^h>\\e/(\\e-1)$ . \\end{definition}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_114": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_114",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_114",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_114",
		"text": "\\paragraph{Household [unused10] 's Problem} To solve household ~ $k$ 's problem , we set up the Lagrangian : \\begin{align*} [unused10] & = \\E[0]\\sum_{t=0} ^{ \\infty}\\d^{t}  \\bigg\\{\\ln{Z_{k} ( t ) } - \\frac{N_{k} ( t ) ^{1+ [unused10] \\\\ & + \\Ac_{k} ( t ) \\bs{W_{k} ( t ) N_{ k }( t ) + B_{ k } ( t - 1 ) + V_{ k }( t ) - Q ( t ) B_{ k}( t ) - \\int_{0} ^{ 1 } P_{j } ( t ) Y_{jk}( t ) \\,dj }\\\\ &+ \\Bc_{k} ( t ) \\bs{N_{k} ^{ d } ( t , W_{ k } ( t ) ) - N_{ k } ( t ) }\\bigg\\}. \\end{align*} In the Lagrangian , $\\Ac_{k}(t)$ is the Lagrange multiplier on the budget constraint in period ~ $t$ ; $\\Bc_{k}(t)$ is the Lagrange multiplier on the labor - demand constraint in period ~ $t$ ; and $Z_{k}(t)$ is the fairness - adjusted consumption index : \\begin{equation} Z_{k}(t) = \\bs{\\int_{0}^{1} Z_{jk}(t)^{(\\e-1)/\\e}\\,dj}^{\\e/(\\e-1)}. \\label{e:zk}\\end{equation} In the consumption index , $Z_{jk}(t)$ is the fairness - adjusted consumption of good ~ $j$ : \\begin{equation} Z_{jk}(t)= F_{j}(t) \\cdot Y_{jk}(t). \\label{e:zjk}\\end{equation}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_100": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_100",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_100",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_100",
		"text": "Last , the superelasticity of the fairness function is given by \\begin{equation*} \\s = M^p \\cdot \\frac{\\f'(M^p)}{\\f(M^p)}. \\end{equation*} Since $\\f(M^p)>0$ and $\\f'(M^p)>0$ , it is clear that $\\s>0$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_128": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_128",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_128",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_128",
		"text": "\\paragraph{First-Order Condition with Respect to Price} The first - order condition of firm ~ $j$ 's problem with respect to $P_{j}(t)$ is $\\pdx{\\Lc_{j}}{P_{j}(t)}=0$ . It yields \\begin{equation} 0 = Y_{j}(t) +\\Hc_{j}(t)\\pd{Y_{j}^{d}}{P_{j}} +(1-\\g)\\Kc_{j}(t) \\frac{C^{p}_{j}(t)}{P_{j}(t)}. \\label{e:focpj}\\end{equation} We divide this condition by $Y_{j}(t)$ and insert the price elasticity of the demand for good ~ $j$ , $E_{j}(M^{p}_{j}(t)) = - \\pdlx{Y_{j}^{d}}{P_j}$ , as well as the perceived price markup for good ~ $j$ , $M^{p}_{j}(t) = P_{j}(t)/C^{p}_{j}(t)$ . We obtain \\begin{equation*} 0 = 1-\\frac{\\Hc_{j}(t)E_{j}(M^{p}_{j}(t))}{P_{j}(t)}+(1-\\g)\\frac{\\Kc_{j}(t)}{Y_{j}(t) M^{p}_{j}(t)}. \\end{equation*} Using the value of $\\Hc_{j}(t)$ given by \\eqref{e:hj} , we finally obtain \\begin{equation} (1-\\g)\\frac{\\Kc_j(t)}{Y_{j}(t)M^{p}_{j}(t)} = \\frac{M_{j}(t)-1}{M_{j}(t)} E_{j}(M^{p}_{j}(t))-1. \\label{e:ejmj}\\end{equation}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_129": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_129",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_129",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_129",
		"text": "\\paragraph{First-Order Condition with Respect to Perceived Marginal Cost} The first - order condition of firm ~ $j$ 's problem with respect to $C^{p}_{j}(t)$ is $\\pdx{\\Lc_{j}}{C^p_{j}(t)}=0$ . It gives \\begin{equation*} 0 =\\E[t]{\\frac{\\G(t+1)}{\\G(t)} \\Hc_{j}(t+1) \\pd{Y_{j}^{d}}{C^{p}_{j}}} + \\g \\E[t]{ \\frac{\\G(t+1)}{\\G(t)} \\Kc_{j}(t+1)  \\frac{C^{p}_{j}(t+1)}{C^{p}_{j}(t)}} -\\Kc_{j}(t). \\end{equation*} And using the elasticity given by \\eqref{e:ydc} , we find \\begin{equation*} \\Kc_{j}(t)=\\E[t]{\\frac{\\G(t+1)}{\\G(t)}\\bc{\\Hc_{j}(t+1)\\frac{Y_{j}(t+1)}{C_{j}^{p}(t)} [E_{j}(M^{p}_{j}(t+1))-\\e]+ \\g \\Kc_{j}(t+1) \\frac{C^{p}_{j}(t+1)}{C_{j}^{p}(t)}}}. \\end{equation*} We modify this equation in two steps : first , we multiply it by $C_j^p(t)/[Y_j(t)P_j(t)]$ ; second , we insert the perceived price markups $M_j^p(t) = P_j(t)/C_j^{p}(t)$ and $M_j^p(t+1) = P_j(t+1)/C_j^{p}(t+1)$ . We get \\begin{equation*}\\medmuskip=2mu \\frac{\\Kc_{j}(t)M_j^p(t)}{Y_j(t)}=\\E[t]{\\frac{\\G(t+1)Y_j(t+1)P_j(t+1)}{\\G(t)Y_j(t)P_j(t)}\\bc{\\frac{\\Hc_{j}(t+1)}{P_j(t+1)}[E_{j}(M^{p}_{j}(t+1))-\\e]+ \\g\\frac{\\Kc_{j}(t+1) M^{p}_{j}(t+1)}{Y_{j}(t+1)}}}. \\end{equation*} Last , we multiply the equation by $(1-\\g)$ ; and we eliminate $\\Hc_j(t+1)$ using \\eqref{e:hj} and $\\Kc_j(t)$ and $\\Kc_j(t+1)$ using \\eqref{e:ejmj} . We obtain firm ~ $j$ 's pricing equation , which links its markup to its perceived markup : \\begin{align} & \\frac{M_{j} ( t ) - 1 } { M_{j } ( t ) } E_{j } ( M^{ p }_{j } ( t ) ) = \\label{e:emj} \\\\ &1+ \\E[t]{\\frac{\\G(t+1)Y_j(t+1)P_j(t+1)} { \\G(t)Y_j(t)P_j(t)}\\bc{\\frac{M_{j} ( t +1 ) - 1 } { M_{j } ( t+1 ) } [ E_{j } ( M^{p }_{j } ( t+1 ) ) - ( 1 -\\g ) \\e ] -\\g } } .\\ nonumber \\end{align}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_101": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_101",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_101",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_101",
		"text": "\\paragraph{Markup} Since customers care about fairness and infer subproportionally , the price elasticity of demand is $E = \\e+(\\e-1) \\g  \\f(M^p(P))$ . Moreover , the monopoly 's optimal markup is \\begin{equation*} M = \\frac{E}{E-1} = 1 + \\frac{1}{E-1}. \\end{equation*} Combining these equations yields the markup \\begin{equation} M =1+\\frac{1}{\\e-1}\\cdot \\frac{1}{1+\\g \\f(M^p(M \\cdot C))}. \\label{e:ma}\\end{equation} In \\eqref{e:ma} we have used the relationship between the price and markup : $P = M \\cdot C$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_115": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_115",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_115",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_115",
		"text": "\\paragraph{First-Order Conditions with Respect to Consumption} We first compute the first - order conditions with respect to $Y_{jk}(t)$ for all goods $j\\in[0,1]$ : $\\pdx{\\Lc_{k}}{Y_{jk}(t)}=0$ . From the definitions of $Z_{k}(t)$ and $Z_{jk}(t)$ given by \\eqref{e:zk} and \\eqref{e:zjk} , we find \\begin{equation*} \\pd{Z_{jk}(t)}{Y_{jk}(t)}=F_{j}(t)\\quad\\text{and}\\quad \\pd{Z_{k}(t)}{Z_{jk}(t)}=\\bs{\\frac{Z_{jk}(t)}{Z_{k}(t)}}^{-1/\\e} dj. \\end{equation*} Hence the first - order conditions imply that for all $j\\in[0,1]$ , \\begin{equation} \\bs{\\frac{Z_{jk}(t)}{Z_{k}(t)}}^{-1/\\e} \\frac{F_{j}(t)}{Z_{k}(t)}=\\Ac_{k}(t) P_{j}(t). \\label{e:focy}\\end{equation}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_16": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_16",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_16",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_16",
		"text": "\\begin{lemma} \\label{l:nofairness} When customers do not care about fairness , the monopoly sets the markup to $M=\\e/(\\e-1)$ , and the cost passthrough is $\\b=1$ . \\end{lemma}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_14": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_14",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_14",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_14",
		"text": "\\begin{definition} Customers who do not care about fairness have a fairness function $F(M^p)=1$ . \\end{definition}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_28": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_28",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_28",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_28",
		"text": "The lemma shows that when customers care about fairness and rationally infer costs , there is a PBE in which fairness does not play a role . With fairness concerns , the price affects demand not only by changing customers ' budget sets but also by changing the perceived markup . In this equilibrium , however , after observing any price chosen by the monopoly , customers perceive the same markup $\\e/(\\e-1)$ . The second channel through which price could affect demand closes , so the monopoly sets the standard markup $\\e/(\\e-1)$ . Since the markup does not depend on marginal cost , changes in marginal cost are fully passed through into prices : prices are flexible again ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_103": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_103",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_103",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_103",
		"text": "\\paragraph{Passthrough} We now compute the cost passthrough , $\\b= \\odlx{P}{C}$ . The equilibrium price is $P= M(M^p(P)) \\cdot C$ , where the markup $M(M^p)$ is given by \\eqref{e:ma} . Using this price equation , we obtain \\begin{equation*} \\b = \\odl{M}{M^p}\\cdot \\odl{M^p}{P}\\cdot\\odl{P}{C}+1. \\end{equation*} Since $\\odlx{M^p}{P}=\\g$ ( Lemma ~ \\ref{l:subproportional} ) and $\\odlx{P}{C}=\\b$ ( by definition ) , we get \\begin{equation} \\b = \\frac{1}{1-\\g \\odl{M}{M^p}}. \\label{e:beta0}\\end{equation}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_117": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_117",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_117",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_117",
		"text": "Last , combining \\eqref{e:focy} and \\eqref{e:ak} , we find that the optimal fairness - adjusted consumption of good ~ $j$ by household ~ $k$ satisfies \\begin{equation*} Z_{jk}(t) = Z_{k}(t) \\bs{\\frac{P_{j}(t)}{X(t)}}^{-\\e}F_{j}(t)^{\\e}. \\end{equation*} As consumption and fairness - adjusted consumption of good ~ $j$ are related by $Y_{jk}(t)= Z_{jk}(t) / F_{j}(t)$ , the optimal consumption of good ~ $j$ by household ~ $k$ satisfies \\begin{equation} Y_{jk}(t)= Z_{k}(t) \\bs{\\frac{P_{j}(t)}{X(t)}}^{-\\e} F_{j}(t)^{\\e-1}. \\label{e:yjk}\\end{equation} Integrating \\eqref{e:yjk} over all households $k\\in[0,1]$ yields the output of good ~ $j$ : \\begin{equation*} Y_{j}(t) = Z(t) \\bs{\\frac{P_{j}(t)}{X(t)}}^{-\\e} F_{j}(t)^{\\e-1}. \\end{equation*} We note that the fairness factor $F_{j}(t)$ is a function of the perceived price markup , $F_{j}(t)=F_j(P_{j}(t)/C_{j}^{p}(t))$ , and that the perceived marginal cost $C_{j}^{p}(t)$ follows the law of motion \\eqref{e:cpj} . These observations allow us to obtain the demand for good ~ $j$ : \\begin{equation*} Y^{d}_{j}(t,P_{j}(t),C_{j}^{p}(t-1)) = Z(t) \\bs{\\frac{P_{j}(t)}{X(t)}}^{-\\e} F_j\\of{\\bp{\\frac{\\e}{\\e-1}}^{1-\\g}\\bs{\\frac{P_{j}(t)}{C_{j}^{p}(t-1)}}^{\\g}}^{\\e-1}. \\end{equation*}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_116": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_116",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_116",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_116",
		"text": "Taking \\eqref{e:focy} to the power of $1-\\e$ and shuffling terms , we then obtain \\begin{equation*} \\frac{1}{Z_{k}(t)^{1-\\e}} \\cdot \\frac{1}{Z_{k}(t)^{(\\e-1)/\\e}}\\cdot Z_{jk}(t)^{(\\e-1)/\\e}= \\Ac_{k}(t)^{1-\\e} \\bs{\\frac{P_{j}(t)}{F_{j}(t)}}^{1-\\e}. \\end{equation*} We integrate this equation over $j\\in[0,1]$ , use the definition of $Z_{k}(t)$ given by \\eqref{e:zk} , and introduce the price index \\begin{equation} X(t)=\\bc{\\int_0^1\\bs{\\frac{P_{j}(t)}{F_{j}(t)}}^{1-\\e}\\,dj}^{1/(1-\\e)}. \\label{e:x}\\end{equation} We obtain the following : \\begin{equation*} \\frac{1}{Z_{k}(t)^{1-\\e}}\\cdot \\frac{Z_{k}(t)^{(\\e-1)/\\e}}{Z_{k}(t)^{(\\e-1)/\\e}}= \\Ac_{k}(t)^{1-\\e} X(t)^{1-\\e}. \\end{equation*} From this equation we infer \\begin{equation} \\Ac_{k}(t) = \\frac{1}{X(t) Z_{k}(t)}. \\label{e:ak}\\end{equation}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_102": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_102",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_102",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_102",
		"text": "Toward showing that \\eqref{e:ma} admits a unique solution , we introduce the price $P^b$ defined by \\eqref{e:pb} and the markup $M^b = P^b/C >1$ . Since $P = M \\cdot C$ , $P$ strictly increases from $0$ to $P^b$ when $M$ increases from $0$ to $M^b$ . Next , Lemma ~ \\ref{l:subproportional} shows that $M^p(P)$ strictly increases from 0 to $M^h$ when $P$ increases from $0$ to $P^b$ . Last , Lemma ~ \\ref{l:phi} indicates that $\\f(M^p)$ strictly increases from $0$ to $\\infty$ when $M^p$ increases from 0 to $M^h$ . As $\\g>0$ , we conclude that when $M$ increases from $0$ to $M^b>1$ , the right - hand side of \\eqref{e:ma} strictly decreases from $\\e/(\\e-1)$ to $1$ . Hence , \\eqref{e:ma} has a unique solution $M\\in\\bs{0,M^b}$ , implying that the markup exists and unique . Given the range of values taken by the right - hand side of \\eqref{e:ma} , we also infer that $M \\in (1, \\e/(\\e-1))$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_29": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_29",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_29",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_29",
		"text": "Of course , there may exist other equilibria beside the one described in Lemma ~ \\ref{l:rational} . A pooling PBE may exist in which all types of the firm charge the same price $P>C^h$ , and consumers believe that a firm who prices otherwise has zero marginal cost . However , this and other non-fully - separating PBEs fail standard signaling refinements . \\footnote{Only a separating PBE satisfies the D1 Criterion from \\ct{CK87} . Intuitively , consumers ought to interpret a price $P'>P$ as coming from type $C=C^h$ rather than type $C=0$ , which undermines the pooling equilibrium . Indeed , if consumers demand no less at $P'$ than in equilibrium , then all types of firm benefit from deviating ; if consumers demand less at $P'$ than in equilibrium , then the highest - cost firm strictly benefits whenever any other type of firm weakly benefits . On these grounds , the D1 Criterion suggests that consumers should interpret $P'>P$ as coming from the highest marginal - cost firm . } Because the linear PBE in Lemma ~ \\ref{l:rational} is so simple and robust , it is more plausible than any alternative , which suggests that fairness is unlikely to matter when customers rationally infer costs ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_15": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_15",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_15",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_15",
		"text": "Without fairness concerns , the fairness function is constant , so its elasticity is $\\f=0$ . According to \\eqref{e:e} , the price elasticity of demand is constant : $E=\\e$ . This implies that the optimal markup for the monopoly takes a standard value of $\\e/(\\e-1)$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_18": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_18",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_18",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_18",
		"text": "The assumption that the fairness function strictly decreases in the perceived markup captures the pattern that customers find higher markups less fair and resent unfair transactions . The assumption that the fairness function is weakly concave means that an increase in perceived markup causes a utility loss of equal magnitude ( if $F$ is linear ) or of greater magnitude ( if $F$ is strictly concave ) than the utility gain caused by an equal - sized decrease in perceived markup . We could not find evidence on this assumption , but it seems natural that people are at least as outraged over a price increase as they are happy about a price decrease of the same magnitude ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_30": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_30",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_30",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_30",
		"text": "\\begin{definition} \\label{d:subproportional} Customers who update subproportionally use the belief - updating rule \\begin{equation} C^{p}(P)=\\bp{C^{b}}^{\\g} \\bp{\\frac{\\e-1}{\\e} P}^{1-\\g}, \\label{e:cp}\\end{equation} where $C^b > (\\e-1) \\cdot (M^h)^{-1/\\g} \\cdot C/\\e$ is a prior point belief about marginal cost , and $\\g \\in(0,1]$ governs the extent to which beliefs anchor on that prior belief . \\end{definition}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_24": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_24",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_24",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_24",
		"text": "A pure - strategy perfect Bayesian equilibrium ( PBE ) of this game comprises three elements : a pure strategy for the monopolist , which is a mapping $P: [0, C^h] \\to \\R_+$ that selects a price for every possible value of marginal cost ; a belief function for customers , which is a mapping $C^p: \\R_+ \\to [0, C^h]$ that determines a marginal cost for every possible price ; and a pure strategy for customers , which is a mapping $Y^d: \\R_+ \\to \\R_+$ that selects a quantity purchased for every possible price . \\footnote{Strictly speaking, [unused10] should allow the consumer to hold probabilistic beliefs about the firm's marginal cost given price, but we sidestep this subtlety because it does not affect our analysis.}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_127": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_127",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_127",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_127",
		"text": "\\paragraph{First-Order Condition with Respect to Output} We then finish solving firm ~ $j$ 's problem . The first - order condition with respect to $Y_{j}(t)$ is $\\pdx{\\Lc_{j}}{Y_{j}(t)}=0$ , which gives \\begin{equation*} P_{j}(t)=\\Hc_{j}(t)+\\Jc_{j}(t). \\end{equation*} Using the value of $\\Jc_{j}(t)$ given by \\eqref{e:jj} , we then obtain \\begin{equation} \\Hc_{j}(t)=P_{j}(t) \\bs{1-\\frac{W(t)/P_{j}(t)}{ \\a A_{j}(t) N_{j}(t)^{\\a-1}}}. \\label{e:hj1}\\end{equation} Firm ~ $j$ 's nominal marginal cost is the nominal wage divided by the marginal product of labor : \\begin{equation} C_{j}(t)= \\frac{W(t)}{\\a A_{j}(t) N_{j}(t)^{\\a-1}}. \\label{e:cj}\\end{equation} Hence the first - order condition \\eqref{e:hj1} can be written \\begin{equation} \\Hc_{j}(t)=P_{j}(t) \\bs{1-\\frac{C_{j}(t)}{P_{j}(t)}}. \\label{e:hj2}\\end{equation} Given that firm ~ $j$ 's markup is $M_j(t)=P_j(t)/C_j(t)$ , we rewrite this equation as \\begin{equation} \\frac{\\Hc_{j}(t)}{P_{j}(t)} = \\frac{M_{j}(t)-1}{M_{j}(t)}. \\label{e:hj}\\end{equation}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_133": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_133",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_133",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_133",
		"text": "The third equation is the usual consumption Euler equation , obtained by simplifying \\eqref{e:eulerx} . By symmetry $X(t)=P(t)/F(t)$ and $Z_{k}(t)=F(t) Y(t)$ , so \\eqref{e:eulerx} gives \\begin{equation} Q(t)=\\d \\E[t]{\\frac{P(t) Y(t)}{P(t+1) Y(t+1)}}. \\label{e:euler}\\end{equation}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_2": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_2",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_2",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_2",
		"text": "\\paragraph{Price Decreases Allowed by Lower Costs} Our assumption equally implies that it is unfair for firms not to pass along cost decreases . \\ct[p.~734]{KKT86} find milder support for this reaction . They describe the following situation : `` A small factory produces tables and sells all that it can make at \\ $200 each. Because of changes in the price of materials, the cost of making each table has recently decreased by \\$ 20 . The factory does not change its price of tables . '' Only 47\\% of respondents find this unfair , despite the elevated markup ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_3": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_3",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_3",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_3",
		"text": "Subsequent studies , however , find that people do expect price reductions after cost reductions . \\ct{KDU91} survey 189 US business students , asking them to consider the following scenario : `` A department store has been buying an oriental floor rug for \\ $100. The standard pricing practice used by department stores is to price floor rugs at double their cost so the selling price of the rug is \\$ 200 . This covers all the selling costs , overheads and includes profit . The department store can sell all of the rugs that it can buy . Suppose because of exchange rate changes the cost of the rug rises from \\ $100 to \\$ 120 and the selling price is increased to \\ $220. As a result of another change in currency exchange rates, the cost of the rug falls by \\$ 20 back to \\ $100.'' Then two alternative scenarios were evaluated: ``The department store continues to sell the rug for \\$ 220'' compared to `` The department store reduces the price of the rug to \\ $200.'' The latter was judged significantly fairer: the fairness rating was $ +2.3 $ instead of $ - 0.4 [unused10] -3 $ is extremely unfair and $ +3 $ extremely fair). Similarly, in survey of US respondents, \\ct[Table~6]{K01} finds that if a factory that sells a table at \\$ 150 locates a supplier charging \\ $20 less for materials, the new fair price is \\$ 138 , well below \\ $ 150 ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_132": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_132",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_132",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_132",
		"text": "The first equation is the monetary - policy rule , given by \\eqref{e:taylor} . This equation links the nominal interest rate , $i(t)$ , to the inflation rate , $\\pi(t)$ . By definition , however , the nominal interest rate is determined by the bond price and the inflation rate by the price level : \\begin{equation} i(t) = \\ln{\\frac{1}{Q(t)}}, \\qquad \\pi(t) = \\ln{\\frac{P(t)}{P(t-1)}}. \\label{e:definition}\\end{equation} Hence the monetary - policy rule links bond price to price level ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_126": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_126",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_126",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_126",
		"text": "\\paragraph{First-Order Conditions with Respect to Labor and Wage} We now finish solving household ~ $k$ 's problem using labor demand ~ \\eqref{e:nk} . The first - order conditions with respect to $N_{k}(t)$ and $W_{k}(t)$ are $\\pdx{\\Lc_{k}}{N_{k}(t)}=0$ and $\\pdx{\\Lc_{k}}{W_{k}(t)}=0$ ; they yield \\begin{align} N_{ k } ( t ) ^ { \\eta}&=\\Ac_{k} ( t ) W_{ k } ( t ) - \\Bc_{k} ( t ) \\label{e:focnk} \\\\ \\Ac_{k} ( t ) N_{ k } ( t ) & = - \\Bc_{k} ( t ) \\od{N_{k} ^{ d } } { W_{ k } } . \\label{e:focwk}  \\end{align} Since the elasticity of $N_{k}^{d}$ with respect to $W_{k}$ is $-\\n$ , we infer from \\eqref{e:focwk} that \\begin{equation} \\Ac_{k}(t) W_{k}(t) = \\Bc_{k}(t) \\n. \\label{e:akwk}\\end{equation} Plugging this result into \\eqref{e:focnk} , we obtain \\begin{equation*} \\Bc_{k}(t) = \\frac{N_{k}(t)^{\\eta}}{\\n-1}. \\end{equation*} Combining this result with \\eqref{e:akwk} then yields \\begin{equation*} W_{k}(t) = \\frac{\\n}{\\n-1} \\cdot \\frac{N_{k}(t)^{\\eta}}{\\Ac_{k}(t)}. \\end{equation*} Finally , by merging this equation with \\eqref{e:ak} , we find that household ~ $k$ sets its wage rate at \\begin{equation} \\frac{W_{k}(t)}{X(t)}=\\frac{\\n}{\\n-1} N_{k}(t)^{\\eta} Z_{k}(t). \\label{e:wkx}\\end{equation} This equation shows that households set their real wage at a markup of $\\n/(\\n-1)>1$ over the marginal rate of substitution between leisure and consumption ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_25": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_25",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_25",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_25",
		"text": "We look for a PBE that is fully separating : the monopoly chooses different prices for different marginal costs , which allows a rational customer who knows the monopoly 's equilibrium strategy and observes the price to deduce marginal cost . We claim the existence of a PBE in which the monopolist uses the strategy $P(C)= \\e \\cdot C/(\\e-1)$ ; customers believe $C^p(P) = (\\e-1) P/\\e$ if $P\\in \\Pc \\equiv \\bs{0,\\e C^h/(\\e-1)}$ , and $C^p(P) = 0$ otherwise ; and customers demand $Y^{d}(P)= P^{-\\e} \\cdot F(P/C^p(P))^{\\e-1}$ . In such a PBE , customers correctly infer marginal costs from prices on the equilibrium path ( $P\\in \\Pc$ ) and infer the worst from prices off the equilibrium path ( $P\\notin \\Pc$ ) , namely that the firm has zero marginal cost and infinitely high markup ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_31": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_31",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_31",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_31",
		"text": "First , customers underinfer marginal costs from price by clinging to their prior belief $C^b$ . The parameter $\\g \\in (0,1]$ measures the degree of underinference . When $\\g=1$ , customers do not update at all about marginal cost based on price ; they naively maintain their prior belief $C^{b}$ , irrespective of the price they observe . When $\\g\\in(0,1)$ , customers do infer something from the price , but not enough ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_19": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_19",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_19",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_19",
		"text": "\\begin{lemma} \\label{l:phi} When customers care about fairness , the elasticity of the fairness function \\begin{equation*} \\f(M^p) = -\\odl{F}{M^p} \\end{equation*} is strictly positive and strictly increasing on $(0,M^h)$ , with $\\lim_{M^p\\to 0} \\f(M^p) = 0$ and $\\lim_{M^p\\to M^h} \\f(M^p) = +\\infty$ . As an implication , the superelasticity of the fairness function \\begin{equation*} \\s = \\odl{\\f}{M^p} \\end{equation*} is strictly positive on $(0,M^h)$ . \\end{lemma}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_27": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_27",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_27",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_27",
		"text": "\\begin{lemma}  \\label{l:rational} When customers care about fairness and rationally infer costs , there is a PBE in which the monopoly uses the markup $M=\\e/(\\e-1)$ , and customers learn marginal cost from price . In this PBE , the cost passthrough is $\\b=1$ . Hence , in this PBE , the markup and cost passthrough are the same as without fairness concerns . \\end{lemma}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_33": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_33",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_33",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_33",
		"text": "Last , we impose a constraint on the parameter $C^b$ such that the perceived markup falls below $M^h$ when the firm prices at marginal cost ; this is necessary for equilibrium existence ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_118": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_118",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_118",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_118",
		"text": "For future reference , the elasticities of the function $Y^{d}_{j}(t,P_{j}(t),C_{j}^{p}(t-1))$ are [unused10] - [unused10] _{j }} { P_{j }}&= \\e+(\\e-1) \\g \\f_{j} ( M ^{p}_{j} ( t ) ) \\equiv E_{j} ( M ^{p}_{j} ( t ) ) \\label{e:ydp} \\\\ [unused10] _{j }} { C_{j}^{ p }}&= ( [unused10] ( M ^{p}_{j} ( t ) ) = E_{j} ( M ^{p}_{j} ( t ) ) - \\e,\\label{e:ydc} \\end{align} where $\\f_{j} = -\\odlx{F_{j}}{M^{p}_{j}}$ is the elasticity of the fairness function . The function $E_{j}$ gives the price elasticity of the demand for good ~ $j$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_130": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_130",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_130",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_130",
		"text": "We present the equilibrium of the model . Because all households and firms face the same conditions , they all behave the same in equilibrium , so we drop the subscripts ~ $j$ and ~ $k$ on all variables ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_124": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_124",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_124",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_124",
		"text": "Last , we combine \\eqref{e:wk} and \\eqref{e:jj} to determine the quantity of labor that firm ~ $j$ hires from household ~ $k$ : \\begin{equation} N_{jk}(t)=N_{j}(t) \\bs{\\frac{W_{k}(t)}{W(t)}}^{-\\n}. \\label{e:njk}\\end{equation} Integrating \\eqref{e:njk} over all firms ~ $j\\in[0,1]$ yields the demand for labor service ~ $k$ : \\begin{equation} N_{k}^{d}(t,W_{k}(t)) = N(t) \\bs{\\frac{W_{k}(t)}{W(t)}}^{-\\n}, \\label{e:nk}\\end{equation} where $N(t) = \\int_0^1 N_{j}(t)\\,dj$ is aggregate employment ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_1": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_1",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_1",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_1",
		"text": "\\paragraph{Price Increases Due to Higher Demand} Our assumption implies that people find price increases unjustified by cost increases to be unfair . In a survey of Canadian residents , \\ct[p.~729]{KKT86} document this pattern . They describe the following situation : `` A hardware store has been selling snow shovels for \\ $15. The morning after a large snowstorm, the store raises the price to \\$ 20 . '' Among 107 respondents , only 18\\% regard this pricing as acceptable , whereas 82\\% regard it as unfair ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_0": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_0",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_0",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_0",
		"text": "Absent fairness concerns , the monopolist would set a constant markup that produces flexible prices , which move proportionally to marginal costs . If customers cared about fairness and rationally inverted the price to uncover the hidden marginal cost , the same pricing rule would be an equilibrium . Indeed , when price increases by $x \\%$ , customers correctly infer that marginal cost has increased by $x \\%$ , and therefore that the markup has not changed . Since the price change does not change the perceived markup , the price elasticity of demand does not change , and neither does the markup ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_125": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_125",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_125",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_125",
		"text": "Moreover , \\eqref{e:w} and \\eqref{e:njk} imply that \\begin{equation*} \\int_0^1 W_{k} N_{jk}\\,dk = W^{\\n} N_{j} \\int_0^1 W_{k}^{1-\\n} \\,dk = W N_{j}. \\end{equation*} This means that when firms optimally allocate their wage bill across labor services , the cost of one unit of labor index is $W$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_131": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_131",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_131",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_131",
		"text": "The equilibrium can be described by seven variables : output $Y(t)$ , employment $N(t)$ , the price level $P(t)$ , the wage $W(t)$ , the bond price $Q(t)$ , the price markup $M(t)$ , and the perceived price markup $M^p(t)$ . Seven equations determine these seven variables ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_119": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_119",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_119",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_119",
		"text": "Moreover , using \\eqref{e:yjk} and the definition of the price index $X$ given by \\eqref{e:x} , we find that \\begin{equation*} \\int_0^1 P_{j} Y_{jk}\\,dj = X^{\\e} Z_{k} \\int_0^1 \\bp{\\frac{P_{j}}{F_{j}}}^{1-\\e} \\,dj = X Z_{k}. \\end{equation*} This means that when households optimally allocate their consumption expenditures across goods , the price of one unit of fairness - adjusted consumption index is $X$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_32": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_32",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_32",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_32",
		"text": "Moreover , insofar as they infer something , they infer that marginal cost is proportional to price , given by $(\\e-1) P/\\e$ . Such proportional inference represents a second error : underinference pertains to how much customers infer , whereas proportional inference describes what customers infer in as much as they do infer . The updating rule has the property that in the limit as $\\g=0$ , customers infer rationally . Indeed , when $\\g=0$ , the monopoly optimally sets the markup $\\e/(\\e-1)$ , which makes $(\\e-1) P/\\e$ the marginal cost at price $P$ , and proportional inference agrees with rational inference . When $\\g \\in (0,1)$ , however , the monopoly does not find it optimal to mark up proportionally , and proportional inference becomes an error ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_26": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_26",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_26",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_26",
		"text": "The argument proceeds in three steps . First , given their beliefs , customers ' demand is indeed optimal , as we have shown in \\eqref{e:yd} . Second , given the monopolist 's strategy , customers ' beliefs are indeed correct for any equilibrium price . Third , given customers ' beliefs and demand , the monopolist 's strategy is optimal . Indeed , given customers ' beliefs for $P\\in \\Pc$ , we have $\\odlx{C^{p}}{P}=1$ . Then , according to \\eqref{e:e} ( which is implied by customers ' strategy ) , the price elasticity of demand for any price on $\\Pc$ is $E=\\e$ . Hence , the monopolist optimally charges $P= \\e C/(\\e-1)$ . Finally , the monopoly has no incentive to charge some price not belonging to $\\Pc$ , which would lead customers to perceive an infinite markup , bringing the fairness factor , demand , and profits to zero ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_22": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_22",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_22",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_22",
		"text": "\\begin{lemma} \\label{l:observable} When customers care about fairness and observe costs , the monopoly 's markup $M$ is implicitly defined by \\eqref{e:mo} . This implies that $M \\in (1,\\e/(\\e-1))$ and the cost passthrough is $\\b=1$ . Hence , the markup is lower than without fairness concerns , but the cost passthrough is identical . \\end{lemma}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_36": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_36",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_36",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_36",
		"text": "\\begin{lemma}  \\label{l:subproportional} When customers update subproportionally , they perceive the monopoly 's markup to be \\begin{equation*} M^{p}(P)=\\bp{\\frac{\\e}{\\e-1}}^{1-\\g} \\bp{\\frac{P}{C^{b}}}^{\\g}, \\end{equation*} which is a strictly increasing function of the observed price $P$ . \\end{lemma}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_135": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_135",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_135",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_135",
		"text": "The fifth equation is the standard link between price markup and employment , which is obtained from the definition of the price markup . In a symmetric economy the price markup is just the inverse of the real marginal cost : $M(t) = P(t)/C(t)$ . Combining the expression of the nominal marginal cost given by \\eqref{e:cj} with the value of the real wage given by \\eqref{e:wp} , we infer the real marginal cost : \\begin{equation*} \\frac{C(t)}{P(t)} = \\frac{\\n}{(\\n-1) \\a} N(t)^{1+\\eta}. \\end{equation*} Since the price markup is the inverse of the real marginal cost , we find \\begin{equation} N(t)=\\bs{\\frac{(\\n-1) \\a }{\\n} \\cdot \\frac{1}{M(t)}}^{1/(1+\\eta)}. \\label{e:na}\\end{equation}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_121": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_121",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_121",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_121",
		"text": "\\paragraph{Firm [unused10] 's Problem} Since the wages set by households depend on firms ' labor demands , we turn to the firms ' problems before finishing the households ' problems . To solve firm ~ $j$ 's problem , we set up the Lagrangian : \\begin{align*} [unused10] & = \\E[0]\\sum_{t=0} ^{ \\infty}\\G(t) \\bigg\\lbrace P_{j} ( t ) Y_{j} ( t ) - \\int_{0} ^{1 } W_{k}( t ) N_{jk}( t ) \\, dk \\\\ & + \\Hc_{j} ( t ) [unused10] _{j} ( t , P_{j} ( t ) , C^{p}_{j}( t - 1 ) ) - Y_{j}( t ) } + [unused10] ( t ) \\bs{A_{j} ( t ) N_{j} ( t ) ^{ \\a}-Y_{j} ( t ) }\\\\ &+ \\Kc_{j} ( t ) [unused10] _{j}( t - 1 ) ^{ [unused10] { \\e} P_{j} ( t ) } ^{1- [unused10] _{j}( t ) }\\ bigg\\rbrace. \\end{align*} In the Lagrangian , $\\Hc_{j}(t)$ is the Lagrange multiplier on the demand constraint in period ~ $t$ ; $\\Jc_{j}(t)$ is the Lagrange multiplier on the production constraint in period ~ $t$ ; $\\Kc_{j}(t)$ is the Lagrange multiplier on the law of motion of the perceived marginal cost in period ~ $t$ ; and $N_{j}(t)$ is the employment index : \\begin{equation} N_{j}(t)= \\bs{\\int_{0}^1 N_{jk}(t)^{(\\n-1)/\\n}\\,dk}^{\\n/(\\n-1)}. \\label{e:nj}\\end{equation}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_109": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_109",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_109",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_109",
		"text": "\\paragraph{Passthrough} Combining \\eqref{e:betaa} with \\eqref{e:phia} and \\eqref{e:sigmaa} , we find that the cost passthrough $\\b$ satisfies \\begin{align*} 1 / \\b = 1+\\frac{\\g^{2}  \\e\\t \\bs{(\\e-1)+\\e\\t} } { ( \\e-1)\\bs{(\\e-1)+\\g \\e\\t}  \\bp{\\e+\\g\\e\\t} } = 1 + \\frac{\\g^{2}  \\t \\bs{(1+\\t)\\e-1} } { ( \\e-1)\\bs{(1+\\g\\t)\\e-1}  \\bp{1+\\g\\t} } . \\end{align*}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_4": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_4",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_4",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_4",
		"text": "\\paragraph{Underinference from Prices}  \\ct{SDT97} report survey evidence that points at underinference in the context of pricing . They presented 362 people in New Jersey with the following thought experiment : `` Changes in the economy often have an effect on people 's financial decisions . Imagine that the US experienced unusually high inflation which affected all sectors of the economy . Imagine that within a six - month period all benefits and salaries , as well as the prices of all goods and services , went up by approximately 25\\% . You now earn and spend 25\\% more than before . Six months ago , you were planning to buy a leather armchair whose price during the 6 - month period went up from \\ $400 to \\$ 500 . Would you be more or less likely to buy the armchair now ? '' The higher prices were distinctly aversive : while 55\\% of respondents were as likely to buy as before and 7\\% were more likely , 38\\% of respondents were less likely to buy ( p. ~ 355 ) . Our model makes this prediction . While consumers who update subproportionally recognize that higher prices signal higher marginal costs , they stop short of rational inference . Consequently , consumers perceive markups to be higher when prices are higher . These consumers deem today 's transaction less fair , so they have a lower willingness to pay for the armchair ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_5": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_5",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_5",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_5",
		"text": "\\paragraph{Surveys of Firms} Following \\ct{BCL98} , researchers have surveyed more than 12,000 firms across developed economies about their pricing practices ( Table ~ \\ref{t:survey} ) . The typical study asks managers to evaluate the relevance of different pricing theories from the economics literature to explain their own pricing , in particular price rigidity . Amongst the theories that the managers deem most important , some version of fairness invariably appears , often called `` implicit contracts '' and described as follows : `` firms tacitly agree to stabilize prices , perhaps out of fairness to customers . '' Indeed , fairness appeals to firms more than any other theory , with a median rank of 1 and a mean rank of $1.9$ ( Table ~ \\ref{t:ranking} ) . The second most popular explanation for price rigidity takes the form of nominal contracts --- prices do not change because they are fixed by contracts : it has a median rank of 3 and a mean rank of $2.6$ . Two common macroeconomic theories of price rigidity --- menu costs and information delays --- do not resonate at all with firms , who rank them amongst the least popular theories , with mean and median ranks above ~ 9 ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_108": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_108",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_108",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_108",
		"text": "\\paragraph{Markup} Combining \\eqref{e:ma} with \\eqref{e:phia} , we obtain the following markup : \\begin{equation*} M = 1+\\frac{1}{\\e-1}\\cdot \\frac{1}{1+\\g\\e\\t/(\\e-1)} = 1+\\frac{1}{(1+\\g\\t)\\e-1}. \\end{equation*} This expression shows that $M$ is lower when $\\e$ , $\\g$ , or $\\t$ are higher ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_120": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_120",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_120",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_120",
		"text": "\\paragraph{First-Order Condition with Respect to Bonds} The first - order condition with respect to $B_{k}(t)$ is $\\pdx{\\Lc_{k}}{B_{k}(t)}=0$ , which gives \\begin{equation*} Q(t) \\Ac_{k}(t) = \\d \\E[t]{\\Ac_{k}(t+1)}. \\end{equation*} Using \\eqref{e:ak} , we obtain household ~ $k$ 's consumption Euler equation : \\begin{equation} Q(t)=\\d \\E[t]{\\frac{X(t) Z_{k}(t)}{X(t+1) Z_{k}(t+1)}}. \\label{e:eulerx}\\end{equation} This equation governs how the household smooths fairness - adjusted consumption over time ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_134": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_134",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_134",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_134",
		"text": "The fourth equation is the usual expression for the real wage , obtained by simplifying \\eqref{e:wkx} . Once again , by symmetry $X(t)=P(t)/F(t)$ and $Z_{k}(t)=F(t) Y(t)$ , so \\eqref{e:wkx} yields \\begin{equation*} \\frac{W(t)}{P(t)}=\\frac{\\n}{\\n-1} N(t)^{\\eta} Y(t). \\end{equation*} Combining this equation with \\eqref{e:y} , we express the real wage as a function of employment : \\begin{equation} \\frac{W(t)}{P(t)}=\\frac{\\n}{\\n-1} A(t) N(t)^{\\eta+\\a}. \\label{e:wp}\\end{equation}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_37": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_37",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_37",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_37",
		"text": "As the belief function $M^{p}(P)$ and fairness function $F(M^{p})$ are differentiable , customers enjoy an infinitesimal price reduction as much as they dislike an infinitesimal price increase . Therefore , the monopoly 's demand curve \\eqref{e:yd} has no kinks , unlike in pricing theories based on loss aversion \\cp{HK08} ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_23": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_23",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_23",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_23",
		"text": "Let $[0, C^h]$ be the set of all possible marginal costs for the monopoly . The monopoly knows its marginal cost $C \\in [0, C^h]$ , but customers do not ; instead , customers have non-atomistic prior beliefs over $[0, C^h]$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_35": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_35",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_35",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_35",
		"text": "\\paragraph{Analytical Results} Plugging the belief - updating rule \\eqref{e:cp} into $M^p= P/C^p$ gives the following :"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_21": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_21",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_21",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_21",
		"text": "Since the marginal cost is assumed to be observable , customers correctly perceive marginal cost ( $C^p = C$ ) , so the perceived markup equals the true markup ( $M^{p}=M$ ) . From \\eqref{e:e} , we see that the price elasticity of demand is $E=\\e+(\\e-1) \\cdot \\f(M)>\\e$ ; therefore , the markup charged by the monopoly satisfies \\begin{equation} M=1+\\frac{1}{\\e-1}\\cdot \\frac{1}{1+\\f(M)}. \\label{e:mo}\\end{equation} Since $\\f(M)$ is strictly increasing from $0$ to $+\\infty$ when $M$ increases from $0$ to $M^h$ ( Lemma ~ \\ref{l:phi} ) , the right - hand side of the equation is strictly decreasing from $\\e/(\\e-1)$ to 1 when $M$ increases from $0$ to $M^h > \\e/(\\e-1)>1$ . We infer that the fixed - point equation \\eqref{e:mo} admits a unique solution , located between 1 and $\\e/(\\e-1$ ) . Therefore , the markup $M$ is well - defined and $M\\in (1,\\e/(\\e-1))$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_122": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_122",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_122",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_122",
		"text": "\\paragraph{First-Order Conditions with Respect to Employment} We compute the first - order conditions with respect to $N_{jk}(t)$ for all labor services $k\\in[0,1]$ : $\\pdx{\\Lc_{j}}{N_{jk}(t)}=0$ . From the definition of $N_{j}(t)$ given by \\eqref{e:nj} , we know that \\begin{equation*} \\pd{N_{j}(t)}{N_{jk}(t)}=\\bs{\\frac{N_{jk}(t)}{N_{j}(t)}}^{-1/\\n} dk. \\end{equation*} Hence the first - order conditions imply that for all $k\\in[0,1]$ , \\begin{equation} W_{k}(t)= \\a \\Jc_{j}(t) A_{j}(t) N_{j}(t)^{\\a-1}\\bs{\\frac{N_{jk}(t)}{N_{j}(t)}}^{-1/\\n}. \\label{e:wk}\\end{equation}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_136": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_136",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_136",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_136",
		"text": "The sixth equation is a pricing equation , which is obtained by simplifying \\eqref{e:emj} . In equilibrium the stochastic discount factor is given by \\begin{equation*} \\G(t)= \\d^{t}\\cdot \\frac{X(0)Z(0)}{X(t) Z(t)}. \\end{equation*} Since by symmetry $Z(t)=F(t) Y(t)$ and $X(t)=P(t)/F(t)$ , we have \\begin{equation*} \\frac{\\G(t+1)}{\\G(t)}=\\d \\cdot\\frac{X(t)}{X(t+1)}\\cdot \\frac{Z(t)}{Z(t+1)}=\\d \\cdot\\frac{P(t)}{P(t+1)}\\cdot \\frac{Y(t)}{Y(t+1)}. \\end{equation*} Hence , \\eqref{e:emj} simplifies to \\begin{equation} \\frac{M(t)-1}{M(t)} E(M^p(t)) = 1-\\d\\g + \\d\\E[t]{\\frac{M(t+1)-1}{M(t+1)}\\bs{E(M^p(t+1))-(1-\\g) \\e}}. \\label{e:ema}\\end{equation} This pricing equation shows the dynamic relationship between actual and perceived price markups . Unlike the other equilibrium conditions --- which are the same as in the textbook model --- the pricing equation is unique to the model with fairness ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_7": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_7",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_7",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_7",
		"text": "\\paragraph{Survey of French Bakers} To better understand how firms incorporate fairness into their pricing decisions , we interviewed 31 bakers in France in 2007 . The French bread market makes a good case study because the market is large ; bakers set their prices freely ; and French people care enormously about bread . \\footnote{In 2005, bakeries employed 148,000 workers, for a yearly turnover of [unused10] billion euros (\\url{https://perma.cc/V679-UFE8} ) . Since 1978 , French bakers have been free to set their own prices , except during the inflationary period 1979 -- 1987 when price ceilings and growth caps were imposed . For centuries , bread prices caused major social upheaval in France . \\ct[p.~35]{M99} explains that before the French Revolution , `` affordable bread prices underlay any hopes for urban tranquility . '' During the Flour War of 1775 , mobs chanted `` if the price of bread does not go down , we will exterminate the king and the blood of the Bourbons ' ' ; following these riots , `` under intense pressure from irate and nervous demonstrators , the young governor of Versailles had ceded and fixed the price ` in the King 's name ' at two sous per pound , the mythohistoric just price inscribed in the memory of the century '' \\cp[p.~12]{K96} . } We sampled bakeries in Aix - en - Provence , Grenoble , Paimpol , and Paris . The interviews reveal that bakers are guided by norms of fairness when they adjust prices to preserve customer loyalty . In particular , cost - based pricing is widely used . Bakers only raise the price of bread in response to increases in the cost of flour , utilities , or wages . They refuse to increase prices in response to increased demand --- during weekends , during the summer tourist season , or during the holiday absences of local competitors . Bakers explained that pricing otherwise would be unfair , and hence would anger and drive away customers ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_6": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_6",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_6",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_6",
		"text": "\\begin{sidewaystable} [ p ] \\caption{Ranking of pricing theories in firm surveys}  \\footnotesize\\begin{tabular*} { \\textwidth}{@{\\extracolsep{\\fill} } lcccccccccccccccc }\\ toprule & \\multicolumn{14} { c } { Country of survey } & \\multicolumn{2} { c } { Overall rank } \\\\ \\cmidrule{2-15}  \\cmidrule{16-17} Theory & US & GB & SE & JP & CA & AT & BE & FR & LU & NL & PT & ES & NO & IS & Median & Mean \\\\ \\ midrule Implicit contracts & 4 & 5 & 1 & 1 & 2 & 1 & 1 & 4 & 1 & 2 & 1 & 1 & 2 & 1 & 1 & $1.9$ \\\\ Nominal contracts & 5 & 1 & 3 & 3 & 3 & 2 & 2 & 3 & 3 & 1 & 5 & 3 & 1 & 2 & 3 & $2.6$ \\\\ Coordination failure & 1 & 3 & 4 & 1 & 5 & 5 & 5 & 2 & 9 & 4 & 2 & 2 & 3 & 4 & $3.5$ & $3.6$ \\\\ Pricing points & 8 & 4 & 7 & 4 & - - & 10 & 13 & 8 & 10 & 7 & 11 & 6 & 4 & 5 & 7 & $7.5$ \\\\ Menu costs & 6 & 11 & 11 & 7 & 10 & 7 & 15 & 10 & 13 & 8 & 10 & 7 & 6 & 6 & 9 & $9.1$ \\\\ Information delays & 11 & -- & 13 & -- & 11 & 6 & 14 & -- & 15 & -- & 8 & 9 & 5 & - - & 11 & $10.2$ \\\\ \\bottomrule\\end{tabular*}  \\note{Survey respondents rated the relevance of several pricing theories to explain price rigidity at their own firm. The table ranks common theories amongst the alternatives. \\ct[Table~5.1]{BCL98} describes the theories as follows ( with wording that varies slightly across surveys ) : `` implicit contracts '' stands for `` firms tacitly agree to stabilize prices , perhaps out of fairness to customers '' ; `` nominal contracts '' stands for `` prices are fixed by contracts '' ; `` coordination failure '' stands for two closely related theories , which are investigated in separate surveys : `` firms hold back on price changes , waiting for other firms to go first '' and `` the price is sticky because the company loses many customers when it is raised , but gains only a few new ones when the price is reduced '' ( which is labeled `` kinked demand curve '' ) ; `` pricing points '' stands for `` certain prices ( like \\$9.99) have special psychological significance''; ``menu costs'' stands for ``firms incur costs of changing prices''; ``information delays'' stands for two closely related theories, which are investigated in separate surveys: ``hierarchical delays slow down decisions'' and ``the information used to review prices is available infrequently.'' The rankings of the theories are reported in Table~5.2 in \\ct{BCL98} ; Table ~ 3 in \\ct{HWY00} ; Table ~ 4 in \\ct{AFH05} ; Chart ~ 14 in \\ct{NHT00} ; Table ~ 8 in \\ct{AKW06} ; Table ~ 5 in \\ct{KBS05} ; Table ~ 18 in \\ct{AD05} ; Table ~ 6.1 in \\ct{LR04} ; Table ~ 8 in \\ct{LM06} ; Table ~ 10 in \\ct{HS06} ; Table ~ 4 in \\ct{M06} ; Table ~ 5 in \\ct{AH05} ; Chart ~ 26 in \\ct{LNW08} ; and Table ~ 17 in \\ct{OPV11} . } \\label{t:ranking}  \\end{sidewaystable}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_137": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_137",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_137",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_137",
		"text": "The seventh and final equation is the law of motion of the perceived price markup . It derives from the law of motion of the perceived marginal cost , given by \\eqref{e:cpj} . Since $M^p(t)=P(t)/C^p(t)$ , \\eqref{e:cpj} implies \\begin{equation*} M^p(t) = \\bs{\\frac{P(t)}{(\\e-1)P(t)/\\e}}^{1-\\g} \\bs{\\frac{P(t)}{C^p(t-1)}}^{\\g} = \\bp{\\frac{\\e}{\\e-1}}^{1-\\g} \\bs{\\frac{P(t)}{P(t-1)}}^{\\g} \\bs{\\frac{P(t-1)}{C^p(t-1)}}^{\\g}. \\end{equation*} Hence the perceived price markup satisfies \\begin{equation} M^p(t) = \\bp{\\frac{\\e}{\\e-1}}^{1-\\g} \\bs{\\frac{P(t)}{P(t-1)}}^{\\g}\\bs{M^p(t-1)}^{\\g}. \\label{e:mpt}\\end{equation}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_123": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_123",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_123",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_123",
		"text": "Toward deriving firm ~ $j$ 's labor demand , we introduce the wage index \\begin{equation} W(t) = \\bs{\\int_{0}^1 W_{k}(t)^{1-\\n}\\,dk}^{1/(1-\\n)}. \\label{e:w}\\end{equation} Taking \\eqref{e:wk} to the power of $1-\\n$ , we obtain \\begin{equation*} W_{k}(t)^{1-\\n} = \\bs{\\a \\Jc_{j}(t) A_{j}(t) N_{j}(t)^{\\a-1}}^{1-\\n} \\frac{1}{N_{j}(t)^{(\\n-1)/\\n}} N_{jk}(t)^{(\\n-1)/\\n}. \\end{equation*} Integrating this condition over $k\\in[0,1]$ and using the definitions of $N_{j}$ and $W$ given by \\eqref{e:nj} and \\eqref{e:w} , we find \\begin{equation*} W(t)^{1-\\n} = \\bs{\\a \\Jc_{j}(t) A_{j}(t) N_{j}(t)^{\\a-1}}^{1-\\n} \\frac{N_{j}(t)^{(\\n-1)/\\n}}{N_{j}(t)^{(\\n-1)/\\n}}. \\end{equation*} From this equation we infer \\begin{equation} W(t) = \\a \\Jc_{j}(t) A_{j}(t) N_{j}(t)^{\\a-1}. \\label{e:jj}\\end{equation}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_20": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_20",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_20",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_20",
		"text": "The proof is simple algebra and relegated to Appendix ~ A . The property that the superelasticity of the fairness function is positive plays a central role in the analysis . It means that the fairness function is more elastic at higher perceived markups . This property follows from Definition ~ \\ref{d:fairness} because a positive , decreasing , and weakly concave function always has positive superelasticity . \\footnote{The concavity of the fairness function is not a necessary condition for the results in the paper: the necessary condition is that the superelasticity of the fairness function is positive. This occurs with concave functions but also with other not-too-convex functions. For example, the logistic function [unused10] with [unused10] is not concave but it has a positive superelasticity: [unused10] . All the results would carry over with a logistic fairness function. We limit ourselves to concave fairness functions instead of allowing for any fairness function with a positive superelasticity because we find such restriction more natural and easier to interpret.}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_34": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_34",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_34",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_34",
		"text": "Despite its apparent arbitrary nature , the assumption of subproportional inference has close ties to game - theoretic models of failure of contingent thinking . It is related to the concept of cursed equilibrium , developed by \\ct{ER05} , and to the concept of analogy - based - expectation equilibrium , developed by \\ct{J05} and extended to Bayesian games by \\ct{JK08} . Both concepts propose mechanisms that can be used to explain why people might fail to account for the information that equilibrium prices reveal about marginal costs . \\footnote{In fact, with [unused10] , the beliefs given by \\eqref{e:cp} resemble those in a fully cursed equilibrium and the coarsest analogy - based - expectation equilibrium , when recasting our model as a Bayesian game , as in Section ~ \\ref{s:rational} . In these equilibrium concepts , an unsophisticated household infers nothing about marginal cost from any economic variable . Consequently , a consumer with average prior beliefs about marginal cost equal to $C^b$ would continue to perceive marginal costs with mean $C^b$ given any price . } Subproportional inference is also related to the cursed - expectation equilibrium developed by \\ct{ERV19} as an alternative to rational - expectations equilibrium in markets . \\footnote{In a cursed-expectation equilibrium of a model in which traders endowed with private information trade a risky asset, each trader forms an expectation about the value of the asset equal to a geometric average of her expectation conditional upon her private signal alone and her expectation conditional upon both her private signal and the market price. Traders' expectations therefore take the form of a weighted average of naive beliefs and correct beliefs. The two rules differ in that consumers in our model average naive beliefs with a particular form of incorrect beliefs (proportional inference); to include rational updating as a limit case, we calibrate the updating rule to match correct equilibrium beliefs for the case in which all consumers are rational. We adopt this approach for its tractability.}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_53": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_53",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_53",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_53",
		"text": "\\paragraph{Firms} Firm ~ $j$ hires labor to produce output using the production function \\begin{equation} Y_{j}(t)=A_{j}(t) N_{j}(t)^{\\a}, \\label{e:yj}\\end{equation} where $Y_{j}(t)$ is output of good ~ $j$ , $A_{j}(t)>0$ is its technology level , $\\a\\in(0,1]$ is the extent of diminishing marginal returns to labor , and \\begin{equation*} N_{j}(t)= \\bs{\\int_{0}^1 N_{jk}(t)^{(\\n-1)/\\n}\\,dk}^{\\n/(\\n-1)} \\end{equation*} is an employment index . In the index , $N_{jk}(t)$ is the quantity of labor service ~ $k$ hired by firm ~ $j$ , and $\\n>1$ is the elasticity of substitution between different labor services . The technology level $A_{j}(t)$ is stochastic and unobservable to households --- making the firm 's marginal cost unobservable ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_47": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_47",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_47",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_47",
		"text": "Having inferred the marginal cost , households deduce that the markup charged by firm ~ $j$ is $M^{p}_{j}(t)=P_{j}(t)/C^{p}_{j}(t)$ . This perceived markup determines the fairness of the transaction with firm ~ $j$ , measured by $F_{j}(M^{p}_{j}(t))$ . The fairness function $F_{j}$ , specific to good ~ $j$ , satisfies the conditions listed in Definition ~ \\ref{d:fairness} . The elasticity of $F_{j}$ with respect to $M^{p}_{j}$ is $\\f_{j} = -\\odlx{F_{j}}{M^{p}_{j}}$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_90": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_90",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_90",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_90",
		"text": "\\paragraph{Comparison with Macroevidence} The property that higher steady - state inflation leads to higher steady - state employment is consistent with evidence that higher average inflation leads to lower average unemployment . \\ct[Table~1]{KW94} find in US data that a permanent increase in inflation by 1 percentage point reduces the unemployment rate between $0.2$ and $1.3$ percentage points , depending on the period and identification strategy . \\ct{KW97} confirm these findings , while highlighting the uncertainty surrounding the Phillips curve 's slope ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_84": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_84",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_84",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_84",
		"text": "\\begin{proposition} \\label{p:longrun} In the New Keynesian model with fairness , the steady - state price markup is a strictly decreasing function of steady - state inflation : \\begin{equation} \\ol{M}(\\ol{\\pi})=1+\\frac{1}{\\e-1}\\cdot\\frac{1}{1+\\frac{(1-\\d)\\g}{1-\\d\\g}\\ol{\\f}(\\ol{\\pi})}. \\label{e:mss}\\end{equation} Hence , steady - state employment is a strictly increasing function of steady - state inflation : \\begin{equation*} \\ol{N}=\\bs{\\frac{(\\n-1) \\a}{\\n}\\cdot\\frac{1}{\\ol{M}(\\ol{\\pi})}}^{1/(1+\\eta)}. \\end{equation*} Thus , the long - run Phillip s curve is not vertical ( fixed $\\ol{N}$ ) but upward sloping . \\end{proposition}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_144": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_144",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_144",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_144",
		"text": "\\paragraph{Proof of Lemma~\\ref{l:longrun} } The expression for the steady - state perceived price markup $\\ol{M^p}$ comes from \\eqref{e:mpss} . The expression for the steady - state fairness factor $\\ol{F} = F(\\ol{M^p})$ follows from combining \\eqref{e:facclim} with \\eqref{e:mf} . Last , the expression for the steady - state elasticity of the fairness function \\begin{equation*} \\ol{\\f} = \\f(\\ol{M^p}) = -F'(\\ol{M^p})\\cdot \\frac{\\ol{M^p}}{F(\\ol{M^p})} \\end{equation*} comes from noting that with the fairness function \\eqref{e:facclim} , $F'(M^p) = -\\t$ . The properties that $\\ol{M^p}$ and $\\ol{\\f}$ are strictly increasing in $\\ol{\\pi}$ , and that $\\ol{F}$ is weakly decreasing in $\\ol{\\pi}$ , follow from the assumptions that $\\e>1$ , $\\g\\in(0,1)$ , $\\t>0$ , and $1-\\c \\geq 0$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_150": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_150",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_150",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_150",
		"text": "First , $\\e$ influences the slope of the long - run Phillips curve through \\begin{equation*} (\\e-1) \\frac{\\bs{1+\\frac{(1-\\d)\\g}{1-\\d\\g}\\t}\\e-1}{\\bs{1+(1-\\c)\\t}\\e-1}, \\end{equation*} which can be rewritten as \\begin{equation*} \\frac{\\bs{1+\\frac{(1-\\d)\\g}{1-\\d\\g}\\t}\\e-1}{(1-\\c)\\t\\frac{\\e}{\\e-1}+1}. \\end{equation*} Since $\\e/(\\e-1)$ is decreasing in $\\e$ and \\begin{equation*} \\bs{1+\\frac{(1-\\d)\\g}{1-\\d\\g}\\t}\\e-1 \\end{equation*} is increasing in $\\e$ , the slope of the long - run Phillips curve is increasing in $\\e$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_151": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_151",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_151",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_151",
		"text": "Second , since $\\c$ appears only once in \\eqref{e:dpi} , it is clear that the slope of the long - run Phillips curve is increasing in $\\c$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_145": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_145",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_145",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_145",
		"text": "\\paragraph{Proof of Proposition~\\ref{p:longrun} } The expressions for the steady - state price markup $\\ol{M}$ and steady - state employment $\\ol{N}$ come from \\eqref{e:mssa} and \\eqref{e:nssa} . Since $\\d<1$ , $\\g\\in(0,1)$ , and $\\ol{\\f}>0$ is strictly increasing in $\\ol{\\pi}$ ( Lemma ~ \\ref{l:longrun} ) , it follows that $\\ol{M}$ is strictly decreasing in $\\ol{\\pi}$ . And since $\\a>0$ , $\\n>1$ , $\\eta>0$ , and $\\ol{M}>0$ is strictly decreasing in $\\ol{\\pi}$ , it follows that $\\ol{N}$ is strictly increasing in $\\ol{\\pi}$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_85": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_85",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_85",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_85",
		"text": "The proof appears in Appendix ~ B. 3 ; its main step is reworking \\eqref{e:em} in steady state to obtain $\\ol{M}$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_91": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_91",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_91",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_91",
		"text": "Quantitatively , the findings by \\ct{KW94} also agree with our model 's predictions . Abstracting from possible changes in labor force participation , their findings imply that increasing inflation by 1 percentage point raises employment by $0.2\\%$ to $1.3\\%$ . This magnitude matches the simulation results for a degree of acclimation between $\\c=0$ and $\\c=0.7$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_46": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_46",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_46",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_46",
		"text": "\\paragraph{Fairness Concerns} Households cannot observe firms ' marginal costs . When a household purchases good ~ $j$ at price $P_{j}(t)$ in period ~ $t$ , it infers that firm ~ $j$ 's marginal cost is $C^{p}_{j}(t)$ . The model is dynamic so it provides a natural candidate for the anchor that households use when inferring costs : last period 's perception of marginal cost . Hence , instead of being given by \\eqref{e:cp} as in the monopoly model , households ' perception of firm ~ $j$ 's marginal cost at time ~ $t$ is given by \\begin{equation} C^{p}_{j}(t)= \\bs{C^{p}_{j}(t-1)}^{\\g}\\bs{\\frac{\\e-1}{\\e} P_{j}(t)}^{1-\\g}, \\label{e:cpj}\\end{equation} where $C^{p}_{j}(t-1)$ is last period 's perceived cost , and $\\g\\in(0,1)$ is the degree of underinference ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_52": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_52",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_52",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_52",
		"text": "Finally , in each period ~ $t$ , household ~ $k$ chooses purchases $Y_{jk}(t)$ for each $j\\in[0,1]$ , labor supply $N_{k}(t)$ , bond holdings $B_{k}(t)$ , and wage rate $W_{k}(t)$ . The household 's objective is to maximize its expected utility subject to the budget constraint , to the solvency constraint , and to firms ' demand for labor service ~ $k$ . The household takes as given its initial endowment of bonds $B_{k}(-1)$ , all fairness factors $F_{j}(t)$ , all prices $P_{j}(t)$ and $Q(t)$ , and dividends $V_{k}(t)$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_78": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_78",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_78",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_78",
		"text": "Figure ~ \\ref{f:technology} displays the response to the positive technology shock . The inflation rate is expressed as a deviation from its steady - state value , measured in percentage points and annualized ( by multiplying by four the variable $\\wh{\\pi}(t)$ ) ; all other variables are expressed as percentage deviations from their steady - state values ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_44": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_44",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_44",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_44",
		"text": "\\begin{corollary}  \\label{c:subproportional} Assume that customers care about fairness according to the fairness function \\eqref{e:f} , infer subproportionally , and are acclimated . Then the monopoly 's markup is given by \\begin{equation*} M = 1+\\frac{1}{\\bp{1+\\g\\t} \\e-1}. \\end{equation*} The markup decreases with the competitiveness of the market ( $\\e$ ) , concern for fairness ( $\\t$ ) , and degree of underinference ( $\\g$ ) . And the cost passthrough is given by \\begin{equation*} \\b = 1\\bigg/\\bc{1+\\frac{\\g^{2} \\t \\bs{\\bp{1+\\t} \\e-1}}{ \\bp{\\e-1}\\bp{1+\\g\\t}\\bs{\\bp{1+\\g\\t} \\e-1}}}. \\end{equation*} The passthrough increases with the competitiveness of the market ( $\\e$ ) ; it decreases with the concern for fairness ( $\\t$ ) and degree of underinference ( $\\g$ ) . \\end{corollary}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_50": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_50",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_50",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_50",
		"text": "To smooth consumption over time , households trade one - period bonds . In period ~ $t$ , household ~ $k$ holds $B_{k}(t)$ bonds . Bonds purchased in period ~ $t$ have a price $Q(t)$ , mature in period ~ $t+1$ , and pay one unit of money at maturity ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_87": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_87",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_87",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_87",
		"text": "The impact of competitiveness , fairness concern , and degree of underinference on the slope of the long - run Phillips curve is reminiscent of the impact of these parameters on the cost passthrough in the monopoly model ( see Corollary ~ \\ref{c:subproportional} ) . The impact of the degree of acclimation is easily understandable . With more acclimation , perceived fairness ( $\\ol{F}$ ) depends less on inflation , because consumers adapt more to different inflation rates . As a result , the elasticity of the fairness function ( $\\ol{\\f}$ ) depends less on inflation , and so the Phillips curve \\eqref{e:mss} is steeper ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_93": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_93",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_93",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_93",
		"text": "\\paragraph{No Fairness Concerns} Without fairness concerns , the price elasticity of demand is $E=\\e$ ( Section ~ \\ref{s:nofairness} ) . Hence the derivative \\eqref{e:dvdp} becomes \\begin{equation*} V'(P) =Y^{d}(P) \\bs{1 - \\e\\frac{P-C}{P}}. \\end{equation*} The function $P\\mapsto (P-C)/P$ is strictly increasing from 0 to 1 as $P$ increases from $C$ to $+\\infty$ , so the term in square brackets is strictly decreasing from 1 to $1-\\e<0$ as $P$ increases from $C$ to $+\\infty$ . Hence , the term in square brackets has a unique root $P^*$ on $(C,+\\infty)$ , is positive for $P<P^*$ , and is negative for $P>P^*$ . Since $Y^d(P)>0$ , these properties transfer to the derivative of the profit function : $V'(P)>0$ for $P\\in(C,P^*)$ , $V'(P)=0$ at $P=P^*$ , and $V'(P)<0$ for $P\\in(P^*,+\\infty)$ . We conclude that the profit function is unimodal , and its maximum $P^*$ is the unique solution to the first - order condition $V'(P)=0$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_153": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_153",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_153",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_153",
		"text": "Fourth , $\\g$ influences the slope of the long - run Phillips curve through \\begin{equation*} \\frac{(1-\\g)(1-\\d\\g)}{\\g^2} \\bs{1+\\frac{(1-\\d)\\g}{1-\\d\\g}\\t}\\bs{\\e-1+\\frac{(1-\\d)\\g}{1-\\d\\g}\\t\\e}, \\end{equation*} which can be rewritten as \\begin{equation*} \\bs{\\frac{1-\\d\\g}{\\g}+(1-\\d)\\t}\\bs{\\frac{(\\e-1)(1-\\g)}{\\g}+\\frac{1-\\g}{1-\\d\\g}(1-\\d)\\t\\e}. \\end{equation*} First , $(1-\\d\\g)/\\g$ and $(1-\\g)/\\g$ are decreasing in $\\g$ . Second , since $\\d<1$ , $(1-\\g)/(1-\\d\\g)$ is decreasing in $\\g$ . Thus , the slope of the long - run Phillips curve is decreasing in $\\g$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_147": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_147",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_147",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_147",
		"text": "Second , the expression of the steady - state price markup $\\ol{M}$ in Proposition ~ \\ref{p:longrun} yields \\begin{equation} \\odl{\\ol{M}}{\\ol{\\f}} = \\frac{\\ol{\\f}}{\\ol{M}}\\cdot \\od{\\ol{M}}{\\ol{\\f}} = \\frac{\\ol{\\f}}{\\ol{M}}\\cdot \\frac{1}{\\e-1}\\cdot \\frac{-1}{\\bs{1+\\frac{(1-\\d)\\g}{1-\\d\\g}\\ol{\\f}}^2}\\cdot \\frac{(1-\\d)\\g}{1-\\d\\g}, \\label{e:dm}\\end{equation} and \\begin{equation} (\\e-1) \\bs{1+\\frac{(1-\\d)\\g}{1-\\d\\g}\\ol{\\f}} \\ol{M} = 1 + (\\e-1) \\bs{1+\\frac{(1-\\d)\\g}{1-\\d\\g}\\ol{\\f}} = \\e + (\\e-1) \\frac{(1-\\d)\\g}{1-\\d\\g}\\ol{\\f}. \\label{e:mssa2}\\end{equation} Combining \\eqref{e:dm} and \\eqref{e:mssa2} , we obtain \\begin{equation*} -\\odl{\\ol{M}}{\\ol{\\f}} = \\frac{(1-\\d)\\g}{1-\\d\\g} \\cdot \\ol{\\f} \\cdot \\frac{1}{\\e + (\\e-1) \\frac{(1-\\d)\\g}{1-\\d\\g}\\ol{\\f}}\\cdot \\frac{1}{1+\\frac{(1-\\d)\\g}{1-\\d\\g}\\ol{\\f}}. \\end{equation*} Hence , using \\eqref{e:longrun} , we find that around the zero - inflation steady state , \\begin{equation} -\\odl{\\ol{M}}{\\ol{\\f}} = \\frac{(1-\\d)\\g}{1-\\d\\g} \\cdot \\frac{\\t}{1+\\frac{(1-\\d)\\g}{1-\\d\\g}\\t}\\cdot \\frac{1}{\\bs{1+\\frac{(1-\\d)\\g}{1-\\d\\g}\\t}\\e-1}. \\label{e:dm2}\\end{equation}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_146": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_146",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_146",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_146",
		"text": "\\paragraph{Proof of Corollary~\\ref{c:longrun} } First , the expressions for the steady - state perceived price markup , $\\ol{M^p}$ , steady - state fairness factor , $\\ol{F}$ , and steady - state elasticity of the fairness function , $\\ol{\\f}$ , in Lemma ~ \\ref{l:longrun} indicate that around the zero - inflation steady state , \\begin{equation} \\ol{M^p} = \\frac{\\e}{\\e-1},\\qquad \\ol{F}=1,\\qquad \\ol{\\f}=\\frac{\\t\\e}{\\e-1}. \\label{e:longrun}\\end{equation} These expressions also show that \\begin{align*} \\od{\\ln(\\ol{M^p} ) }{ \\ol{\\pi} } & = [unused10] { 1 - \\ g } \\\\ \\od{\\ln(\\ol{F} ) }{ \\ol{\\pi} } & = - \\t \\cdot (1-\\c) \\cdot \\frac{\\ol{M^p} }{ [unused10] } [unused10] ) }{ [unused10] }\\\\ \\od{\\ln(\\ol{\\f} ) }{ \\ol{\\pi} } & = \\od{\\ln(\\ol{M^p} ) }{ \\ol{\\pi} } - \\od{\\ln(\\ol{F} ) }{ \\ol{\\pi} }. \\end{align*} Hence , around the zero - inflation steady state , we have \\begin{equation*} \\od{\\ln(\\ol{F})}{\\ol{\\pi}} = - (1-\\c) \\cdot \\frac{\\t\\e}{\\e-1} \\cdot \\frac{\\g}{1-\\g} \\end{equation*} and \\begin{equation} \\od{\\ln(\\ol{\\f})}{\\ol{\\pi}} = \\frac{\\g}{1-\\g} \\bs{1 + (1-\\c) \\cdot \\frac{\\t\\e}{\\e-1}}. \\label{e:dphi}\\end{equation}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_152": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_152",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_152",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_152",
		"text": "Third , $\\t$ influences the slope of the long - run Phillips curve through \\begin{equation*} \\frac{1}{\\t} \\cdot \\frac{\\bs{1+\\frac{(1-\\d)\\g}{1-\\d\\g}\\t}\\bs{\\bp{1+\\frac{(1-\\d)\\g}{1-\\d\\g}\\t}\\e-1}}{\\bs{1+(1-\\c)\\t}\\e-1}, \\end{equation*} which can be rewritten as \\begin{equation*} \\X(\\t) = \\frac{\\bs{1+\\frac{(1-\\d)\\g}{1-\\d\\g}\\t}\\bs{\\frac{(1-\\d)\\g}{1-\\d\\g}\\t+\\frac{\\e-1}{\\e}}}{\\t\\bs{(1-\\c)\\t +\\frac{\\e-1}{\\e}}}. \\end{equation*} The function $\\X(\\t)$ is a quadratic - quadratic rational function , whose behavior can be determined from its asymptotes and zeros . The function has two vertical asymptotes , at \\begin{equation*} \\t = -\\frac{\\e-1}{(1-\\c)\\e}<0 \\quad \\text{and}\\quad \\t=0, \\end{equation*} and a horizontal asymptote , at \\begin{equation} \\X = \\bs{\\frac{(1-\\d)\\g}{1-\\d\\g}}^2 \\cdot \\frac{1}{1-\\c}>0. \\label{e:Xi}\\end{equation} Moreover , both zeros of $\\X(\\t)$ are negative , at \\begin{equation*} \\t = -\\frac{1-\\d\\g}{(1-\\d)\\g}<0 \\quad \\text{and}\\quad \\t= -\\frac{\\e-1}{\\e}\\cdot\\frac{1-\\d\\g}{(1-\\d)\\g}<0. \\end{equation*} Hence , the function $\\X(\\t)$ cannot cross the $x$ - axis when $\\t>0$ . This means that it must approach its positive horizontal asymptote from above , decreasing from $+\\infty$ when $\\t\\to 0^+$ toward the horizontal asymptote \\eqref{e:Xi} when $\\t\\to +\\infty$ . Thus , $\\X(\\t)$ is decreasing in $\\t>0$ , and so is the slope of the long - run Phillips curve ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_92": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_92",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_92",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_92",
		"text": "The monopoly chooses a price $P>C$ to maximize profits \\begin{equation*} V(P) = (P-C) \\cdot Y^{d}(P). \\end{equation*} The profit function is differentiable . Its derivative is \\begin{equation*} V'(P) = Y^{d}+\\bp{P-C} \\od{Y^{d}}{P} =Y^{d}- \\bp{P-C} \\frac{Y^d}{P} E(P), \\end{equation*} where \\begin{equation*} E(P) \\equiv -\\odl{Y^{d}}{P} = -\\frac{P}{Y^d}\\cdot\\od{Y^{d}}{P} \\end{equation*} is the price elasticity of demand . Hence the derivative of the profit function satisfies \\begin{equation} V'(P) =Y^{d}(P) \\bs{1 - \\frac{P-C}{P} E(P)}. \\label{e:dvdp}\\end{equation} We now study the properties of the derivative \\eqref{e:dvdp} in the various cases considered in Section ~ \\ref{s:monopoly} ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_86": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_86",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_86",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_86",
		"text": "\\begin{corollary} \\label{c:longrun} In the New Keynesian model with fairness , around the zero - inflation steady state , the slope of the long - run Phillips curve is \\begin{equation*} \\od{\\ol{\\pi}}{\\ln(\\ol{N})} = \\frac{1+\\eta}{1-\\d}\\cdot \\frac{(1-\\g)(1-\\d\\g)}{\\g^2}\\cdot \\frac{\\e-1}{\\t} \\cdot \\frac{\\bs{1+\\frac{(1-\\d)\\g}{1-\\d\\g}\\t}\\bs{\\bp{1+\\frac{(1-\\d)\\g}{1-\\d\\g}\\t}\\e-1}}{\\bs{1+(1-\\c)\\t}\\e-1}. \\end{equation*} The slope increases with the competitiveness of the goods market ( $\\e$ ) and degree of acclimation ( $\\c$ ) ; it decreases with the concern for fairness ( $\\t$ ) and degree of underinference ( $\\g$ ) . \\end{corollary}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_51": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_51",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_51",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_51",
		"text": "Household ~ $k$ 's consumption - savings decisions in each period ~ $t$ must obey the constraint \\begin{equation*} \\int_{0}^{1} P_{j}(t) Y_{jk}(t)\\,dj + Q(t) B_{k}(t) = W_{k}(t) N_{k}(t)+ B_{k}(t-1)+V_{k}(t), \\end{equation*} where $W_{k}(t)$ is the wage rate for labor service ~ $k$ , and $V_{k}(t)$ are dividends from firm ownership . In addition , household ~ $k$ satisfies a solvency constraint that prevents Ponzi schemes ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_45": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_45",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_45",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_45",
		"text": "A continuum of firms indexed by ~ $j\\in[0,1]$ and a continuum of households indexed by $k\\in [0,1]$ make up the economy . Firms use labor services to produce goods . Households supply labor services , consume goods , and save using riskless nominal bonds . Since goods are imperfect substitutes for one another , and labor services are also imperfect substitutes , firms exercise some monopoly power on the goods market , and households exercise some monopoly power on the labor market ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_79": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_79",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_79",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_79",
		"text": "The increase in technology reduces marginal costs , pulling down inflation . Observing lower prices , customers underinfer the underlying decrease in marginal costs and thus perceive lower price markups and fairer transactions . The improvement in perceived fairness decreases the price elasticity of the demand for goods . Firms best respond by raising their markups . The price markup increases by $1.3\\%$ at the peak , which depresses employment by $0.7\\%$ . Despite the drop in employment , output initially increases by $0.5\\%$ due to improved technology ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_41": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_41",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_41",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_41",
		"text": "\\paragraph{Comparison with Microevidence} The result that prices do not fully respond to marginal - cost shocks accords well with evidence on real firm behavior . First , using matched data on product prices and producers ' unit labor cost in Sweden , \\ct{CS12} find a passthrough of idiosyncratic marginal - cost changes into prices of only $0.3$ . Second , using production data for Indian manufacturing firms , \\ct[Table~7]{DGK16} find that following trade liberalization in India , marginal costs fell significantly due to the import tariff reduction , yet prices failed to fall in step : they estimate passthroughs between $0.3$ and $0.4$ . Third , using production and cost data for Mexican manufacturing firms , \\ct[Table~7]{CCW17} also find a modest passthrough of idiosyncratic marginal - cost changes into prices : between $0.2$ and $0.4$ . Last , combining production data for US manufacturing firms with data on energy prices and consumption , \\ct[Tables~5 and 6]{GSW19} find a moderate passthrough of marginal - cost changes caused by energy - price variations into prices : between $0.5$ and $0.7$ . Taking the midpoint estimates from the four studies , we find an average passthrough of $0.3+0.35+0.3+0.6=0.4$ . Such cost passthrough is well below ~ 1 ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_55": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_55",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_55",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_55",
		"text": "\\paragraph{Monetary Policy} The nominal interest rate is determined by a simple monetary - policy rule : \\begin{equation} i(t)=i_{0}(t)+\\p \\pi(t), \\label{e:taylor}\\end{equation} where $i_{0}(t)$ is a stochastic exogenous component , $\\pi(t)$ is the inflation rate , and $\\p>1$ governs the response of the interest rate to inflation ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_69": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_69",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_69",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_69",
		"text": "We also need to calibrate a parameter specific to the textbook model : $\\x$ , which governs price rigidity . To generate price rigidity , the New Keynesian literature uses either the staggered pricing of \\ct{C83} or the price - adjustment cost of \\ct{R82} . Both pricing assumptions lead to the same linearized Phillips curve around the zero - inflation steady state , and therefore to the same simulations \\cp{R95} . But the \\name{C83} interpretation of $\\x$ is easier to map to the data , so we use it for calibration . The parameter $\\x$ indicates the share of firms that cannot update their price each period ; it can be calibrated from microevidence on the frequency of price adjustments . If a share $\\x$ of firms keep their price fixed each period , the average duration of a price spell is $1/(1-\\x)$ \\cp[p.~43]{G08} . In the microdata underlying the US Consumer Price Index , the mean duration of price spells is about 3 quarters \\cp[Table~1]{NS13} . Hence , we set $1/(1-\\x)=3$ , which implies $\\x=0.67$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_82": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_82",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_82",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_82",
		"text": "The proof involves manipulating the inference mechanism ~ \\eqref{e:cpj} to obtain $\\ol{M^p}$ , and using \\eqref{e:facclim} and \\eqref{e:mf} to obtain $\\ol{F}$ and $\\ol{\\f}$ . It appears in Appendix ~ B. 3 ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_96": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_96",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_96",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_96",
		"text": "\\paragraph{Fairness Concerns and Subproportional Inference of Costs} With fairness concerns and subproportional inference of costs , the price elasticity of demand is $E=\\e+(\\e-1)\\g\\f(M^p(P))$ ( Section ~ \\ref{s:subproportional} ) . The profit function is now defined for $P\\in (C, P^b)$ , where the upper bound is defined by \\begin{equation} P^b = \\frac{\\e}{\\e-1} (M^h)^{1/\\g} C^b. \\label{e:pb}\\end{equation} The price $P^b$ is such that at $P^b$ , the perceived markup reaches the upper bound of the domain of the fairness function : $M^p(P^b)=M^h$ . We know that $P^b > C$ because $C^b > (\\e-1) \\cdot (M^h)^{-1/\\g} \\cdot C/\\e$ ( Definition ~ \\ref{d:subproportional} ) . The derivative \\eqref{e:dvdp} becomes \\begin{equation*} V'(P) =Y^{d}(P) \\bs{1 - \\frac{P-C}{P} \\cdot \\bc{\\e+(\\e-1)\\g\\f(M^p(P))}}. \\end{equation*} Again , the function $P\\mapsto (P-C)/P$ is strictly increasing from 0 to 1 as $P$ increases from $C$ to $+\\infty$ . The perceived markup $M^p(P)$ is strictly increasing from $M^p(C)>0$ to $M^h$ as $P$ increases from $C$ to $P^b$ ( Lemma ~ \\ref{l:subproportional} ) . Hence , the elasticity of the fairness function $\\f(M^p(P))$ is strictly increasing from $\\f(M^p(C))>0$ to $+\\infty$ as $P$ increases from $C$ to $P^b$ ( Lemma ~ \\ref{l:phi} ) . Since $\\g>0$ , we infer that the term in square brackets is strictly decreasing from 1 to $-\\infty$ as $P$ increases from $C$ to $P^b$ . Thus the term in square brackets has a unique root $P^*$ on $(C,P^b)$ , is positive for $P<P^*$ , and is negative for $P>P^*$ . Following the same argument as in the previous cases , we conclude that the profit function is unimodal , and its maximum $P^*$ is the unique solution to the first - order condition $V'(P)=0$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_156": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_156",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_156",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_156",
		"text": "As a first step toward computing the Phillip s curve , we compute the elasticity of the price elasticity of demand $E(M^p) = \\e+(\\e-1)\\g\\f(M^p)$ . Given that the elasticity of $\\f(M^p)$ is $\\s$ ( Lemma ~ \\ref{l:phi} ) , the elasticity of $E(M^p)$ at the steady state is \\begin{equation} \\odl{E}{M^p} = \\frac{(\\e-1)\\g\\ol{\\f}}{\\e+(\\e-1) \\g \\ol{\\f}}\\cdot \\ol{\\s} \\equiv \\O_{0}. \\label{e:omega0}\\end{equation} Second , we introduce the auxiliary function \\begin{equation*} \\L_1(M) = \\frac{M-1}{M}. \\end{equation*} The elasticity of $\\L_1(M)$ at the steady state is \\begin{equation*} \\odl{\\L_1}{M} =\\frac{\\ol{M}}{\\ol{M}-1}-1 = \\frac{1}{\\ol{M}-1}\\equiv \\O_{1}. \\end{equation*} Using the value of $\\ol{M}$ in \\eqref{e:mssa} , we find that $\\O_1$ satisfies \\begin{equation} \\O_1 = (\\e-1)\\bs{1+\\frac{(1-\\d)\\g}{1-\\d\\g}\\ol{\\f}}. \\label{e:omega1}\\end{equation} The left - hand side of \\eqref{e:ema} can be written $LHS = \\L_1(M(t)) \\cdot E(M^p(t))$ . Accordingly , around the steady state the log - linear approximation of $LHS$ is \\begin{equation} \\ln(LHS)-\\ln(\\ol{LHS}) = \\O_{1} \\wh{m}(t) + \\O_{0} \\wh{m^p}(t). \\label{e:lhs}\\end{equation}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_142": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_142",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_142",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_142",
		"text": "Third , in steady state the law of motion of the perceived price markup \\eqref{e:mpt} implies that \\begin{equation*} (\\ol{M^p})^{1-\\g}= \\bp{\\frac{\\e}{\\e-1}}^{1-\\g} \\bs{\\frac{P(t)}{P(t-1)}}^{\\g} . \\end{equation*} Taking this expression to the power of $1/(1-\\g)$ , and noting that in steady state $P(t)/P(t-1)=\\exp(\\ol{\\pi})$ , we find that the steady - state perceived price markup is \\begin{equation} \\ol{M^{p}} = \\frac{\\e}{\\e-1} \\exp{\\frac{\\g}{1-\\g} \\ol{\\pi}}. \\label{e:mpss}\\end{equation}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_143": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_143",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_143",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_143",
		"text": "Fourth , in steady state the pricing equation \\eqref{e:ema} implies that \\begin{equation} 0 = 1-\\d\\g - \\frac{\\ol{M}-1}{\\ol{M}} E(\\ol{M^p}) + \\d \\frac{\\ol{M}-1}{\\ol{M}} \\bs{E(\\ol{M^p})-(1-\\g) \\e}. \\label{e:emss1}\\end{equation} Shuffling this expression , we obtain the following : \\begin{align} 0 &= ( 1 - \\d\\g) \\ol{M} - ( [unused10] - 1 ) E ( \\ol{M^p} ) + [unused10] -1 ) \\bs{E(\\ol{M^p} ) - ( 1 -\\g ) \\e }\\ nonumber \\\\ 0 &= \\bs{1-\\d\\g - (1-\\d)E(\\ol{M^p} ) - \\d(1-\\g)\\e} \\ol{M} + ( 1 - \\d)E(\\ol{M^p} ) +\\d ( 1 -\\g ) \\e\\ nonumber \\\\ [unused10] &= \\frac{(1-\\d)E(\\ol{M^p} ) + \\d (1-\\g)\\e}{(1-\\d)E(\\ol{M^p} ) +\\d ( 1 -\\g ) \\e - ( 1 -\\d\\g ) }\\ nonumber \\\\ [unused10] &= 1 + \\frac{(1-\\d\\g)} { ( 1 - \\d)E(\\ol{M^p} ) + ( \\d-\\d\\g)\\e - (1-\\d\\g)}.\\label{e:emss2}  \\end{align} In addition , \\eqref{e:ydp} shows that in steady state the price elasticity of demand is $E(\\ol{M^p})=\\e+(\\e-1) \\g \\f(\\ol{M^p})$ . Using this expression , we rewrite the denominator of the fraction in \\eqref{e:emss2} as \\begin{equation*} (1-\\d) \\e + (1-\\d)(\\e-1)\\g\\f(\\ol{M^p}) +(\\d-\\d\\g)\\e - (1-\\d\\g) = (\\e-1) \\bs{(1-\\d\\g) + (1-\\d) \\g \\f(\\ol{M^p})}. \\end{equation*} Plugging this result back into \\eqref{e:emss2} , we obtain the steady - state price markup : \\begin{equation} \\ol{M} = 1+ \\frac{1}{\\e-1}\\cdot \\frac{1}{1 + \\frac{(1-\\d)\\g}{1-\\d\\g} \\f(\\ol{M^p})}. \\label{e:mssa}\\end{equation}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_157": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_157",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_157",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_157",
		"text": "Next , we introduce another auxiliary function : \\begin{equation*} \\L_2(M^p) =E(M^p) - (1-\\g)\\e = \\g \\bs{\\e +(\\e-1)\\f(M^p)}. \\end{equation*} The elasticity of $\\L_2(M^p)$ at the steady state is \\begin{equation} \\odl{\\L_2}{M^p} = \\frac{(\\e-1) \\ol{\\f}}{\\e+(\\e-1) \\ol{\\f}}\\cdot \\ol{\\s} \\equiv \\O_{2}. \\label{e:omega2}\\end{equation} We also introduce the auxiliary function \\begin{equation*} \\L_3(x) = 1- \\d\\g + \\d x, \\end{equation*} whose elasticity is \\begin{equation*} \\odl{\\L_3}{x} = \\frac{\\d x}{\\L_3} \\equiv \\O_{3}. \\end{equation*} The right - hand side of \\eqref{e:ema} ( abstracting from the expectation operator ) can be written \\begin{equation*} RHS = \\L_3(\\L_1(M(t+1))\\cdot \\L_2(M^p(t+1)). \\end{equation*} Hence , around the steady state the log - linear approximation of $RHS$ is \\begin{equation} \\ln(RHS)-\\ln(\\ol{RHS}) = \\O_{3} \\cdot \\bs{\\O_{1} \\wh{m}(t+1) + \\O_{2} \\wh{m^p}(t+1)}, \\label{e:rhs}\\end{equation} where the elasticity $\\O_3$ is evaluated at $\\ol{x}=\\ol{\\L_1}\\cdot \\ol{\\L_2}$ and $\\ol{\\L_3}= \\ol{RHS} = \\ol{LHS} =\\ol{E} \\cdot\\ol{\\L_1}$ . Thus in \\eqref{e:rhs} we have \\begin{equation} \\O_{3} = \\frac{\\d \\ol{\\L_1}\\cdot \\ol{\\L_2}}{\\ol{E}\\cdot \\ol{\\L_1}} = \\d\\g \\frac{\\e +(\\e-1)\\ol{\\f}}{\\e+(\\e-1) \\g \\ol{\\f}}. \\label{e:omega3}\\end{equation}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_97": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_97",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_97",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_97",
		"text": "By definition , the elasticity of the fairness function is given by \\begin{equation*} \\f(M^p) = - M^p \\cdot \\frac{F'(M^p)}{F(M^p)}. \\end{equation*} The properties of the fairness function $F$ listed in Definition ~ \\ref{d:fairness} indicate that $F(M^p)>0$ and $F'(M^p)<0$ , so $\\f(M^p)>0$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_83": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_83",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_83",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_83",
		"text": "The lemma shows that in steady state households perceive higher price markups when inflation is higher . Households understand that in steady state nominal marginal costs grow at the inflation rate , but because of subproportional inference , they misjudge the level of those costs and thus of price markups . Since perceived price markups are higher when inflation is higher , the fairness factor is lower --- except when consumers are fully acclimated ( $\\c=1$ ) , in which case the fairness factor is always one . Last , the elasticity of the fairness function is higher when inflation is higher ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_68": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_68",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_68",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_68",
		"text": "\\paragraph{Parameters of the Textbook New Keynesian Model} We also calibrate a textbook New Keynesian model ( described in Appendix ~ C ) , which we will use as a benchmark in simulations . For the parameters common to the two models , we use the same values --- except for $\\e$ . In the textbook model , the steady - state price markup is $\\e/(\\e-1)$ , so we set $\\e=3$ to obtain a markup of ~ $1.5$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_54": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_54",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_54",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_54",
		"text": "Each period ~ $t$ , firm ~ $j$ chooses output $Y_{j}(t)$ , price $P_{j}(t)$ , and employment levels $N_{jk}(t)$ for all $k\\in[0,1]$ . The firm 's objective is to maximize the expected present - discounted value of profits \\begin{equation*} \\E[0]\\sum_{t=0}^{\\infty}\\G(t) \\bs{P_{j}(t) Y_{j}(t)-\\int_{0}^{1}W_{k}(t) N_{jk}(t)\\,dk}, \\end{equation*} where $\\G(t)$ is the stochastic discount factor for period - $t$ nominal payoffs , subject to the production constraint ~ \\eqref{e:yj} , to demand for good ~ $j$ , and to the law of motion of the perceived marginal cost \\eqref{e:cpj} . The firm takes as given the initial belief about its marginal cost $C^p_{j}(-1)$ , all wage rates $W_{k}(t)$ , and discount factors $\\G(t)$ . Its profits accrue to households as dividends ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_40": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_40",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_40",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_40",
		"text": "The proof is relegated to Appendix ~ A , but the intuition is simple . First , when customers care about fairness but underinfer marginal costs , they become more price - sensitive . Indeed , an increase in the price increases the opportunity cost of consumption --- as in the case without fairness --- and also increases the perceived markup , which reduces the marginal utility of consumption and therefore demand . This heightened price - sensitivity raises the price elasticity of demand above $\\e$ and pushes the markup below $\\e/(\\e-1)$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_56": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_56",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_56",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_56",
		"text": "\\paragraph{Symmetry} We assume a symmetric economy . All households receive the same bond endowment $B(-1)$ and same dividends $V(t)$ . All firms share a common technology $A(t)$ , face the same fairness function $F$ , and are believed to have the same initial cost $C^p(-1)$ . Hence , all households behave identically , as do all firms ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_42": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_42",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_42",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_42",
		"text": "\\paragraph{Additional Analytical Results} To obtain further results , we introduce a simple fairness function that satisfies all the requirements from Definition ~ \\ref{d:fairness} : \\begin{equation} F(M^p) = 1- \\t \\cdot \\bp{M^p - \\frac{\\e}{\\e-1}}, \\label{e:f}\\end{equation} where $\\t>0$ governs the intensity of fairness concerns . A higher $\\t$ means that a consumer grows more upset when consuming an overpriced item and more content when consuming an underpriced item . The fairness function reaches $1$ when the perceived markup equals $\\e/(\\e-1)$ ; then fairness - adjusted consumption coincides with actual consumption . When the perceived markup exceeds $\\e/(\\e-1)$ , the fairness function falls below one ; and when the perceived markup lies below $\\e/(\\e-1)$ , the fairness function surpasses one ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_95": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_95",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_95",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_95",
		"text": "\\paragraph{Fairness Concerns and Rational Inference of Costs} With fairness concerns and rational inference of marginal costs , the price elasticity of demand is again $E=\\e$ ( Section ~ \\ref{s:rational} ) . Hence , as in the case of no fairness concerns , the profit function is unimodal and its maximum is the unique solution to the first - order condition $V'(P)=0$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_81": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_81",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_81",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_81",
		"text": "\\paragraph{Acclimation} \\ct[p.~730]{KKT86} hypothesize that `` any stable state of affairs tends to become accepted eventually '' . We adapt their idea by assuming that people partially acclimate to the steady - state inflation rate , generalizing the fairness function \\eqref{e:f} to \\begin{equation} F(M^p) = 1 - \\t \\cdot(M^p - M^f), \\label{e:facclim}\\end{equation} where $M^f$ is the fair markup resulting from acclimation . We assume that the fair markup is the weighted average of the standard markup $\\e/(\\e-1)$ and the steady - state perceived markup $\\ol{M^p}$ : \\begin{equation} M^f = \\c \\cdot \\ol{M^p} + (1-\\c) \\cdot \\frac{\\e}{\\e-1}. \\label{e:mf}\\end{equation} The parameter $\\c \\in [0,1]$ measures acclimation : when $\\c=0$ , there is no acclimation ; when $\\c=1$ , there is full acclimation , so people do not mind whatever is happening in steady state ; when $\\c\\in(0,1)$ , people may be permanently satisfied or dissatisfied in steady state , but less than when $\\c=0$ . \\footnote{This specification does not change anything at the zero-inflation steady state. With zero inflation, [unused10] , so [unused10] for any [unused10] . Therefore, the fairness function~\\eqref{e:facclim} simplifies to the function ~ \\eqref{e:f} for any ~ $\\c$ . }"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_141": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_141",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_141",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_141",
		"text": "Second , in steady state the monetary - policy rule \\eqref{e:taylor} implies that $\\ol{r} = \\ol{i_{0}} + (\\p-1) \\ol{\\pi}$ . Since $\\ol{r} = \\r$ , the steady - state inflation rate is \\begin{equation*} \\ol{\\pi}=\\frac{\\r-\\ol{i_{0}}}{\\p-1}. \\end{equation*}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_155": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_155",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_155",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_155",
		"text": "\\paragraph{IS Equation} The fifth equation is the IS equation , which is based on the consumption Euler equation ~ \\eqref{e:euler} . We start by computing a log - linear approximation of \\eqref{e:euler} , as in \\ct[pp.~35--36]{G08} : \\begin{equation*} \\ln(Y(t))=\\E[t]{\\ln(Y(t+1))} + \\E[t]{\\pi(t+1)} + \\r - i(t), \\end{equation*} where $\\r = -\\ln(\\d)$ is the discount rate . Subtracting the steady - state values of both sides yields \\begin{equation*} \\wh{y}(t)=\\E[t]{\\wh{y}(t+1)}+\\E[t]{\\wh{\\pi}(t+1)} - \\wh{i}(t). \\end{equation*} Last , we introduce the values of $\\wh{y}(t)$ and $\\wh{y}(t+1)$ given by \\eqref{e:yhat} , and the value of $\\wh{i}(t)$ given by ~ \\eqref{e:ihat} . We obtain the IS equation : \\begin{equation} \\a \\wh{n}(t)+\\p \\wh{\\pi}(t)=\\a \\E[t]{\\wh{n}(t+1)}+\\E[t]{\\wh{\\pi}(t+1)} - \\wh{i_0}(t) - \\wh{a}(t)+ \\E[t]{\\wh{a}(t+1)}. \\label{e:is}\\end{equation}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_169": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_169",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_169",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_169",
		"text": "\\paragraph{Simulations} We start from a steady - state situation . To be consistent with the simulations of Figures ~ \\ref{f:monetary} and ~ \\ref{f:technology} , we assume that steady - state inflation is zero , so the marginal cost $C$ is constant in steady state . Then we impose an unexpected permanent 1 \\ % increase in $C$ . We compute the firm 's response to this shock by solving the nonlinear dynamical system of four equations that describes firm 's pricing . We obtain the dynamics of the cost passthrough by calculating the percentage change in price over time : \\begin{equation*} \\b(t) = \\frac{P(t)-\\ol{P}}{\\ol{P}} \\times 100. \\end{equation*}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_168": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_168",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_168",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_168",
		"text": "\\begin{figure} [ t ] \\includegraphics[scale=0.3,page=15]{\\pdf}  \\caption{Simulated dynamics of cost passthrough}  \\note{The cost passthrough represents the percentage increase in price due to a 1\\% increase in marginal cost. The empirical estimates of the cost passthrough ( [unused10] and [unused10] ) are obtained in Section~\\ref{s:calibration} . The simulations are obtained from the pricing model in Appendix ~ \\ref{a:calibration} under the calibration in Table ~ \\ref{t:calibration} .} \\label{f:calibration}  \\end{figure}"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_154": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_154",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_154",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_154",
		"text": "We describe the log - linearized equilibrium through six variables . The first four are the log - deviations from steady state of output , employment , price markup , and perceived price markup : $\\wh{y}(t)$ , $\\wh{n}(t)$ , $\\wh{m}(t)$ , and $\\wh{m^p}(t)$ . The final two are the deviations from steady state of the nominal interest rate and inflation rate : $\\wh{i}(t)$ and $\\wh{\\pi}(t)$ . These six variables are governed by six linear equations ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_140": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_140",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_140",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_140",
		"text": "\\paragraph{Steady-State Equilibrium Conditions} First , in steady state the consumption Euler equation \\eqref{e:euler} gives \\begin{equation*} \\ol{Q}=\\d \\cdot \\frac{P(t)}{P(t+1)}. \\end{equation*} Taking the logarithm of this equation and using \\eqref{e:definition} , we obtain \\begin{equation*} \\ol{i} = \\r + \\ol{\\pi}, \\end{equation*} where $\\r \\equiv -\\ln(\\d)$ is the discount rate . Equivalently , the steady - state real interest rate $\\ol{r} \\equiv \\ol{i}- \\ol{\\pi}$ equals the discount rate $\\r$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_80": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_80",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_80",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_80",
		"text": "We study the long - run effects of monetary policy by comparing the steady - state equilibria induced by different values of the exogenous component $\\ol{i_0}$ in the monetary - policy rule \\eqref{e:taylor} . In steady state the real interest rate equals the discount rate $\\r \\equiv -\\ln(\\d)$ ; therefore , by choosing $\\ol{i_0}$ , monetary policy perfectly controls steady - state inflation : \\begin{equation*} \\ol{\\pi} = \\frac{\\r-\\ol{i_{0}}}{\\p-1}. \\end{equation*} To obtain zero inflation , it suffices to set $\\ol{i_0}=\\r$ ; to obtain higher inflation , it suffices to reduce $\\ol{i_0}$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_94": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_94",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_94",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_94",
		"text": "\\paragraph{Fairness Concerns and Observable Costs} With fairness concerns and observable costs , the price elasticity of demand is $E=\\e+(\\e-1)\\f(P/C)$ ( Section ~ \\ref{s:observable} ) . The profit function is now defined for $P\\in (C, M^h \\cdot C)$ . The derivative \\eqref{e:dvdp} becomes \\begin{equation*} V'(P) =Y^{d}(P) \\bs{1 - \\frac{P-C}{P} \\cdot \\bc{\\e+(\\e-1)\\f(P/C)}}. \\end{equation*} Again , the function $P\\mapsto (P-C)/P$ is strictly increasing from 0 to 1 as $P$ increases from $C$ to $+\\infty$ . The elasticity of the fairness function $\\f(P/C)$ is strictly increasing from $\\f(1)>0$ to $+\\infty$ as $P$ increases from $C$ to $M^h \\cdot C$ ( Lemma ~ \\ref{l:phi} ) . Hence the term in square brackets is strictly decreasing from 1 to $-\\infty$ as $P$ increases from $C$ to $M^h \\cdot C$ . This implies that the term in square brackets has a unique root $P^*$ on $(C,M^h \\cdot C)$ , is positive for $P<P^*$ , and is negative for $P>P^*$ . Following the same argument as in the previous case , we conclude that the profit function is unimodal , and its maximum $P^*$ is the unique solution to the first - order condition $V'(P)=0$ ."
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_43": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_43",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_43",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_43",
		"text": "Furthermore , to compare different industries or economies , we focus on a situation in which customers have acclimated to prices by coming to judge firms ' markups as acceptable : $C^b$ adjusts so $M^p = \\e/(\\e-1)$ and $F=1$ . Acclimation is likely to occur eventually within any industry or economy , once customers have faced the same prices for a long time . \\footnote{As noted by \\ct[p.~730]{KKT86} , `` Psychological studies of adaption suggest that any stable state of affairs tends to become accepted eventually , at least in the sense that alternatives to it no longer come to mind . Terms of exchange that are initially seen as unfair may in time acquire the status of a reference transaction \\ldots. [People] adapt their views of fairness to the norms of actual behavior.'' The belief-updating rule~\\eqref{e:cpj} introduced in the New Keynesian model has the property that for any initial belief , people eventually become acclimated . }"
	},
	"1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_57": {
		"id": "1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_57",
		"phase": "test",
		"topic": "econ.th",
		"document": "1904.05656v4.Pricing_under_Fairness_Concerns",
		"paragraph": "paragraph_57",
		"prefix": "selected/test/econ.th-ann4/1904.05656v4.Pricing_under_Fairness_Concerns/paragraph_57",
		"text": "\\paragraph{Notation} Since the equilibrium is symmetric , we drop subscripts ~ $j$ and ~ $k$ to denote the equilibrium values taken by the variables . We also denote the steady - state value of any variable $H(t)$ by $\\ol{H}$ . And for any variable $H(t)$ except the inflation and interest rates , we denote the logarithmic deviation from steady state by $\\wh{h}(t)\\equiv \\ln(H(t))-\\ln(\\ol{H})$ . For the inflation and interest rates , we denote the deviation from steady state by $\\wh{\\pi}(t)\\equiv \\pi(t)-\\ol{\\pi}$ , $\\wh{i_0}(t) \\equiv i_0(t)-\\ol{i_0}$ , and $\\wh{i}(t) \\equiv i(t) - \\ol{i}$ ."
	},
	"1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_11": {
		"id": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_11",
		"phase": "test",
		"topic": "physics.atom_ph",
		"document": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime",
		"paragraph": "paragraph_11",
		"prefix": "selected/test/physics.atom_ph-ann8/1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_11",
		"text": "The radiation near $\\theta \\approx 20^{\\circ}$ arises after the reflection of the electrons . When the laser field is tightly focused , the emission time in this case again is of the order of the duration of the electron beam $\\Delta t\\approx L_R/c+L_b/c(1+\\beta)\\sim L_b/2c$ , with the Rayleigh length $L_R=\\pi w_0^2/\\lambda_0$ \\cite{Suppl_material} . However , due to reflection , the front of the radiation field and the rear part of the electron beam are counterpropagating , which yields a very short radiation pulse : $\\Delta t_d\\sim \\pi T_0(w_0/\\lambda_0)^2(1-\\beta\\cos\\theta)+L_b (1-\\cos\\theta)/c(1+\\beta)\\sim L_b (1-\\cos\\theta)/2c $ \\cite{Suppl_material} ."
	},
	"1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_10": {
		"id": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_10",
		"phase": "test",
		"topic": "physics.atom_ph",
		"document": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime",
		"paragraph": "paragraph_10",
		"prefix": "selected/test/physics.atom_ph-ann8/1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_10",
		"text": "\\includegraphics[width=8cm]{fig4.eps} [unused10] . } \\label{plane-wave}  \\end{figure}"
	},
	"1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_12": {
		"id": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_12",
		"phase": "test",
		"topic": "physics.atom_ph",
		"document": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime",
		"paragraph": "paragraph_12",
		"prefix": "selected/test/physics.atom_ph-ann8/1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_12",
		"text": "Moreover , there is another reason which further decreases the emission time . During the forward radiation all electrons loose energy which facilitates the reflection when the condition $\\gamma\\sim \\xi/2$ is approached . However , only the front fraction of the bunch can encounter the strongest laser field at the peak of the laser pulse within the focal region and loose enough energy to fulfil the reflection condition . The rear electrons experience a weaker laser field , because of the laser defocusing effect and can not achieve the reflection . Then , the effective length $\\tilde{L}_b $ of the reflected electron bunch is shorter than the total bunch length , for the given parameters $\\tilde{L}_b\\approx 10\\lambda_0$ \\cite{Suppl_material} . For the given parameters our estimate provides $\\Delta t_d\\approx 0.24T_0$ and $\\Delta t\\approx 4T_0$ , which is in agreement with Fig. ~ \\ref{spectrum} ( a ) and ( b ) ."
	},
	"1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_8": {
		"id": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_8",
		"phase": "test",
		"topic": "physics.atom_ph",
		"document": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime",
		"paragraph": "paragraph_8",
		"prefix": "selected/test/physics.atom_ph-ann8/1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_8",
		"text": "Let us explain the duration of the gamma radiation at different emission angles . The ultrarelativistic electrons in the bunch , which counterpropagate with the laser field , radiate initially in the direction opposite to the laser propagation [ see $\\eta<35$ in Fig. ~ \\ref{single} ( d ) ] . Significant photon emission appears when the $\\chi$ - parameter achieves a rather large peak value of $\\chi\\approx 0.6$ , as shown in Fig. ~ \\ref{single} ( a ) . Due to the radiation loss the electron energy decreases ( Fig. ~ \\ref{single} ( c ) ) . On the other hand , at this moment the laser field is still large ( Fig. ~ \\ref{single} ( b ) ) , yielding the electron reflection at $\\eta\\approx 36$ [ see the large change of $\\theta$ at $\\eta\\approx 36$ in Fig. ~ \\ref{single} ( d ) ] . After the reflection the electron emits briefly closer to the laser propagation direction because it leaves the focal region with an essential decrease of the parameter $\\chi$ . The emission angle $\\theta\\sim \\xi/\\gamma\\approx 20^{\\circ}$ , is determined by the values of $\\xi$ and $\\gamma$ after the reflection . This is the tilting angle of the electron trajectory with respect to the laser propagation direction after the reflection ."
	},
	"1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_9": {
		"id": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_9",
		"phase": "test",
		"topic": "physics.atom_ph",
		"document": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime",
		"paragraph": "paragraph_9",
		"prefix": "selected/test/physics.atom_ph-ann8/1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_9",
		"text": "The radiation at $\\theta\\approx 180^{\\circ}$ arises before the electrons reach the reflection point . While the duration of the radiation wave packet of a single electron is extremely short $\\Delta t_d^{(1)}\\sim \\tau_0/4\\gamma^2$ , each consecutive electron in the bunch contributes into the total radiation field with corresponding time delay . Therefore , the total duration of the emission is of the order of the electron 's bunch duration $L_b/c$ . An accurate estimation of the radiation pulse duration yields $\\Delta t_d\\sim \\tau_0/ 4\\gamma^2+2L_b/c(1+\\beta)$ , and the radiation time of the electron beam $\\Delta t=(\\tau_0+L_b/c)/(1+\\beta)$ \\cite{Suppl_material} . Furthermore , $\\Delta t_d/\\Delta t\\approx 1.4$ which corresponds to Fig. ~ \\ref{spectrum} ( a ) and ( b ) . The length of the emitted gamma radiation pulse is deduced by calculating the distance between the front of the gamma - pulse ( which arises when the laser pulse reaches the front part of the electron beam ) and the end of the gamma - pulse ( which is determined by the moment when the laser pulse reaches the end of the electron beam ) \\cite{Suppl_material} ( see also Fig. ~ \\ref{schematic} ( b ) and ( c ) ) ."
	},
	"1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_13": {
		"id": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_13",
		"phase": "test",
		"topic": "physics.atom_ph",
		"document": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime",
		"paragraph": "paragraph_13",
		"prefix": "selected/test/physics.atom_ph-ann8/1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_13",
		"text": "The focusing of the laser beam is absolutely essential . In a plane - wave laser pulse , as shown in Fig. ~ \\ref{plane-wave} , the emission time of the radiation before the reflection can be seen from the area $\\theta>90^{\\circ}$ in Fig. ~ \\ref{plane-wave} ( a ) , and that after the reflection from $\\theta<90^{\\circ}$ . In the latter case , the electron moves along the propagation direction of the laser pulse and experiences the field of the rest of the laser pulse . Then , the emission of photons takes the long time $\\Delta t\\sim \\tau_0/(1-\\beta)\\gg L_b/c$ \\cite{Suppl_material} . In the frame of the detector , the duration of the radiation pulse is shortened with respect to the emission time by a factor $1-\\beta \\cos\\theta$ to become $\\Delta t_d\\sim \\tau_0(1-\\beta\\cos\\theta)/(1-\\beta)$ \\cite{Suppl_material} [ see the time range for $\\theta <90^\\circ$ in Fig. ~ \\ref{plane-wave} ( b ) compared to Fig. ~ \\ref{plane-wave} ( a ) ] . However , the shortest duration of the radiation pulse at $\\theta\\approx 20^{\\circ}$ is still much larger than the laser period , in contrast to the case of the focused field [ in the focused field $\\tau_0/(1-\\beta)$ is replaced by $L_R/c$ in the emission time ] ."
	},
	"1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_16": {
		"id": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_16",
		"phase": "test",
		"topic": "physics.atom_ph",
		"document": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime",
		"paragraph": "paragraph_16",
		"prefix": "selected/test/physics.atom_ph-ann8/1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_16",
		"text": "Finally , we estimate the total number of photons in the gamma - ray burst of $830$ as duration for the parameters in Fig. ~ \\ref{spectrum} to be $N_{ph}\\sim 10^2$ within the emission solid angle $\\Delta\\Omega=1$ mrad $^2$ . In spite of a small number of total photons , the photon flux ( F ) and the brilliance ( B ) are rather large due to the short duration of the pulse : $F\\sim 10^{14}$ photons s $^{-1}$ $0.1 \\%$ BW , and $B\\sim 3\\times 10^{20}$ photons s $^{-1}$ mrad $^{-2}$ mm $^{-2}$ $0.1 \\%$ BW , respectively , e.g. , the brilliance is 2 orders of magnitude larger than in the recent experiment \\cite{Powers_2014} ."
	},
	"1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_14": {
		"id": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_14",
		"phase": "test",
		"topic": "physics.atom_ph",
		"document": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime",
		"paragraph": "paragraph_14",
		"prefix": "selected/test/physics.atom_ph-ann8/1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_14",
		"text": "Several gamma - ray bursts are observable near $\\theta \\approx 20^{\\circ}$ in the 4 - cycle laser pulse ( Fig. ~ \\ref{spectrum} ( a ) ) . Moreover , a single gamma - ray burst arises in a 2 - cycle laser pulse , and a gamma - ray comb is formed by employing longer laser pulses \\cite{Suppl_material} . This is because the electron can be reflected at any wave crest due to the stochastic character of the gamma - photon emission , while there is only one single burst when stochastic effects are neglected \\cite{Suppl_material} . This feature of the angle - resolved radiation intensity can serve as an indicator of stochastic effects in photon emission ."
	},
	"1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_15": {
		"id": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_15",
		"phase": "test",
		"topic": "physics.atom_ph",
		"document": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime",
		"paragraph": "paragraph_15",
		"prefix": "selected/test/physics.atom_ph-ann8/1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_15",
		"text": "The described effect of the short gamma ray generation near the reflection condition is rather robust . While here one example of the effect at $\\xi =600$ and $\\gamma_0\\approx 400$ has been provided , our simulations show that the same mechanism for ultrashort gamma - ray bursts works as well when varying the laser field and the electron energy within a large range : $\\delta \\xi/\\xi\\sim 1/2$ and $\\delta \\gamma/\\gamma_0 \\sim 1/2$ \\cite{Suppl_material} ."
	},
	"1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_2": {
		"id": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_2",
		"phase": "test",
		"topic": "physics.atom_ph",
		"document": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime",
		"paragraph": "paragraph_2",
		"prefix": "selected/test/physics.atom_ph-ann8/1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_2",
		"text": "Let us determine the parameters of the applied regime . First of all , we consider the nonlinear regime of Compton scattering when the invariant laser field parameter is large , $\\xi\\gg 1$ , where $\\xi\\equiv |e|E_0/(m\\omega_0)$ , $E_0$ and $\\omega_0$ are the laser field and frequency , respectively , and $e$ and $m$ are the electron charge and mass , respectively ( Planck units $\\hbar=c=1$ are used throughout ) . Second , the reflection of the counterpropagating electron in a laser pulse requires a relativistic Lorentz factor $\\gamma\\approx\\xi/2$ . In fact , the electron , initially at rest , in the laser field drifts along the laser propagation direction with the Lorentz factor of the drift $\\gamma_{ drift}=\\xi/2$ \\cite{Salamin_1996} . Similarly , the electron deviation angle with respect to the laser propagation direction can be estimated as $\\theta\\sim \\xi/\\gamma$ , and the reflection condition corresponds to $\\theta\\sim 1$ . Third , the interaction has to be in the radiation - dominated regime ( RDR ) , when the radiation losses during a laser period are comparable with the electron 's initial energy , and the radiation reaction has a decisive impact on the electron dynamics . This regime is characterized by the parameter $R \\equiv\\alpha \\xi \\chi \\gtrsim 1$ \\cite{RMP_2012} , which is the ratio of the radiated energy during a laser period to the electron energy . Here , $\\alpha$ is the fine structure constant , and $\\chi\\equiv \\gamma(\\omega_0/m)\\xi (1-\\beta \\cos\\theta)$ the quantum strong field parameter , which determines the recoil of the electron during the photon emission with $\\chi \\approx \\omega/m\\gamma$ \\cite{RMP_2012} . $\\beta$ is the relativistic beta factor of the electron , $\\theta$ the polar angle between the electron velocity and the laser propagation direction , and $\\omega$ the emitted photon energy . The RDR is mostly accessible in the quantum regime of interaction when $\\chi\\gtrsim 1$ \\cite{Baurichter_1997_new} . However , the RDR regime is only achievable with extremely intense lasers $\\xi\\gg 1$ . Thus , combining the quantum RDR conditions $R=\\alpha \\xi\\chi \\gtrsim 1$ and $\\chi\\approx 10^{-6}\\gamma\\xi\\sim 1$ , with the reflection condition $\\gamma\\sim\\xi/2$ , one requires $\\gamma \\sim \\xi \\sim 10^3$ . Electron beams of GeV energies ( $\\gamma \\sim 10^3$ ) can be produced by the laser - plasma acceleration technique \\cite{Esarey_2009} and the laser intensities of $10^{23}$ - $10^{24}$ W / cm $^2$ ( $\\xi \\sim 10^3$ ) are anticipated with next generation facilities ( see , e.g. , \\cite{ELI,HiPER} ) ."
	},
	"1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_3": {
		"id": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_3",
		"phase": "test",
		"topic": "physics.atom_ph",
		"document": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime",
		"paragraph": "paragraph_3",
		"prefix": "selected/test/physics.atom_ph-ann8/1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_3",
		"text": "Our analysis in this Letter is based on Monte - Carlo simulations employing QED theory for the electron radiation and classical equations of motion for the propagation of electrons between photon emissions \\cite{Suppl_material, Elkina_2011,Ridgers_2014,Green_2015} . In superstrong laser fields $\\xi\\gg 1$ , the coherence length of the photon emission is much smaller than the laser wavelength and the typical size of the electron trajectory \\cite{Ritus_1985} ( see also \\cite{Khokonov_2010} ) . As a result , the photon emission probability is determined by the local electron trajectory . In this case the photon emission probability in the laser field can be approximated by that of constant cross fields with the corresponding local value of the parameter $\\chi$ ( this is the well - known synchrotron approximation ) \\cite{Baier_b_1994} , cf. \\cite{Khokonov_2002a} . We employ a linearly polarized focused short laser pulse , which is an approximate solution of Maxwell 's equations with first order corrections with respect to the small parameters $(k_0w_0)^{-1}$ and $(\\omega_0 \\tau_0)^{-1}$ \\cite{Jian-Xing_2014} , where $k_0$ , $w_0$ and $\\tau_0$ are the wave vector , the waist radius and the pulse duration of the laser beam , respectively ."
	},
	"1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_1": {
		"id": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_1",
		"phase": "test",
		"topic": "physics.atom_ph",
		"document": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime",
		"paragraph": "paragraph_1",
		"prefix": "selected/test/physics.atom_ph-ann8/1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_1",
		"text": "\\begin{figure} [ b ] \\includegraphics[width=8cm]{fig1.eps} [unused10] . } \\label{schematic}  \\end{figure}"
	},
	"1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_0": {
		"id": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_0",
		"phase": "test",
		"topic": "physics.atom_ph",
		"document": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime",
		"paragraph": "paragraph_0",
		"prefix": "selected/test/physics.atom_ph-ann8/1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_0",
		"text": "In linear Thomson / Compton scattering the duration of the emitted gamma - radiation pulse is determined by the shortest of either the laser or electron beam duration . In an all - optical setup the electron bunch length is of the order of the laser pulse length and the created gamma - rays are of duration of several tens of femtoseconds . Are shorter pulses of gamma - rays necessary ? Generally , short laser pulses are required for the time - resolved monitoring and control of fast - evolving processes with the pump - probe technique . The state - of - the - art time - resolution has achieved the attosecond scale by using extreme ultraviolet radiation , which allows to track the dynamics of an electronic wave packet in an atom \\cite{Krausz_2009} . The required frequencies of the short pulses depend on the characteristic energies of the processes under investigation . The molecular dynamics and chemical reactions can be controlled with a few electronvolt excitations driven by an infrared laser field , and the inner - shell electron dynamics by photons with a few 100 eV up to several keV energies . The next challenge is to time - resolve the intra-nuclear dynamics \\cite{Ledingham_2003,Palffy_2015} . It is known \\cite{Povh_book} that typical energies of nuclear single - particle transitions are of the order of 1 - 10 MeV with typical decay lifetimes of the levels around $10^{-9}-10^{-15}$ s . The energies of the collective nuclear excitations range from several dozens of keV up to 30 MeV . The disintegration time of compound nuclei during nuclear reactions ranges from $10^{-19}-10^{-16}$ s . This sets the scale for the required photon energy and pulse duration . There is a wealth of nuclear phenomena for which the investigation of the time resolved dynamics requires short photon pulses , such as , resonance fluorescence ( 1 fs timescale ) , resonance internal conversion ( 1 as timescale ) and compound nuclei evolution ( zeptosecond timescale ) ."
	},
	"1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_4": {
		"id": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_4",
		"phase": "test",
		"topic": "physics.atom_ph",
		"document": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime",
		"paragraph": "paragraph_4",
		"prefix": "selected/test/physics.atom_ph-ann8/1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_4",
		"text": "\\includegraphics[width=8cm]{fig2.eps} \\ caption { ( Color online ) The angle - resolved radiation intensity for photon energies above 1 MeV in a 4 - cycle laser pulse with carrier - envelope phase $\\phi_{CEP}=0$ and azimuthal angle of emission with respect to the laser propagation direction $\\phi=180^\\circ$ ( the spectra are similar at $\\phi\\approx 0$ ) : ( a ) Color coded is Log $_{10}$ [ d $^2\\varepsilon_R/$ d $\\Omega$ d $(t_d/T_0)$ ] rad $^{-2}$ in the detector time $t_d$ , with the radiation energy $\\varepsilon_R$ in units of the electron rest energy $m$ , the laser period $T_0$ , and the emission solid angle $\\Omega$ ; ( b ) Color coded is Log $_{10}$ [ d $^2\\varepsilon_R/$ d $\\Omega$ d $(t/T_0)$ ] rad $^{-2}$ with the electron emission time $t$ ; ( c ) The differential gamma - ray radiation via d $^2\\varepsilon_R/$ d $\\Omega$ d $(t_d/T_0)$ at $\\theta = 20^{\\circ} $ and $\\Delta \\theta = 0.002$ rad . ( d ) The spectral distribution d $^2 \\varepsilon_R/$ d $\\Omega$ d $\\omega$ of the main pulse in ( c ) . The laser and the electron beam parameters are given in the text . } \\label{spectrum}  \\end{figure}"
	},
	"1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_5": {
		"id": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_5",
		"phase": "test",
		"topic": "physics.atom_ph",
		"document": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime",
		"paragraph": "paragraph_5",
		"prefix": "selected/test/physics.atom_ph-ann8/1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_5",
		"text": "The simulation results for the gamma - radiation properties above the photon energy of 1 MeV are shown in Fig. ~ \\ref{spectrum} . The applied parameters are the following : the peak intensity of the 4 - cycle laser pulse is $I\\approx 4.9\\times 10^{23}$ W / cm $^2$ ( $\\xi=600$ ) , the laser wavelength $\\lambda_0 = 1$ $\\mu$ m , and the laser beam waist size $w_0$ = 1 $\\mu$ m . The initial kinetic energy of the electrons is $200$ MeV ( $\\gamma_0=392$ , $\\chi_{max}\\approx0.8$ ) . As the electron reflection condition should hold in the laser field , larger initial electron energies $\\gamma_0>\\xi/2$ are required because of radiation losses . We employ an electron bunch of length $L_b=10\\lambda_0$ , and of transverse size $w_b=w_0$ , with the number of electrons $N_e=3\\times 10^{8}$ . The energy as well as angular spread of the bunch are $\\Delta \\gamma/\\gamma_0=\\Delta \\theta=10^{-3}$ . \\begin{figure}"
	},
	"1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_7": {
		"id": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_7",
		"phase": "test",
		"topic": "physics.atom_ph",
		"document": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime",
		"paragraph": "paragraph_7",
		"prefix": "selected/test/physics.atom_ph-ann8/1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_7",
		"text": "The time - dependent angular resolved radiation intensity is shown in Fig. ~ \\ref{spectrum} ( a ) . The radiation sweeps from the polar angle $\\theta=180^{\\circ}$ down to $\\theta\\approx 20^{\\circ}$ . The duration of the emission decreases with decreasing $\\theta$ . At $\\theta\\approx 180^{\\circ}$ it is mostly determined by the length of the electron bunch , while at small angles it is smaller than the laser period $T_0$ . The duration of the gamma - radiation at $\\theta = 20^{\\circ}$ with an aperture angle $\\Delta \\theta =0.002$ is illustrated in Fig. ~ \\ref{spectrum} ( c ) . The duration of the main gamma - pulse is about \\textbf{ [unused10] } as . This is the main result of this paper : ultrashort gamma ray bursts of attosecond duration can be generated closer to the laser propagation direction , while using much longer laser and electron beams ( 13 fs and 33 fs , respectively , in the given example ) . The spectral distribution of the gamma ray burst is shown in Fig. ~ \\ref{spectrum} ( d ) , with the central frequency being $\\omega \\approx 67 m=34.2$ MeV . Narrower gamma - ray pulses can be detected at smaller polar angles where , however , the mean frequency is smaller ."
	},
	"1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_6": {
		"id": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_6",
		"phase": "test",
		"topic": "physics.atom_ph",
		"document": "1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime",
		"paragraph": "paragraph_6",
		"prefix": "selected/test/physics.atom_ph-ann8/1504.02393v3.Attosecond_gamma_ray_pulses_via_nonlinear_Compton_scattering_in_the_radiation_dominated_regime/paragraph_6",
		"text": "\\includegraphics[width=8cm]{fig3.eps}  \\caption{(Color online) Dynamics of a single exemplary electron with respect to the phase [unused10] . Parameters are the same as in Fig.~\\ref{spectrum} . The blue dots present the points where gamma photons are emitted . } \\label{single}  \\end{figure}"
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_48": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_48",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_48",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_48",
		"text": "[unused10] \\text bf { Temperature - dependent transition from two to one distinct paths in the toy model . } The means and standard deviations of the discrete \\frechet ( blue ) and Hausdorff ( red ) distances for double - barrel simulations of one particle ( A ) and eight particles ( B ) are shown as functions of temperature . Measurements for simulations at \\unit{250} {\\kelvin } and below were divided into an upper and lower distribution by separating distance measurements above and below a \\unit{1.25} {\\nano\\meter } cutoff . Above the temperature cutoff , all measurements were treated as part of the same distribution . Both the \\ frechet and Hausdorff metric lose the ability to distinguish between the two barrels as the paths begin to wander out of well - defined pathways when the temperature is on the order of the equivalent energy of the central barrier ( $2 {k_{B}T}$ at \\unit{300} {\\kelvin } ) . At higher temperatures , thermal perturbations become large relative to the barrier , permitting particle clusters to explore the full width of the potential spanning both barrels so as to generate trajectories confined to a single , unified pathway ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_49": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_49",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_49",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_49",
		"text": "[unused10] \\ text bf { Annotated \\ frechet distance matrix of AdK transition trajectories generated by different path - sampling methods . } The \\frechet distance matrix from Fig.~\\ref{fig:m_psa} is shown with the numerical values of $\\delta_{F}$ ( rounded to one decimal ) superimposed . Due to the size of the distance matrix , the high resolution image is provided as a simple means for online data exploration with the help of the zoom function of an image viewer ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_39": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_39",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_39",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_39",
		"text": "GOdMD produced the path with the greatest peak displacement ( $\\rho\\approx 2.8$ ~ \\AA; Fig.~\\ref{fig:m_cv} C ) , corresponding to complete LID opening before substantial NMP movement occured ( Fig. ~ \\ref{fig:m_cv} B ) . The results from GOdMD are unlike any of the other methods and therefore GOdMD is well - classified as an outlier by PSA ( Fig. ~ \\ref{fig:m_psa} ) ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_11": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_11",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_11",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_11",
		"text": "To analyze a set of $N$ paths , we compute the $N(N-1)/2$ unique pairwise Hausdorff and \\ frechet distances . To present the data efficiently , we levied the versatility of hierarchical clustering ~ \\cite{Xu2008-mg} along with the visual power of a heat map - dendrogram representation to present a quantitative approach to visualizing the similarities of collections of paths . In agglomerative hierarchical clustering , objects are linked with similar objects to form growing clusters in a bottom - up approach . The similarity between two objects is defined by a metric , while the similarity of clusters ( i.e. , sets of objects ) is uniquely determined by a linkage criterion that computes cluster similarity as a function of the pairwise similarities of the objects comprising each cluster ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_10": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_10",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_10",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_10",
		"text": "\\paragraph{Path similarity analysis (PSA).} The Hausdorff metric , $\\delta_{H}$ , and the discrete \\ frechet metric , $\\delta_{dF}$ , defined in Eq. ~ \\ref{eq:dh} and Eq. ~ \\ref{eq:dF} , respectively , were computed as described in the Introduction . Further details on the numerical implementation are provided in \\nameref{S2_Text} . Both metrics are implemented as part of the MDAnalysis Python package ~ \\cite{Michaud-Agrawal2011-yg} in the module \\texttt{MDAnalysis.analysis.psa} , which is available as open source at \\url{www.mdanalysis.org} under the GNU General Public License 2 ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_38": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_38",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_38",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_38",
		"text": "MENM - SP was the most distant member in the cluster of the four ENM - based methods in PSA ( Fig. ~ \\ref{fig:m_psa} ) . Careful inspection of both angle - angle space ( Fig. ~ \\ref{fig:m_cv} B ) and \\zr (Fig.~\\ref{fig:m_cv} C ) revealed that the MENM - SP path contained a very large gap in the trajectory snapshots ; the penultimate conformer was located in the first half of the transition ( $\\zeta>$ ~ 4 ~\\ AA ) , while the final snapshot was the open crystal structure end state . Such a big gap in the path affects the discrete Hausdorff / \\ frechet distances because the distance between two MENM - SP paths with well - aligned gaps is unaffected whereas the distance between an MENM - SP path and one without gaps tends to be somewhat larger due to large point distances originating from the latter 's conformers in the portion of the transition where the gap occurs . ANMP was also somewhat of an outlier within the ENM cluster ( Fig. ~ \\ref{fig:m_psa} ) , which can be traced to its path being much farther away from the LinInt reference than any other ENM / Morph method ( $\\rho\\approx 2.2$ \\dots [unused10] ~\\AA{} versus [unused10] ~\\AA; Fig.~\\ref{fig:m_cv} C ) . Structurally , the NMP domain opened nearly all the way before much of the LID motion took place , in contrast with every other method ( Fig. ~ \\ref{fig:m_cv} B ) ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_12": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_12",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_12",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_12",
		"text": "\\paragraph{Native contacts analysis (NCA).} For consistency with other methods used in this paper , we define a contact to be a residue pair whose \\ Ca atoms are separated by a distance smaller than $\\unit{8}{\\angstrom}$ . A \\emph{native contact} is a contact present in a reference structure . Given a transition path , the fraction of native contacts $Q$ ~ \\cite{Shakhnovich1991-ae} is the fraction of contacts in a native structure that are present in a transition structure . We then define , for any intermediate conformer in a transition , $Q_1$ and $Q_2$ as the fractions of native contacts with respect to an initial and final structure , respectively . Transition paths are projected onto 2D $Q_1$ - $Q_2$ ( NC ) space by parametrically plotting the percentage of contacts relative to the initial and final states ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_8": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_8",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_8",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_8",
		"text": "\\paragraph{Measuring structural similarity.} Both the Hausdorff and \\frechet distances defined in Eq.~\\ref{eq:dh} and Eq. ~ \\ref{eq:dF} , respectively , are defined in terms of a point metric $d(p,q)$ on \\ tnd configuration space that measures the distance ( i.e. , similarity ) between conformations $p$ and $q$ . We employ the root mean square distance ( rmsd ) defined in the usual way as \\begin{equation}\\label{eq:rmsd} d_\\text{RMS}(p,q) = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{3N}\\left(p_{i}-q_{i}\\right)^2}, \\end{equation} where $N$ is the number of atoms , and $\\{p_i\\}_{i=1}^{3N}$ and $\\{q_i\\}_{i=1}^{3N}$ define the configuration space coordinates of conformations $p$ and $q$ , respectively ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_9": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_9",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_9",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_9",
		"text": "DT is believed to undergo a transition from an inactive closed conformation to an active open one , which includes a 180 $^{\\circ}$ rotation of a mobile domain ~ \\cite{Bennett1994-hn} ( Fig. ~ \\ref{fig:combotrans} B ) . An open conformation was captured in a domain - swapped dimeric structure ~ \\cite{Bennett1994-um} and compared to the closed monomeric structure ~ \\cite{Bennett1994-im} . DT is divided into three domains , with the translocation ( T ) domain , residues 179 - 379 , being responsible for the majority of the opening and unrolling conformational motion about the receptor - binding ( R ) domain , residues 380 - 535 , and the catalytic ( C ) domain , residues 1 - 178 . The conformational transition of a DT monomer was simulated previously and considered challenging for simulation methods ~ \\cite{Krebs2000-di, Farrell2010-wh} . We simulated transition pathways of DT between a closed and open conformation based on chain A from the monomeric structure ( PDB id : 1MDT ~ \\cite{Bennett1994-im} ) and chain A from the domain - swapped dimeric structure ( PDB id : 1DDT ~ \\cite{Bennett1994-um} ) , respectively ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_13": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_13",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_13",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_13",
		"text": "\\paragraph{Comparison with a linearly interpolated path.} A simple way to quantify the geometry of a single transition path is to measure its orthogonal separation , $\\rho$ , from a reference path as a function of progress , $\\zeta$ , along the reference path ( Fig. ~ \\ref{fig:pla} ) . In this way , any transition path can be projected in a 2D space depicting `` displacement '' ( $\\rho$ ) versus `` progress '' ( $\\zeta$ ) relative to a reference path . We selected naive linear interpolation ( LinInt ) to serve as a zeroth - order reference transition path . Note that , in comparison with PSA , this approach necessitates defining an explicit progress measure in the form of a reference path --- which may not be appropriate beyond relatively simple examples like the AdK transition --- and is furthermore not amenable to direct pair wise comparisons among a large ensemble of transition paths ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_17": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_17",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_17",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_17",
		"text": "To explicitly illustrate the uses and limitations of heuristic collective variables , and to make a connection with previous work , we examine the AdK \\ctor transition ( Fig. ~ \\ref{fig:combotrans} A ) in 2D angle - angle space ~ \\cite{Beckstein2009-ll} . The NMP - CORE angle \\tnmp is formed by the geometric centers of the backbone and C \\textsubscript{ [unused10] } atoms in residues 115 - 125 ( CORE - LID ) , 90 - 100 ( CORE ) , and 35 - 55 ( NMP ) of \\textit{E.\\ coli} AdK . Likewise , \\tlid is defined as the angle between residues 179 - 185 ( CORE ) , 115 - 125 ( CORE - hinge - LID ) , and 125 - 153 ( LID ) . As many of the methods we studied used \\ Ca - only models , we defined NMP - CORE and LID - CORE angles by exclusively using the \\Ca atoms of the residues . The angle - angle space defined by ( \\tnmp , \\tlid ) quantifies the degree to which NMP and LID are open and the sequence in which they open ( close ) for the \\cto ( \\otc ) transition ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_16": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_16",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_16",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_16",
		"text": "Defining $\\rho$ using the rmsd permits a close connection with PSA in the following way : the maximal rmsd of a path $P$ from LinInt , $\\max_{k=1}^m\\{\\rho(k)\\}$ will be the Hausdorff distance between $P$ and LinInt , $\\delta_H(P,\\text{LinInt})$ , when $P$ is restricted to the region of configuration space between the boundary conformations ( and assuming that structural alignment prior to rmsd measurement was performed identically ) . Furthermore , when $P$ does not `` backtrack ' ' , $\\zeta(k)$ is monotonically decreasing --- indeed , $P$ can be said to backtrack ( with respect to some reference path ) when $\\zeta(k)$ is \\emph{not} monotone --- and the Hausdorff and \\ frechet distances coincide : $\\max_{k=1}^m\\{\\rho(k)\\} = \\delta_F(P,\\text{LinInt}) = \\delta_H(P,\\text{LinInt})$ ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_14": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_14",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_14",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_14",
		"text": "Given two boundary conformations $\\{c_0,c_f\\}\\in\\mathbb{R}^{3N}$ in \\ tnd configuration space with reference path $R$ embedded in $\\mathbb{R}^{3N}$ ( that linearly interpolates $c_0$ and $c_f$ ) , and a piecewise - linear ( transition ) path $P$ embedded in $\\mathbb{R}^{3N}$ and composed of a sequence of conformations , $(p_k)_{k=1}^m$ , where $m$ is the number of time steps , we compute for each $p_k$ : ( 1 ) the rmsd between $p_k$ and its orthogonal projection onto $R$ , $r_k$ , \\begin{equation} \\rho(k) = d_\\text{RMS}(p_k,r_k), \\end{equation} and ( 2 ) the rmsd between $r_k$ and final state $c_f$ , \\begin{equation} \\zeta(k) = d_\\text{RMS}(r_k,c_f) \\end{equation} ( see Fig. ~ \\ref{fig:pla} ) . A transition path can then be projected onto \\ zr space by parametrically plotting $\\zeta(k)$ versus $\\rho(k)$ for all values of $k$ . For a path beginning at $r_0=c_0$ , the rmsd to the final structure is given by the rmsd between the initial and final states , $\\zeta(0) = d_\\text{RMS}(c_0,c_f)$ , while the rmsd for a path ending at $r_m=c_f$ is $\\zeta(m) = d_\\text{RMS}(c_f,c_f) = 0$ ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_28": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_28",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_28",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_28",
		"text": "At zero temperature , trajectories initiated at the same point progressed along identical paths due to the absence of thermal diffusion . Two trajectory groups were formed ( Fig. ~ \\ref{fig:doublebarrel} A , B ) , consistent with what was expected from the initial conditions . A clustered heat map of the \\ frechet distances between the $T=\\unit{0}{\\kelvin}$ trajectories clearly showed two well - defined clusters ( Fig. ~ \\ref{fig:doublebarrel} C ) , containing four trajectories each , in both the structure of the dendrogram as well as the color division in the heat map . Due to thermal perturbations , higher - temperature trajectories exhibited substantial wandering ( Fig. ~ \\ref{fig:doublebarrel} D , E ) and even produced a transition across the central barrier ( blue trajectory in Fig. ~ \\ref{fig:doublebarrel} E ) . In contrast with the zero temperature case , both the number of clusters and the clusters themselves were much more vaguely defined . Two clusters with four trajectories per cluster ( red and green / blue trajectories , Fig. ~ \\ref{fig:doublebarrel} D -- F ) were still formed , although the blue trajectory , which underwent a barrier - crossing transition near $z=-\\unit{0.5}{\\nano\\meter}$ , is an outlier in the cluster with the three green trajectories ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_29": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_29",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_29",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_29",
		"text": "Trajectory categorization for the toy model with PSA did not depend strongly on the dimensionality ( cluster size ) as thermal noise alone appeared to have a much more substantial influence ( \\nameref{S1_Fig} ) . In particular , we could not discern meaningful differences in the center of mass motions between one - and eight - particle clusters from the data . Furthermore , in the eight - particle case at \\unit{250} {\\kelvin } , performing PSA using the full ( $24$ - dimensional ) configuration space trajectories did not produce a different clustering than PSA applied only to the center of mass trajectories ( data not shown ) . The same analysis as above was carried out with the Hausdorff distance instead of the \\ frechet distance to assess their relative discriminative powers . Both produce similar results at temperatures below \\unit{300} {\\kelvin } with low - temperature simulations exhibiting two distinct pathways ( \\nameref{S2_Fig} ) . Between \\unit{350} { \\kelvin} and \\unit{500} {\\kelvin } , however , Hausdorff and \\ frechet distance measurements started to become substantially uncorrelated ( \\nameref{S3_Fig} ) . This effect is likely due in part to the sensitivity of the \\frechet metric to backtracking (Fig.~\\ref{fig:frechethaus} ) , which may be amplified when the typical energy of thermal perturbations become comparable to the height of a potential barrier ( $2 k_{B}T$ at \\unit{300} { \\kelvin}). High-temperature simulations ( [unused10] \\unit{300} {\\kelvin } ) began to explore both tubes as if they were a single pathway ( \\nameref{S2_Fig} and \\nameref{S4_Fig} ) ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_15": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_15",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_15",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_15",
		"text": "\\begin{figure} [ ] \\begin{adjustwidth} { 0.5 in } { 0.5 in } \\ centering \\includegraphics[]{./Fig3.jpg} \\ caption { A hypothetical transition pathway $P$ ( cyan line ) in a 3D configuration space composed of a discrete number of conformer snapshots ( cyan circles ) connects an initial state ( green circle ) , $c_0$ , and final state ( red diamond ) , $c_f$ . The reference path $R$ ( black line ) is represented by LinInt . Each snapshot $p_k$ is associated with its projection , $r_k$ , on $R$ ; the progress , $\\zeta(k)$ , is the rmsd between $r_k$ and $c_f$ ( dashed purple line along $R$ ) and the displacement , $\\rho(k)$ , is the rmsd between $p_k$ and $r_k$ ( dashed purple line perpendicular to $R$ ) . } \\label{fig:pla} \\end{adjustwidth}  \\end{figure}"
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_18": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_18",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_18",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_18",
		"text": "The toy system is defined as a group of $N$ particles connected by harmonic springs subject to Brownian dynamics in a 3D potential energy landscape ( Figure ~ \\ref{fig:toy_model} ) . Individual particles were connected in analogy to a complete graph , with vertices and edges respectively representing particles and springs . Spring equilibrium distances were set to zero separation for simplicity . Differing dimensionalities of the configuration space were examined by varying the number of particles $N$ . The external potential was given a double - well shape in the $y$ - direction with a parabolic shape in the $x$ - direction ( centered at $x=y=0$ ) , ensuring that particle clusters are confined to one of two `` barrels '' running along the $z$ - direction ( Figure ~ \\ref{fig:toy_model} ) . The energy barrier between the tubes was set to a height of 2 ~ $k_BT$ ( $\\sim\\unit{5}{\\kilo\\joule\\per\\mole}$ ) at $T=\\unit{300}{\\kelvin}$ . We set up a ramp potential sloping down toward increasing $z$ ( i.e. , a constant potential energy gradient in the positive $z$ direction ) to induce large - scale transitions from small to large values of $z$ ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_30": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_30",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_30",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_30",
		"text": "\\begin{figure} [ htb ] \\begin{adjustwidth} { - 0.5 in } { 0.5 in } \\ centering \\includegraphics[]{./Fig6.jpg} \\ caption { Path similarity analysis of trajectories generated by different path - sampling methods . The AdK closed $\\rightarrow$ open transition was sampled three times ( except LinInt ) with different methods ( see text ) . Smaller distances indicate transition paths with greater similarity . The dendrogram depicts a hierarchy of clusters where smaller node heights of parent clusters indicate greater similarity between child clusters . \\ frechet distances $\\delta_{F}$ are in \\ AA { } and correspond to a structural rmsd in accordance with the rmsd point metric . See text for a description of the methods . \\protect\\nameref{S5_Fig} contains the same data annotated with numerical values of $\\delta_{F}$ . } \\label{fig:m_psa}  \\end{adjustwidth}  \\end{figure}"
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_24": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_24",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_24",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_24",
		"text": "The main thrust of the path - sampling methods comparison is to demonstrate PSA 's viability and not necessarily to directly evaluate the performance of the sampling algorithms . As such , adjustable parameters for all simulations were left at their default values unless explicitly stated . Transitions were produced using the highest allowable resolution , i.e. , using all non-hydrogen atoms when possible or only \\ Ca atoms otherwise . For each method , three unique paths were generated by either re-running those with stochastic algorithms or , for the deterministic ones , by adjusting a single parameter ; in the case of rTMD , six total simulations were performed [ three each for fast ( $\\sim\\unit{1}{\\angstrom\\per\\pico\\second}$ ) and slow ( $\\sim\\unit{0.01}{\\angstrom\\per\\pico\\second}$ ) pulling speed ; see \\nameref{S5_Text} for further details ] . DIMS , FRODA and MDdMD simulations , which produce a unique trajectory every run , were run three times each without altering initial settings . Three GOdMD runs were performed by changing the relaxation window ( $\\unit{20}{\\pico\\second}$ , $\\unit{50}{\\pico\\second}$ and $\\unit{100}{\\pico\\second}$ ) . Distinct trajectories for the deterministic , ENM - based algorithms were obtained by varying spring cutoff distances : one transition at the default value and two by decreasing / increasing the cutoff . Morph trajectories were produced by toggling energy minimization and structural pre-alignment settings , and a single LinInt trajectory was included as a zeroth - order reference . All other simulation settings were left at default values where possible . Simulations and analyses performed in this study are summarized in Table ~ \\ref{tab:tests} . Furthermore , as half of the methods were limited to \\ Ca structures as inputs --- the coarsest representation among the methods --- all analyses were restricted to \\ Ca trajectory representations to provide a lowest common denominator . Trajectories were also aligned to a common reference structure generated by aligning and averaging the CORE \\ Ca coordinates of the 1 AKE : A and 4 AKE : A structures ( see \\nameref{S6_Text} in the Supporting Information for a description of the structural alignment procedures ) ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_2": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_2",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_2",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_2",
		"text": "PSA does not require the use of true metrics and can be used with any path distance function or other dissimilarity measure where only Eqs. ~ \\ref{eq:first} -- \\ref{eq:third} are satisfied . The triangle inequality ( Eq. ~ \\ref{eq:fourth} ) , which is a generalization of the transitive property , says that when two objects , $A$ and $B$ , in some metric space , are each close to a third object , $C$ , in the same space , then $A$ is close to $B$ in the sense that the triangle inequality , $d(A,B) \\leq d(A,C) + d(B,C)$ , provides an upper bound on their distance apart . The triangle inequality is therefore important when comparing more than two objects , which is the common scenario when analyzing many conformational transitions . Although in the following we only consider true metrics , we also explore several distance functions that violate the triangle inequality in \\nameref{S1_Text} . In the main part of this study , we consider two candidates for $\\delta$ --- the Hausdorff metric ~ \\cite{Huttenlocher1993-rr, Alt1995-dh, Alt2008-lg} and the discrete \\frechet metric~\\cite{Frechet1906-ih, Alt1995-mc} --- and illuminate situations where one might be selected in favor of the other . Given two paths as input , both metrics locate two points , one per path , corresponding to some notion of a maximal deviation between the paths . An important property of these metrics is that they are sensitive only to path geometry ; they are insensitive to dynamical motions and associated physical time scales along paths . We provide a brief overview of these two path metrics in the context of conformational transitions ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_3": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_3",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_3",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_3",
		"text": "\\paragraph{Hausdorff metric.} We start with a \\ tnd configuration space containing two paths $P$ and $Q$ represented , respectively , as sequences of conformations $\\{(p_k)_{k=1}^n \\mid p_k\\in\\mathbb{R}^{3N}, k=1,\\dots,n\\}$ and $\\{(q_k)_{k=1}^m \\mid q_k\\in \\mathbb{R}^{3N}, k=1,\\dots,m\\}$ . The \\emph{Hausdorff distance} is defined as \\begin{equation}\\label{eq:dh} \\delta_{H}(P,Q) = \\max\\left\\{\\delta_h(P\\mid Q),\\delta_h(Q\\mid P)\\right\\}, \\end{equation} where \\begin{equation}\\label{eq:direct-dh} \\delta_{h}(P\\mid Q) = \\max_{p\\in P}\\min_{q\\in Q} d(p,q) \\end{equation} is the \\emph{directed Hausdorff distance} from $P$ to $Q$ , and $d$ is a distance metric on $\\mathbb{R}^{3N}$ ( measuring point distances ) ~ \\cite{Huttenlocher1993-rr} ; the vertical bar ( $P\\mid Q$ ) emphasizes that $\\delta_{h}(P\\mid Q)$ is not commutative . The function $\\delta_{h}(P\\mid Q)$ selects the point $p*\\in P$ , among all points in $P$ , with the most distant nearest neighbor $q*\\in Q$ ( as measured by $d(p*,q*)$ ) . In the language of conformational transitions , we interpret $d(p,q)$ as a putative structural similarity measure between conformers $p$ and $q$ , so that for some conformer $p_k\\in P$ , its structural `` nearest neighbor '' in $Q$ is given by $\\min_{q\\in Q} d(p_k,q)$ . Thus , $\\delta_{h}(P\\mid Q)$ is the distance $d$ associated with the conformer in $P$ having the \\emph{most distant} or \\emph{least similar} nearest neighbor ( in $Q$ ) . The Hausdorff distance between $P$ and $Q$ , $\\delta_H(P,Q)$ , is therefore the distance associated with the point --- \\ emph { of all points in $P$ and $Q$ } --- with the least similar nearest neighbor , and implies that all points have a nearest neighbor that is at most $\\delta_H(P,Q)$ away ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_25": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_25",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_25",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_25",
		"text": "\\begin{table} [ ht ] \\begin{adjustwidth} {- 2.25 in } { 0 in } % Comment out / remove adjust width environment if table fits in text column . \\caption{\\sffamily\\small\\textbf{Summary of simulations, calculations, and analyses.} } \\sffamily\\small \\begin{tabular} {@{} | l | l | l | l | l| l | @{}} \\hline Assessment & System & Transition & Path generation & \\# path samples  & Analysis methods\\tsup{ [unused10] } \\\\ \\hline ( 1 ) Intuition and viability & double - barrel & $z$ : ~ $0\\rightarrow 4$ ~ nm & Brownian $\\,+\\,$ ramp & 4 $\\times$ ( 2 ICs ) & PSA ( \\dF ) , \\dF {}- \\dH distr/ corr * \\\\ \\hline ( 2 ) Methods comparison & AdK & \\cto & various methods & 3 $\\times$ ( 11 methods ) & PSA ( \\dF / \\dH {}* ) , NCA , \\zr , AA \\\\ \\hline ( 3 ) Transition ensembles & AdK & \\cto & DIMS , FRODA & 200 $\\times$ ( 2 methods ) & PSA ( \\dF {}* ) , \\dF -\\dH distr/corr * \\\\ \\hline & DT & \\cto & DIMS , FRODA & 200 $\\times$ ( 2 methods ) & PSA ( \\dF ) , \\dF -\\dH distr/corr * \\\\ \\hline ( 4 ) Atomic detail from PSA & AdK & \\cto & DIMS , FRODA & 200 $\\times$ ( 2 methods ) & PSA ( \\dH - pairs ) \\\\ \\hline \\end{tabular}  \\begin{flushleft} * Result in Supporting Information \\\\ \\tsup{ [unused10] } Analysis methods : PSA , path similarity analysis ; \\ dF , \\ frechet distance ; \\ dH , Hausdorff distance ; \\ dF - \\dH distr / corr , \\ frechet { } - Hausdorff distribution / correlation analysis ; NCA , native contacts analysis ; \\ zr , progress vs. displacement along path of linear interpolation ; AA , angle - angle space . \\end{flushleft}  \\label{tab:tests}  \\end{adjustwidth}  \\end{table}"
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_31": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_31",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_31",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_31",
		"text": "Paths from a given method were more similar to other paths from the same method than to those produced by a different method , as indicated by well - defined $3\\times3$ squares along the heat map diagonal . Methods based on similar physical models tended to produce relatively similar pathways , while algorithmically distinct approaches appeared less likely to produce similar pathways . For instance , Morph and LinInt both implement linear coordinate interpolation . Their paths are essentially identical ( $\\delta_{F} \\leq 0.5$ ~\\ AA ) , which indicates that additional features implemented in Morph , such as checking for steric overlaps , may not be relevant for the AdK transition . Another cluster was formed by the two MD - based importance sampling methods , DIMS and MDdMD , together with MD - based rTMD at slow pulling velocity ( `` rTMD - S '' ; \\ frechet distance $2.1\\ \\mathrm{\\AA} \\leq \\delta_{F} \\leq 2.7\\ \\mathrm{\\AA}$ ) . In other cases , similarities and differences did not always follow an immediately obvious pattern . FRODA , which satisfies rigidity constraints during a transition but does not employ a potential energy function , nevertheless formed a cluster with DIMS , MDdMD , and rTMD - S ( $2.6\\ \\mathrm{\\AA} \\leq \\delta_{F} \\leq 3.1\\ \\mathrm{\\AA}$ ) . The grouping of FRODA with DIMS / MDdMD / rTMD - S appears , however , less strong than , for instance , the clustering of DIMS with MDdMD because for other choices of the linkage algorithm FRODA is more distantly associated with the DIMS / MDdMD / rTMD - S cluster and a robust cluster of MAP / Morph / LinInt trajectories ( see \\nameref{S6_Fig} B - - D and further discussion in \\nameref{S3_Text} ) . The fast - pulling rTMD ( `` rTMD - F '' ) and MAP trajectories were strikingly similar to the Morph paths ( $\\delta_{F} \\approx 1$ ~\\ AA ) , even though rTMD - F performs MD with an atomistic physics - based force field , whereas MAP 's energy function is based on an elastic network model and the path is generated via minimization of Onsager - Machlup action ( and not just linear interpolation ) . Interestingly , the MAP / rTMD - F / Morph sub-cluster was grouped with the cluster formed by four of the dynamical algorithms ( DIMS , MDdMD , rTMD - S , FRODA ) . The other four ENM algorithms --- iENM , MENM - SD / SP , and ANMP --- produced their own cluster , with MENM - SD and iENM being the most similar to each other . A careful examination of the heat map revealed that although MAP , rTMD - F , and Morph paths somewhat resembled iENM and MENM - SD paths ( $\\delta_{F} \\leq 2.5$ ~\\ AA ) , their overall patterns of \\ frechet distances were very similar to DIMS / MDdMD / rTMD - S ( as seen in the similar overall striping in the shading of the heat map ) so that the `` Morph - like cluster '' rather clustered with these dynamical methods than with the `` ENM cluster '' . The GOdMD paths formed their own outlier cluster , appearing substantially different from all other methods ( $\\delta_{F} > 3$ ~\\ AA ) ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_19": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_19",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_19",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_19",
		"text": "\\begin{figure} [ !htb ] \\begin{adjustwidth} { 0.5 in } { 0.5 in } \\ centering \\includegraphics[width=230pt]{./Fig4.jpg} \\ caption { The toy model consists of a cluster of connected particles moving in a double - well potential along the $z$ - axis under the influence of a linear ramp potential ( not shown ) . In the cluster for $N=8$ , each particle ( red ) is connected to every other particle with a harmonic spring ( blue ) of equilibrium length 0 ( cluster not shown to scale . ) The potential landscape for constant $z$ forms a `` double barrel ' ' --- red ( blue ) regions correspond to high ( low ) energies --- is parabolic along the $x$ - direction ( cyan line ) , and has a double - well shape in the $y$ - direction ( purple line ) , which produces a central barrier separating two `` barrels ' ' ( gray crosshatching ) . A saddle point is located at the intersection of the cyan and purple lines . Motion in this landscape is biased toward either of the low - energy barrels , but transitions between barrels are possible at finite temperatures . } \\label{fig:toy_model}  \\end{adjustwidth}  \\end{figure}"
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_27": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_27",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_27",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_27",
		"text": "\\begin{figure} [ !htb ] \\begin{adjustwidth} { - 2.0 in } { 0.5 in } \\ centering [unused10] \\ caption { Double - barrel potential energy landscape projected onto the $xy$ - plane and $yz$ - plane . Groups of point masses ( clusters ) mutually connected by harmonic springs move under the influence of a transition - inducing ramp potential in the positive $z$ direction and the two low - energy minima of the `` barrels ' ' at $y=\\pm \\unit{0.8}{\\nano\\meter}$ . Colored lines depict the center of mass trajectories for each cluster . ( A - - C ) trajectories at $T=\\unit{0}{\\kelvin}$ . ( D - - F ) trajectories at $T=\\unit{250}{\\kelvin}$ . ( A , D ) Projection of paths onto the $xy$ - plane together with the double - barrel potential . ( B , E ) Projection of paths onto the $yz$ - plane . ( C , E ) Clustered heat maps summarize the \\ frechet distances for all pairs of trajectories ; dendrograms record cluster distances according to the Ward criterion . Trajectory colors in each row match the corresponding path ( s ) in the dendrogram . The trajectory - averaged radius of gyration for clusters at finite temperature is \\unit{0.35} { \\ nano\\ meter } ( black circles ) . } \\label{fig:doublebarrel}  \\end{adjustwidth}  \\end{figure}"
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_33": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_33",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_33",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_33",
		"text": "\\paragraph{Native Contacts Analysis.} We performed two dimensional NCA on trajectories by measuring ( for each conformer snapshot ) the fraction of native contacts relative to the closed starting state ( \\qc ) and to the open target conformation ( \\qo ) as collective variables ( Fig. ~ \\ref{fig:m_cv} A ) . Using the NC trajectories , we examined the dynamic relationship of contact formation and breaking for each method . In general , the \\cto trajectories began on or near the right vertical axis , corresponding to the first conformers of the paths having ( nearly ) 100\\% of their contacts in common with the closed structure and around 95\\% of open state contacts . Most trajectories terminated at the top horizontal axis with the final conformers containing close to 100\\% of the final , open 4 AKE : A structure contacts and about 93\\% of 1 AKE : A contacts . The starting conformers of the DIMS NC paths only contained 96\\% of the contacts seen in the 1 AKE crystal structure ( \\qc ~ $=0.96$ ) , which is to be expected given that the initial closed structure was energy - minimized and equilibrated prior to performing MD . \\begin{figure} [ ] \\begin{adjustwidth} { - 1.0 in } { 0.5 in } \\ centering [unused10] \\caption { Projections of trajectory 2 of the AdK \\cto transition from each path - sampling method onto low - dimensional collective variables . The location of the initial structure is shown in each plot by the green circle , while the final structure is represented by the red diamond . ( A ) Projection of all pathways from the various path - sampling methods onto NC space . The horizontal axis corresponds to the percentage of contacts ( of a transition snapshot ) shared with the initial 1 AKE : A structure ( green circle ) and the percentage of contacts in common with the final 4 AKE : A structure ( red diamond ) is displayed on the vertical axis . The top - left legend identifies EN - based methods ; the other methods are listed in the bottom legend . The LinInt path is shown for reference as a broken black curve . ( B ) Projection on NMP angle ( $\\theta_{\\text{NMP}}$ ) \\emph{vs} LID angle ( $\\theta_{\\text{LID}}$ ) . In B and C , trajectories generated by the dynamical methods ( DIMS , rTMD , FRODA , MDdMD , GOdMD ) are plotted with diamonds and non-dynamical method trajectories with circles . ( C ) \\zr space projection using LinInt as the reference path . Trajectory progress in \\zr space is from left to right from higher to lower values of the progress variable $\\zeta$ . MDdMD terminates at 1.5 ~\\AA ~\\Ca rmsd from 4 AKE ( red diamond ) ; DIMS MD terminates at 0.5 ~\\AA ~ heavy atom rmsd . } \\label{fig:m_cv}  \\end{adjustwidth}  \\end{figure}"
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_1": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_1",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_1",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_1",
		"text": "Path similarity analysis ( PSA ) exploits the properties of a ( path ) metric function , $\\delta$ , that measures a distance between a pair of piecewise - linear or polygonal curves , i.e. , an ordered set of vertices connected by edges . A metric $\\delta$ applied to curves $A$ , $B$ , $C$ has the properties \\begin{subequations} \\begin{align} \\delta(A,B) &\\geq 0 \\label{eq:first} \\\\ \\delta(A,B) &= 0 \\iff A=B \\label{eq:second} \\\\ \\delta(A,B) &= \\delta(B,A) \\label{eq:third} \\\\ \\delta(A,C) &\\leq \\delta(A,B) + \\delta(B,C). \\label{eq:fourth}  \\end{align}  \\end{subequations} In particular , Eq. ~ \\ref{eq:second} , the identity property , is essential since it implies that , given two curves $A$ and $B$ , if $B$ were to be continuously deformed so as to monotonically decrease the distance $\\delta(A,B)$ , then $\\delta(A,B)\\rightarrow 0$ as $B\\rightarrow A$ . That is , two curves must become identical as their mutual distance approaches zero so that decreasing values of $\\delta$ correspond to increasing similarity . The other properties --- non-negativity ( Eq. ~ \\ref{eq:first} ) , commutativity ( Eq. ~ \\ref{eq:third} ) and triangle inequality ( Eq. ~ \\ref{eq:fourth} ) --- guarantee that $\\delta$ behaves in the same way as any other metric usually used in structural comparisons ( such as root mean squared distance ) even though it compares whole paths and not just individual conformations ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_0": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_0",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_0",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_0",
		"text": "Using NCA , PCA or other CV approaches cannot , however , guarantee that important dynamical motions will be captured in the projections --- whether ( and what ) dynamical information is lost depends on the projection itself . It is clear that a quantitative method that can examine a full \\ tnd trajectory would help mitigate biases inherent to selecting a coordinate projection . We propose a general computational method named \\emph{Path Similarity Analysis} ( PSA ) to quantitatively compare $3N$ - dimensional macromolecular transition paths , which is based on the idea of measuring the geometric similarity between pairs of paths using path similarity metrics . Based on distances between paths , trajectories are then clustered by similarity . The structural determinants responsible for the difference between any two trajectories are extracted at the atomic level by exploiting properties of the underlying metric . Here we introduce the PSA approach , examine its suitability , performance , and limitations as a computational approach to quantifying path similarity and apply it to a toy system and conformational transitions of two proteins ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_32": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_32",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_32",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_32",
		"text": "The classification of trajectories was found to be robust against use of different linkage functions in the clustering algorithm , provided that the linkage primarily assessed the \\emph{dissimilarity} of clusters ( such as Ward 's criterion in Fig. ~ \\ref{fig:m_psa} and the complete / average / weighted linkage in \\nameref{S6_Fig} B -- D ) instead of similarity ( single linkage in \\nameref{S6_Fig} A ) . Using the Hausdorff metric instead of the \\ frechet metric did not change the clustering either and the Pearson correlation coefficient between $\\delta_{H}$ and $\\delta_{F}$ was very close to unity ( \\nameref{S7_Fig} ) . In \\nameref{S1_Text} , alternative distance definitions , namely averaged \\ frechet and Hausdorff distances ( which are , however , not proper metrics ) , reduced the amount of detail in the clustering and resulted in an amalgamation of clusters into one large `` dynamical methods cluster '' ( TMD - S , DIMS , MDdMD , GOdMD , FRODA ) , a `` Morph - like cluster '' ( Morph , LinInt , TMD - S , MAP ) , and an `` ENM cluster '' ( ANMP , iENM , MENM - SP / SD ) ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_26": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_26",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_26",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_26",
		"text": "We simulated one - and eight - particle cluster transitions in the double - barrel potential energy landscape between a starting state ( defined as a center - of - mass location below $z=\\unit{0}{nm}$ ) and a final state ( $z\\geq\\unit{4}{nm}$ ) . Eight - particle simulations at zero and \\unit{250} { \\kelvin} are shown in Fig.~\\ref{fig:toy_model} . The particles were weakly confined to one of two potential energy barrels separated by a 2 ~ $k_BT$ barrier at \\unit{300} { \\kelvin} (Fig.~\\ref{fig:doublebarrel} A , D ) and evolved under the influence of thermal diffusion and drift due to a linearly decreasing ramp potential in the $z$ direction ( Fig. ~ \\ref{fig:doublebarrel} B , E ) . Simulations were run at temperatures between \\unit{0} { \\kelvin} and \\unit{600} { [unused10] {\\ kelvin } increments , with eight runs at each temperature . Trajectories were initialized such that two distinct groups of paths would be produced at zero temperature : for each temperature , we initialized half of the simulations to one side of the central barrier at $(x_0,y_0) = (\\unit{0}{nm},\\unit{0.4}{nm})$ and the other half at $(\\unit{0}{nm},\\unit{-0.4}{nm})$ ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_22": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_22",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_22",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_22",
		"text": "\\begin{table} [ ht ] \\begin{adjustwidth} { - 2.25 in } { 0 in } % Comment out / remove adjust width environment if table fits in text column . \\setlength{\\tabcolsep} { 0.20 em } \\caption{\\sffamily\\small\\textbf{Approach to generating paths in tested path-sampling methods.} } \\sf family\\small \\begin{tabular} {@{ } | l | l | l | l | l | l | l | @{}} \\hline Type & Name & Dynamics & Path propagation / biasing \\tsup{a} & Rev \\tsup{b} & TS / Stoch \\tsup{c} & Progress variable \\\\ \\hline perturbation MD & DIMS \\cite{Perilla2011-im} & Langevin NVT & SR & N & Y / Y & rmsd - to - target \\\\\\hline & rTMD \\cite{Ferrara2000-py} & Langevin NVT & moving harmonic restraint & N & Y / Y & rmsd - to - target \\\\\\hline & MDdMD \\cite{Sfriso2012-uf} & discrete MD & SR + essential dynamics & N & Y / Y & ssd - to - target \\tsup{ [unused10] } \\\\\\hline & GOdMD \\cite{Sfriso2013-ah} & discrete CG - MD & SR + metadynamics & N & Y / Y & ssd - to - target \\tsup{ [unused10] } \\\\\\hline geometric targeting & FRODA \\cite{Farrell2010-wh} & -- & stepwise - enforced rmsd constraint * & N & Y / ( Y / N ) & rmsd - to - target \\\\\\hline CG - ENM & ANMP \\cite{Das2014-ry} & -- & SD from SP ( cusp min. ) to minima & Y & N / N & -- \\\\\\hline & iENM \\cite{Tekpinar2010-kc} & -- & parametric SP / fixed - point eqn. & Y & N/ N & -- \\\\\\hline & MAP \\cite{Franklin2007-mz} & -- & OM minimum action path & Y & N/ N & -- \\\\\\hline & MENM -SD \\cite{Zheng2007-es} & -- & SD from SP to minima & Y & N/ N & -- \\\\\\hline & MENM -SP \\cite{Zheng2007-es} & -- & parametric SP / fixed - point eqn. & Y & N/ N & -- \\\\\\hline adiabatic mapping & Morph \\cite{Krebs2000-di} & -- & linearly interpolated snapshots & Y & N/ N & -- \\\\\\hline linear interpolation & LinInt & -- & linearly interpolated snapshots & Y & N/ N & -- \\\\\\hline \\end{tabular}  \\begin{flushleft} DIMS , rTMD , MDdMD , and GOdMD are all non-deterministic MD - based methods . DIMS and rTMD employ a conventional force field and Langevin dynamics in the canonical ensemble ; the discrete MD algorithms used by MDdMD and GOdMD assume ballistic particle motion until a collision occurs --- along with the depth of the interatomic square wells , momentum and energy conservation are used to determine outgoing momenta without explicitly computing forces . FRODA uses a non-physical dynamical algorithm to path - search stereochemically correct regions of configuration space . CG - ENM methods generate transitions by constructing low - energy paths in the potential energy landscape . Morph and LinInt linearly interpolate the position of each atom between the initial and final states . \\\\ \\tsup{a} SR , soft ratcheting ; SD , steepest descent ; SP , saddle point ; OM , Onsager - Machlup . \\\\ [unused10] Is the method exactly reversible ? \\\\ [unused10] Is the algorithm based on a ( physical or non-physical ) time step ? Is it stochastic ? \\\\ [unused10] At each step , rmsd reduced by fixed amount while simultaneously enforcing other constraints . \\\\ \\tsup{ [unused10] } ssd , sum of squared distances to target ( includes weighting that varies between MDdMD and GOdMD ) . \\end{flushleft}  \\label{tab:methods_path}  \\end{adjustwidth}  \\end{table}"
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_36": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_36",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_36",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_36",
		"text": "In the \\zr space projection (Fig.~\\ref{fig:m_cv} C ) , the dynamical methods tended to obtain the greatest distance from the LinInt reference path near the end of the transition ( $\\zeta \\lessapprox$ ~ 3.5 ~\\ AA ) whereas the non-dynamical methods peaked nearer the beginning . Thus , the dynamical / non-dynamical method dichotomy previously observed in both NCA and PSA was also present in \\zr space . The structural interpretation of this behavior is , based on the projection into angle - angle space ( Fig. ~ \\ref{fig:m_cv} B ) , that the dynamical methods favored a pathway during which first the LID domains opens , followed by the NMP domain . Non-dynamical methods produced either NMP - opening - first paths or paths with brief LID - opening motions . In \\zr space , however , dynamical methods produced paths with a greater average and peak ( orthogonal ) displacement from LinInt than non-dynamical methods ( which cannot be discerned by apparent displacements in angle - angle space ) , further corroborating the clusterings from PSA ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_4": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_4",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_4",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_4",
		"text": "\\paragraph{\\frechet metric.} Unlike the Hausdorff metric , \\ frechet metrics are sensitive to the orientation ( i.e. , directionality ) of paths ; real transition paths are inherently directional which in principle makes \\ frechet metrics superior to the Hausdorff metric . Informally , the \\emph{continuous \\frechet distance} can be visualized by considering a man walking on a path $P$ and his dog on another path $Q$ ~ \\cite{Alt1995-mc} . Both start at the initial points of their respective paths , and they are imagined to be connected by an elastic leash that remains taught so as to measure the distance separating them at all times . We then allow the man and dog to move independently on their respective paths under the condition that each progresses in a monotonic fashion ( i.e. , no backward steps ) from start to finish . The \\ frechet distance between $P$ and $Q$ is then defined as the length of the shortest leash necessary for the man and dog to move along their respective paths from beginning to end according to the aforementioned constraints . Formally , for two continuous curves $P: [a_{0},a_{1}] \\rightarrow \\mathbb{R}^{3N},\\ a_{0} < a_{1}$ and $Q: [b_{0},b_{1}] \\rightarrow \\mathbb{R}^{3N},\\ b_{0} < b_{1}$ that are parameterized with a real parameter , the continuous \\ frechet distance corresponds to finding two specific continuous and monotonous parameterizations $\\alpha: [0,1]\\rightarrow[a_{0}, a_{1}]$ and $\\beta: [0,1]\\rightarrow[b_{0},b_{1}]$ ( the `` schedules ' ' of the man and the dog along their paths ) so that the largest point distance $d$ for a given set of parameterizations is minimized ~ \\cite{Alt1995-mc} , \\begin{equation} \\label{eq:contFrechet} \\delta_{F}(P,Q) = \\min_{\\alpha, \\beta} % \\max_{t\\in[0,1]}d\\Big(P\\big(\\alpha(t)\\big), Q\\big(\\beta(t)\\big)\\Big). \\end{equation} Algorithms exist to solve this difficult problem in \\BigO{nm\\log nm} time for polygonal curves ( where $n$ and $m$ are the number of vertices in each curve ) ~ \\cite{Alt1995-mc} and various faster approximate solutions have been suggested ~ \\cite{Driemel2012-ji, Har-Peled2014-nx} ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_5": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_5",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_5",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_5",
		"text": "In this paper , however , we exclusively use the \\ emph { discrete \\ frechet distance } , $\\delta_{dF}$ , with the algorithm outlined by ~ \\cite{Eiter1994-wz} as it is simpler and faster to compute ( in \\BigO{nm} time ) than its continuous counterpart , \\ dF . The formal definition of $\\delta_{dF}$ considers two polygonal curves $P$ and $Q$ that are defined respectively by $n$ and $m$ ordered points in a metric space $(V,d)$ for some metric $d$ . Let the corresponding sequence of endpoints of the line segments of $P$ and $Q$ be respectively defined as $\\sigma(P)=(p_1,\\dots,p_n)$ and $\\sigma(Q)=(q_1,\\dots,q_m)$ . In the product space $\\sigma(Q,P) \\equiv \\sigma(P)\\times\\sigma(Q)$ , we define a \\emph{coupling} between two polygonal curves $P$ and $Q$ as a sequence , \\begin{equation} C(P,Q) \\equiv (p_{a_1},q_{b_1}),(p_{a_2},q_{b_2}),\\dots,(p_{a_L},q_{b_L}), \\end{equation} of $L$ unique pairs of points ( i.e. , number of links ) satisfying the following conditions : ( 1 ) The first / last pairs correspond to the first / last points of the respective paths ( $a_1=b_1=1$ , $a_L=n$ and $b_L=m$ ) ; ( 2 ) at least one point on a path ( for a pair of points , one per path ) must be advanced to its successive point , i.e. , \\ ( $a_{i+1}=a_i$ and $b_{i+1}=b_i+1$ ) or ( $a_{i+1}=a_i+1$ and $b_{i+1}=b_i$ ) or ( $a_{i+1}=a_i+1$ and $b_{i+1}=b_i+1$ ) for all $i=1,\\dots,L$ . The largest distance between a pair of points $(p_{a_i},q_{b_i})$ for a given coupling $C$ defines the coupling distance \\begin{equation} \\label{eq:coupl_dist} \\|C\\| \\equiv \\max_{i=1,\\ldots,L} d(p_{a_i},q_{b_i}). \\end{equation} Given the space of all possible couplings between $P$ and $Q$ , $\\Gamma_{P,Q}$ , the \\emph{discrete \\frechet distance} between $P$ and $Q$ is the minimum coupling distance among all couplings in $\\Gamma_{P,Q}$ : \\begin{equation} \\label{eq:dF} \\delta_{dF}(P,Q) = \\min_{C\\in\\Gamma_{P,Q}}{\\|C\\|}. \\end{equation}"
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_37": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_37",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_37",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_37",
		"text": "Fast - pulling rTMD ( rTMD - F ) , as a dynamical method , appeared as an exception to the dynamical / non-dynamical method dichotomy . However , both the projection onto domain angles and especially the \\ zr projection clearly showed that the rTMD - F path was very similar to LinInt ( $\\rho <$ ~ 1 ~\\ AA { } in Fig. ~ \\ref{fig:m_cv} C ) . rTMD with very high pulling velocities of the restraint potential moves the system almost exlusively in the direction of the restraint force . For an rmsd restraint , the gradient points exactly along the LinInt path . Therefore , rTMD - F functions more like LinInt or Morph and less than equilibrium MD with an additional bias potential and hence PSA clustered rTMD - F with LinInt and Morph ( Fig. ~ \\ref{fig:m_psa} ) ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_23": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_23",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_23",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_23",
		"text": "We also generated transitions using five CG - ENM - based methods . These particular models first construct two harmonic potential energy functions , based on anisotropic network models ( ANMs ) , about initial and final native ( crystallographic ) states , which has the general form \\begin{displaymath} \\label{eq:anm} U ( \\mv{X} ) = \\frac{1} { 2 } \\sum_{d_{ij} ^ {\\,0 } < R_c } C_{ij } [unused10] - d_{ij } ^ {\\,0 }\\ right ) ^ 2 + \\Delta U , \\end{displaymath} where the sum is taken over all unique pairs of \\ Ca atoms separated by less than a specified cutoff distance , $R_c$ , and $\\Delta U$ is the energy difference between the two states . For atoms $i$ and $j$ , $C_{ij}$ is the force constant , $d_{ij}$ is the Euclidean distance between them , and $d_{ij}^{\\,0}$ is the corresponding distance in the native ( crystallographic ) structure . Force constants can determined by fitting to isotropic crystallographic B - factors for instance . A double - well ( two - state ) potential landscape is constructed by combining the separate potentials . Given a two - state potential , transition paths are generated by connecting the two ( end - state ) minima along low - energy pathways . The ENM - based methods are distinguished primarily by their two - state energetics ( i.e. , mixing potential ) and method of defining and searching for low - energy transition paths . The cutoff distance , $R_c$ , can adjusted to some degree for all the tested ENM - based approaches , but a couple also enable modification of the force ( spring ) constants , $C_{ij}$ , and the end state energy difference , $\\Delta U$ ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_35": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_35",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_35",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_35",
		"text": "Morph , LinInt , and two of the five ENM - based methods ( ANMP and iENM ) produced the shortest NC trajectories progressing directly to the target conformation with relatively little wandering , whereas the six MENM paths deviated noticeably toward the DIMS and FRODA trajectories in the latter half of the transition ; MAP paths were also nearer the MENM pathways in location and shape than to the paths from the other ENM - based methods . The MENM paths and two MAP paths were unique among the non-dynamical methods in that they each contained a V - shaped , cusp - like feature where extra 4 AKE : A contacts were broken ( \\ qo ~ $\\approx 0.91$ , $0.91$ and $0.92$ , respectively ) that were subsequently reformed toward the end of the transition . The rTMD - F NC path was situated in an intermediate position between the other dynamical methods and the non-dynamical methods . Initially , only 1 AKE : A contacts that do not exist in 4 AKE : A were broken . Then the missing 4 AKE : A native contacts were formed . The Morph , LinInt , ANMP and iENM paths , which were divided between two clusters in PSA , exhibited progress along negatively sloped NC space trajectories during which 4 AKE : A contacts were formed while 1 AKE : A contacts were simultaneously broken . However , the close structural correspondence between MAP , rTMD - F , and Morph paths in PSA was not recapitulated in NCA . On the other hand , the ANMP paths , which were reasonably similar to iENM in PSA ( $1.4\\ \\mathrm{\\AA} \\leq \\delta_{F} \\leq 2.7\\ \\mathrm{\\AA}$ in Fig. ~ \\ref{fig:m_psa} ) but fairly different from Morph ( $2.8\\ \\mathrm{\\AA} \\leq \\delta_{F} \\leq 3.1\\ \\mathrm{\\AA}$ ) , appeared fairly similar to both iENM and Morph in NC space ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_21": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_21",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_21",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_21",
		"text": "\\begin{table} [ ht ] \\begin{adjustwidth} { - 2.25 in } { 0 in } % Comment out / remove adjust width environment if table fits in text column . \\setlength{\\tabcolsep} { 0.20 em } \\caption{\\sffamily\\small\\textbf{Modeling of energetics in tested path-sampling methods.} } \\sffamily\\small \\begin{tabular} {@{ } | l | l | l | l | l | l | l |@{}} \\hline Res \\tsup{a} & Name & Force field / potential \\tsup{b} & Solvent energetics \\tsup{c} & Mixing function / other energetics \\tsup{d} \\\\ \\hline all - atom & DIMS \\cite{Perilla2011-im} & CHARMM22 / CMAP & ACS / ACE2 IS & $T=\\unit{300}{\\kelvin}$ \\\\\\hline & rTMD \\cite{Ferrara2000-py} & CHARMM22 / CMAP & Generalized Born IS & $T=\\unit{300}{\\kelvin}$ \\\\\\hline & MDdMD \\cite{Sfriso2012-uf} & bonds / angles : inf. \\ sq - well & Lazaridis - Karplus IS & NBF : simple vdW / electrostatic , $T=\\unit{300}{\\kelvin}$ \\\\\\hline & FRODA \\cite{Farrell2010-wh} & stereochemical constraints & hydrophobic contacts * & overlap / angle / H - bond constraints \\\\\\hline & Morph \\cite{Krebs2000-di} & CHARMM / XPLOR \\tsup{ [unused10] } & -- & energy minimization of intermediate snapshots \\\\\\hline & LinInt & -- & -- & -- \\\\\\hline \\Ca- only & GOdMD \\cite{Sfriso2013-ah} & bonds : inf. \\ sq - well & -- & NBF : Go - like + ENM - MetaD \\\\\\hline & ANMP \\cite{Das2014-ry} & double - well ANM & -- & $E_\\text{mix}=\\min\\left\\{U_i,U_f\\right\\}$ \\\\\\hline & iENM \\cite{Tekpinar2010-kc} & double - well ANM & -- & $E_\\text{mix}=F(U_i,U_f)$ ( arbitrary ) , collision penalty \\\\\\hline & MAP \\cite{Franklin2007-mz} & two ANMs , OM dynamics & overdamped Langevin \\tsup{ [unused10] } & minimum OM action $\\rightarrow$ 2 ODEs +BCs $\\rightarrow$ path \\\\\\hline & MENM - SD / SP \\cite{Zheng2007-es} & double - well ANM & -- & $E_\\text{mix}=\\beta^{-1} \\ln\\left\\{\\exp\\left[-\\beta(U_i+\\epsilon_i)\\right] + \\exp\\left(-\\beta(U_f+\\epsilon_f)\\right]\\right\\}$ \\\\\\hline \\end{tabular}  \\begin{flushleft} All MD - based methods use atomic resolution ; Morph and LinInt are the only other methods with greater than \\ Ca resolution . Except for MAP , ENM - based models define double - well potentials using different mixing functions of each anisotropic network model ( ANM ) constructed about each native states . MAP uses 2 ODEs , found by minimizing the Onsager - Machlup action for each ANM about the native states , and satisfying continuity conditions for positions and velocities at their interface . MENM - SD / SP assumes weak mixing : $T_m = T$ ( $\\beta=1/kT_m$ , is an adjustable parameter ) ; in the limit of vanishing mixing , $T_m\\rightarrow 0^+$ , $E_\\text{mix}= \\min\\left\\{U_i,U_f\\right\\}$ , which is the same double - well potential used by ANMP . \\\\ [unused10] Resolution of the model . \\\\ [unused10] inf. sq - well , infinite square well ; ANM , anisotropic network model ; OM , Onsager - Machlup . \\\\ [unused10] IS , implicit solvent ; FRODA does not have a solvent model ; MAP assumes overdamped Langevin dynamics in using the Onsager - Machlup action . \\\\ \\tsup{d} NBF , non-bonded forces ; vdW , van der Waals potential ; ENM - MetaD , elastic network model - based metadynamics ; $E_\\text{mix}$ , mixing function for two - state potential ; $U_i$ ( $U_f$ ) , potential energy function about the initial ( final ) native state ; OM , Onsager - Machlup ; ODEs +BCs , ordinary differential equations plus boundary conditions . \\\\ \\tsup{*} FRODA does not use a solvent model . \\\\ \\tsup{ [unused10] } Morph uses CHARMM / XPLOR relaxation to minimize energy of intermediate snapshots . \\\\ \\tsup{ [unused10] } MAP assumes overdamped Langevin dynamics in using the Onsager - Machlup action . \\\\ \\end{flushleft}  \\label{tab:methods_energy}  \\end{adjustwidth}  \\end{table}"
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_7": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_7",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_7",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_7",
		"text": "\\begin{figure} [ t ] \\ centering \\includegraphics[]{./Fig1.jpg} \\ caption { Two paths $P$ ( green ) and $Q$ ( cyan ) begin at state $c_0$ and end at state $c_f$ with directionality indicated by the arrows . The \\ frechet distance $\\delta_F$ and Hausdorff distance $\\delta_H$ are given by the lengths of the purple and orange lines , respectively . The purple lines are the same length and correspond to the minimally stretched \\ frechet `` leash ' ' ; the orange line spans a pair of points separated by the Hausdorff distance ( only one is shown because in this case there are infinitely many pairs of points with the same $\\delta_{H}$ ) . Due to the back tracking of path $P$ toward state $A$ , combined with the monotonicity ( no - backward - movement ) constraint of the \\ frechet metric , $\\delta_{F} > \\delta_{H}$ . } \\label{fig:frechethaus}  \\end{figure}"
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_6": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_6",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_6",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_6",
		"text": "The continuous \\ frechet distance constitutes a lower bound on the discrete \\ frechet distance , $\\delta_{F} \\leq \\delta_{dF}$ , because $\\delta_{F}$ accounts for points along the ( straight ) edges connecting the vertices , whereas $\\delta_{dF}$ only takes the vertices themselves into consideration ~ \\cite{Eiter1994-wz} . Furthermore , if we define the maximum edge length for a polygonal curve $P$ to be the largest distance between consecutive points in $P$ , $d_\\text{max}(P) \\equiv \\max_{i=1,\\ldots,p-1}d\\left(p_i,p_{i+1}\\right)$ , we can set an upper bound on $\\delta_{dF}$ given two polygonal curves $P$ and $Q$ so that $\\delta_F\\leq \\delta_{dF}(P,Q) \\leq \\delta_F(P,Q) + \\max \\{d_\\text{max}(P), d_\\text{max}(Q)\\}$ ~ \\cite{Eiter1994-wz} . Thus , $\\delta_{dF}$ differs from $\\delta_{F}$ by no more than the longest edge among both paths and , to good approximation , $\\delta_{dF}\\approx\\delta_{F}$ for typical trajectories with regularly spaced conformations . Hereafter we refer to the discrete \\ frechet distance as simply the \\ frechet metric ( distance ) with symbol \\ dF { } for brevity . The \\ frechet distance is bounded from below by the Hausdorff distance for any given pair of piecewise - linear curves ~ \\cite{Alt2001-wh} ( $\\delta_{F} \\geq \\delta_{H}$ ) because for convex polygonal curves the \\ frechet and Hausdorff distances are equal ~ \\cite{Buchin2008-tv} while for other path geometries the \\ frechet distance can become arbitrarily larger than the Hausdorff distance ~ \\cite{Driemel2012-ji} . In the case of macromolecular trajectories , the case of backtracking appears particularly relevant because of its conceptual link to a random walk and its connection to thermal fluctuations . If one path runs backward along some portion relative to another path , the \\ frechet distance will increase with the extent of the back tracking , whereas the Hausdorff distance will be unaffected since it ignores the direction of path traversal ( Fig. ~ \\ref{fig:frechethaus} ) ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_20": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_20",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_20",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_20",
		"text": "To construct a properly coarse - grained system , we required zero - temperature cluster dynamics to be identical for all $N$ - particle clusters ( given sensibly chosen initial conditions ) . Spring constants , particle masses and sizes , and the external potentials were scaled so as to preserve the average diffusive behavior of a cluster . Furthermore , spring constants were chosen to be large enough to prevent clusters from splitting themselves across the central barrier ( where some particles in the cluster fall to one tube and some fall to other ) . Particles comprising a cluster were furthermore initialized at the same location so that zero temperature center - of - mass trajectories would be independent of particle number , $N$ . It should be emphasized that this toy model was not intended to replicate a real physical system , but primarily served to build intuition prior to studying conformational pathways in realistic protein systems . More detailed information about the construction of the double - barrel system is provided in \\nameref{S4_Text} in the Supporting Information ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_34": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_34",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_34",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_34",
		"text": "The five dynamical methods --- DIMS , rTMD , FRODA , MDdMD , and GOdMD --- produced somewhat noisy paths where the fluctuations took place along a positively sloping direction in NC space . A positive slope implies that contacts were simultaneously formed or broken relative to both native structures , which can be taken to be indicative of passage through a transition state that is distinct from either end state conformation . DIMS trajectories did not exactly reach the target structure ( \\qo ~ $\\leq 0.98$ ) as DIMS simulations were considered complete as soon as a conformer was within 0.5 ~\\ AA { } heavy atom ( non-hydrogen ) rmsd from the target crystal structure 4 AKE . MDdMD paths partly overlapped with DIMS paths during contact breaking but failed to reform them ( \\qo ~ $<0.94$ ) ; as with DIMS , transition completion is determined by a cutoff --- manually set to 1.5 ~\\AA ~\\Ca rmsd --- due to the difficulties of convergence to a target using the soft - ratcheting biasing approach in MDdMD . DIMS and MDdMD broke a similar number of contacts relative to both states ( around 8 - 9 \\% and 9 - 10 \\% , respectively ) . rTMD -S showed qualitatively similar behavior but broke up to about 12 \\% of native contacts . The closely - knit cluster of DIMS , MDdMD and rTMD -S paths produced by PSA reflects the qualitative similarity of their NC trajectories . DIMS , MDdMD and FRODA all generated noisy , V - shaped NC pathways suggestive of a transition region and supports the picture from PSA where these three methods form a loose cluster apart from the non-dynamical methods . FRODA clustered somewhat apart from the other three , which correlates with the observation that FRODA trajectories in NC space exhibited the greatest contact breaking ( \\qc ~ $=0.82$ , \\qo ~ $=0.80$ ) of all methods tested . This behavior is not unexpected because FRODA achieves random motion by randomly displacing and rotating rigid units of the protein at the sub-amino acid level at each step prior to re-enforcing geometric constraints . As such , \\ Ca fluctuations and , thus , native contact dynamics that would be prohibited by conventional potentials are permitted by the geometric model although constraints on the overall sequence and structure would nevertheless limit dramatic perturbations to the \\ Ca rmsd . GOdMD paths , though quite noisy , followed a path more closely resembling those from the non-dynamical methods , particularly MAP and Morph ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_47": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_47",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_47",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_47",
		"text": "[unused10] \\ text bf { Effect of temperature and dimensionality on the correlation between \\ frechet and Hausdorff distance . } Coefficients of the Pearson correlation between Hausdorff and \\ frechet distances for one - and eight - particle simulations plotted as a function of temperature . Path distances remain well correlated up to \\unit{300} {\\kelvin } and are least correlated at \\unit{500} {\\ kelvin } , with the one - particle simulations exhibiting a substantially larger drop in correlation . At the highest temperature the central barrier becomes negligible and the simulations start to equally sample a single tube dominated by the steep repulsive walls . Therefore , the paths become more similar again between the $N=1$ and $N=8$ clusters and the correlation coefficient increases ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_46": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_46",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_46",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_46",
		"text": "\\label{S2_Fig}  \\textbf{Correlation analysis of \\frechet and Hausdorff distances in the toy model.} Regression analyses examining the correlation between corresponding \\ frechet ( horizontal axes ) and Hausdorff ( vertical axes ) distance measurements are plotted along with the joint distributions plots for double - barrel simulations of one particle ( orange points ) and eight particles ( purple ) for temperatures ranging between 0 and \\unit{500} { \\kelvin} in \\unit{50} {\\kelvin } increments ( panels A - - K ) and at \\unit{600} {\\kelvin } ( panel L ) . Scatter points correspond to individual \\ frechet distance measurements in nm rmsd and are plotted with the line produced by linear regression . The shading about the regression lines correspond to a 95\\% confidence interval . Kernel density estimates ( kde ) are shown for each $N$ , $T$ pair and are computed using the same set of bandwidth constants specified in \\nameref{S1_Fig} . The separated distributions at low temperatures merge between \\unit{300} { \\kelvin} to \\unit{450} {\\kelvin } , with a notable narrowing of the range of distance measurements occuring between \\unit{400} {\\kelvin } to \\unit{450} {\\kelvin } ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_44": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_44",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_44",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_44",
		"text": "\\paragraph{Summary.} We developed a flexible and quantitative framework for analyzing macromolecular transition paths using path metrics as a means to measure the mutual similarity of paths in configuration space , potentially using the full $3N$ - dimensional configuration space information . As far as we are aware , there is currently no standard procedure for quantitatively analyzing and characterizing transition paths . After comparing a set of transitions from a variety of path - sampling algorithms and analyzing transition ensembles of two sets of dynamical , stochastic trajectories , PSA 's viability as a tool to quantitatively compare transition paths appears promising ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_50": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_50",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_50",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_50",
		"text": "\\label{S11_Fig} \\ text bf { Nearest neighbor distances along trajectories for the median Hausdorff pairs in the AdK ensemble comparison . } The nearest neighbor distances $\\delta_{h}(k; Q \\mid P)$ ( solid line , \\ solidrule ) and $\\delta_{h}(k; P \\mid Q)$ ( dashed line , \\ dashed rule ) between pairs of paths $P$ / $Q$ belonging to the three median Hausdorff pairs in the AdK ensemble comparison ( Fig. ~ \\ref{fig:dhp} A ) are shown for DIMS / FRODA ( purple ) , DIMS / DIMS ( blue ) , and FRODA / FRODA ( green ) . The largest value $\\max_{k,j}\\big(\\delta_{h}(k; Q \\mid P), \\delta_{h}(j; P \\mid Q)\\big)$ is the actual Hausdorff distance . For illustration purposes , nearest neighbor distances are plotted as a function of frame number $k$ normalized to the interval $[0,1]$ ( i.e. , $k/|P|$ ) , where $0$ ( $1$ ) corresponds to the first ( last ) frame . In general , an appropriate one - dimensional order parameter should be chosen in order to plot nearest neighbor distances for structurally corresponding trajectory frames ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_45": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_45",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_45",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_45",
		"text": "[unused10] \\text bf { Effect of temperature and dimensionality on the distribution of path metrics . } Violin plots \\cite{Hintze:1998tw} show the distributions of discrete \\ frechet distances for double - barrel simulations of one particle ( orange ) and eight particles ( purple ) for temperatures ranging between 0 and \\unit{500} {\\kelvin } in \\unit{50} {\\kelvin } increments ( panels A - - K ) and at \\unit{600} {\\kelvin } ( panel L ) . Black points correspond to individual \\ frechet distance measurements , with distance units in nm rmsd . A kernel density estimate ( kde ) is shown for each $N$ , $T$ pair to qualitatively emphasize the behaviors of the distributions across the entire temperature range ; the bandwidth for each pair is explicitly set to produce two distinct distributions at low temperatures and gradually increased to generate smooth , single distributions at high temperatures . The separated distributions at low temperatures merge between \\unit{300} { \\kelvin} to \\unit{450} {\\kelvin } , with the eight - particle simulations merging toward higher temperatures relative to the one - particle simulations ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_41": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_41",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_41",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_41",
		"text": "As an explicit example , we identified three Hausdorff pairs for the DIMS and FRODA \\cto AdK transition ensembles and projected them in AA space ( Fig. ~ \\ref{fig:dhp} A ) . We first segregated the full set of Hausdorff distance measurements into : ( 1 ) mutual distances among DIMS paths , ( 2 ) mutual distances among FRODA paths , and ( 3 ) inter-method distances measured between a DIMS and a FRODA path . A total of [unused10] \\dH - pairs were identified for the ensemble of $N=400$ paths . In order to present representative data for the whole ensemble , we identified the two \\dH - pairs associated with the median and maximum Hausdorff distances for each comparison ( 1 ) , ( 2 ) , and ( 3 ) as defined above ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_40": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_40",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_40",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_40",
		"text": "For AdK , transition path trajectories generated with DIMS formed one cluster that was distinct from a second cluster containing all FRODA trajectories ( see \\nameref{S8_Fig} in the Supporting Information ) . The mean \\ frechet distance $\\langle\\delta_{F}\\rangle$ between DIMS and FRODA trajectories was $\\unit{2.9\\pm 0.1}{\\angstrom}$ , significantly higher than the mean within the FRODA ( $\\unit{2.2\\pm 0.1}{\\angstrom}$ ) and DIMS ensemble ( $\\unit{1.4\\pm 0.2}{\\angstrom}$ ) . DIMS generated paths with smaller \\ frechet distances among themselves than FRODA , while paths produced by a given method were notably more similar among themselves than when compared with paths from the other method , with no difference between \\ frechet and Hausdorff distance ( \\nameref{S10_Fig} A ) . These observations imply that while FRODA produced paths that sampled a larger region of AdK 's configuration space than DIMS , each method generated a unique pathway that can be viewed as a tube in configuration space whose diameter was smaller than the typical distance between the tubes ."
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_42": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_42",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_42",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_42",
		"text": "\\begin{figure} [ ] \\begin{adjustwidth} { - 2.0 in } { 0.5 in } \\ centering \\includegraphics[]{./Fig9.jpg} \\ caption { `` Hausdorff pairs ' ' ( $\\delta_H$ - pairs ) analysis using 200 DIMS ( cyan ) and 200 FRODA ( light green ) trajectories projected into AA space . Hausdorff distances were computed for all unique path pairs . ( A ) Conformer pairs --- corresponding to the $\\delta_H$ - pairs with the median and maximum Hausdorff distances ( solid and dashed lines , respectively ) --- are projected onto the domain angle space for the following comparisons : DIMS -- FRODA ( purple ) , DIMS -- DIMS ( red ) , and FRODA -- FRODA ( blue ) . Experimental crystal structures , including some intermediates , are shown as stars \\cite{Beckstein2009-ll} , with further details available in \\nameref{S1_Tab} . Insets : Two heavy - atom representations are shown for the median $\\delta_H$ - pair between a DIMS path and FRODA path , corresponding to snapshots from the respective trajectories . The magnitude of the displacement vector between the two conformations is projected onto each atom . Color bar units for atomic displacement are in \u00c3 ngstr\u00c3\u00b6m . The initial and final conformations ( green circle and red diamond , respectively ) are shown along with the linear interpolation path LinInt -- black dashed line ) for reference . ( B , C ) Salt bridges in the DIMS and FRODA conformers from the DIMS - FRODA median Hausdorff pair . Three LID - NMP salt bridges ( R156 - D33 , D158 - R36 , and K157 - D54 ) and a CORE - NMP salt bridge ( E170 - K57 ) are intact in the DIMS structure ( B ) that are broken in the FRODA structure ( C ) . The residues responsible for these salt bridges tug on the NMP domain more substantially than their counterparts in the LID domain , which are located toward the base of the LID . } \\label{fig:dhp}  \\end{adjustwidth}  \\end{figure}"
	},
	"1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_43": {
		"id": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_43",
		"phase": "test",
		"topic": "q_bio.qm",
		"document": "1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways",
		"paragraph": "paragraph_43",
		"prefix": "selected/test/q_bio.qm-ann11/1505.04807v2.Path_Similarity_Analysis_a_Method_for_Quantifying_Macromolecular_Pathways/paragraph_43",
		"text": "A Hausdorff pair describes the two frames at which the two trajectories in question differ most . Additionally , the regions where trajectories differ to varying degrees from each other might also be of interest . This kind of information is provided by the the set of nearest neighbor distances along a path . Eq. ~ \\ref{eq:direct-dh} defines the \\emph{nearest neighbor distance} of point $p_{k}$ on path $P$ from path $Q$ as $\\delta_{h}(k; P\\mid Q) := \\delta_{h}(p_{k} \\mid Q) := \\min_{q\\in Q} d(p_{k}, q)$ and the nearest neighbor distance of point $q_{k}$ on path $Q$ from path $P$ as $\\delta_{h}(k; Q \\mid P)$ . In general , these two distances are not symmetric , i.e. {} $\\delta_{h}(k; P \\mid Q) \\neq \\delta_{h}(j; Q \\mid P)$ for any conformations $j, k$ . When $\\delta_{h}\\big(k(\\xi); P \\mid Q\\big)$ and $\\delta_{h}\\big(j(\\xi); Q \\mid P\\big)$ are plotted against a suitable common order parameter $\\xi$ , the regions of large and small differences between trajectories can be quantified . For example , in \\nameref{S11_Fig} , the nearest neighbor distances of the three pairs of trajectories corresponding to the median Hausdorff pairs in Fig. ~ \\ref{fig:dhp} A showed that the DIMS and FRODA trajectories primarily differed in the first [unused10] \\ % of the transition , which corresponds to LID - opening in DIMS and simultaneous LID / NMP - opening in FRODA . The DIMS trajectories differed almost uniformly along the whole path by only $\\lessapprox 1.3$ ~\\ AA , suggesting that they follow a similar path perturbed by thermal fluctuations . The FRODA trajectories differed by $\\sim 2$ ~\\ AA {} during the middle half of the transition but practically coincided at beginning and end , showing that FRODA can accurately connect two given endpoint structures even with its stochastic component enabled ."
	}
}